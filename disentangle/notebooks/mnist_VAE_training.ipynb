{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this notebook, the idea is to try to see how much compression we can get with a LVAE model. The hope is that we can then work with a smaller latent space and apply discriminator on this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.model_type import ModelType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.core.data_type import DataType\n",
    "from disentangle.core.sampler_type import SamplerType\n",
    "from finetunesplit.asymmetric_transforms import TransformEnum\n",
    "\n",
    "\n",
    "import ml_collections\n",
    "config = ml_collections.ConfigDict()\n",
    "config.training = ml_collections.ConfigDict()\n",
    "config.training.lr = 1e-3\n",
    "config.training.lr_scheduler_patience = 10\n",
    "config.training.val_fraction = 0.1\n",
    "config.training.test_fraction = 0.1\n",
    "\n",
    "config.loss = ml_collections.ConfigDict()\n",
    "config.loss.loss_type = LossType.Elbo\n",
    "# config.loss.usplit_w = 0.1\n",
    "# config.loss.denoisplit_w = 1 - config.loss.usplit_w\n",
    "config.loss.kl_loss_formulation = 'denoisplit'\n",
    "# config.loss.mixed_rec_weight = 1\n",
    "config.loss.restricted_kl = False\n",
    "config.loss.kl_weight = 1.0\n",
    "config.loss.reconstruction_weight = 1.0\n",
    "config.loss.kl_annealing = False\n",
    "config.loss.kl_annealtime = 10\n",
    "config.loss.kl_start = -1\n",
    "config.loss.kl_min = 1e-7\n",
    "config.loss.free_bits = 1.0\n",
    "\n",
    "\n",
    "config.data = ml_collections.ConfigDict()\n",
    "config.data.input_is_sum = False\n",
    "config.data.image_size = 28\n",
    "config.data.normalized_input = True\n",
    "# input has two channels.\n",
    "config.data.color_ch = 1\n",
    "config.data.multiscale_lowres_count = None\n",
    "\n",
    "# for loading MNIST dataset\n",
    "config.data.data_type = DataType.MNIST\n",
    "config.data.num_channels = 2\n",
    "config.data.sampler_type = SamplerType.DefaultSampler\n",
    "config.data.ch0_labels_list = [0, 1]\n",
    "config.data.ch1_labels_list = [3,4]\n",
    "config.data.ch0_transforms_params = [{'name':TransformEnum.PatchShuffle,'patch_size':28, 'grid_size':14}]\n",
    "config.data.ch1_transforms_params = [{'name':TransformEnum.Translate,'max_fraction':1.0}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config.model = ml_collections.ConfigDict()\n",
    "config.model.encoder = ml_collections.ConfigDict()\n",
    "config.model.decoder = ml_collections.ConfigDict()\n",
    "config.model.model_type = ModelType.LadderVae\n",
    "config.model.z_dims = [4,4]\n",
    "\n",
    "config.model.encoder.batchnorm = True\n",
    "config.model.encoder.blocks_per_layer = 1\n",
    "config.model.encoder.n_filters = 64\n",
    "config.model.encoder.dropout = 0.1\n",
    "config.model.encoder.res_block_kernel = 3\n",
    "config.model.encoder.res_block_skip_padding = False\n",
    "config.model.decoder.batchnorm = True\n",
    "config.model.decoder.blocks_per_layer = 1\n",
    "config.model.decoder.n_filters = 64\n",
    "config.model.decoder.dropout = 0.1\n",
    "config.model.decoder.res_block_kernel = 3\n",
    "config.model.decoder.res_block_skip_padding = False\n",
    "\n",
    "config.model.decoder.conv2d_bias = True\n",
    "\n",
    "config.model.skip_nboundary_pixels_from_loss = None\n",
    "config.model.nonlin = 'elu'\n",
    "config.model.merge_type = 'residual'\n",
    "config.model.stochastic_skip = True\n",
    "config.model.learn_top_prior = True\n",
    "config.model.img_shape = None\n",
    "config.model.res_block_type = 'bacdbacd'\n",
    "\n",
    "config.model.gated = True\n",
    "config.model.no_initial_downscaling = True\n",
    "config.model.analytical_kl = False\n",
    "config.model.mode_pred = False\n",
    "config.model.var_clip_max = 20\n",
    "# predict_logvar takes one of the four values: [None,'global','channelwise','pixelwise']\n",
    "config.model.predict_logvar = None  #'pixelwise' #'channelwise'\n",
    "config.model.logvar_lowerbound = -5  # -2.49 is log(1/12), from paper \"Re-parametrizing VAE for stablity.\"\n",
    "config.model.multiscale_lowres_separate_branch = False\n",
    "config.model.multiscale_retain_spatial_dims = True\n",
    "config.model.monitor = 'val_psnr'  # {'val_loss','val_psnr'}\n",
    "config.model.non_stochastic_version = False\n",
    "config.model.enable_noise_model = False\n",
    "config.model.skip_bottomk_buvalues = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.nets.lvae import LadderVAE\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data_mean = {'target': np.array([0.0]), 'input':np.array([0.0])} \n",
    "data_std = {'target': np.array([1.0]), 'input':np.array([1.0])}\n",
    "model = LadderVAE(data_mean, data_std, config, target_ch=1)\n",
    "_ = model.cuda()\n",
    "\n",
    "model.set_params_to_same_device_as(torch.ones(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.training import create_dataset\n",
    "\n",
    "datadir = '/group/jug/ashesh/data/MNIST/'\n",
    "train_dset, val_dset = create_dataset(config, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     pred, td_data = model(tar[None,:1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the optimizer and start VAE training with the first channel of the target data returned from the dataset.\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.training.lr)\n",
    "model.train()\n",
    "_ = model.cuda()\n",
    "num_epochs = 100\n",
    "recons_loss = []\n",
    "kl_loss = []\n",
    "dloader = torch.utils.data.DataLoader(train_dset, batch_size=64, shuffle=True)\n",
    "bar = tqdm(range(num_epochs))\n",
    "for _ in bar:\n",
    "    for i, batch in enumerate(dloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, tar = batch\n",
    "        inp = tar[:,0:1].cuda()\n",
    "        output_dict = model.training_step((inp,inp), i)\n",
    "        loss = output_dict['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        recons_loss.append(output_dict['reconstruction_loss'].cpu().item())\n",
    "        kl_loss.append(output_dict['kl_loss'].cpu().item())\n",
    "        # print(loss.item())\n",
    "        bar.set_description(f\"loss: {np.mean(recons_loss[-10:]):.3f} kl_loss: {np.mean(kl_loss[-10:]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].plot(recons_loss)\n",
    "ax[1].plot(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimgs = 10\n",
    "idx_list = np.random.randint(0, len(val_dset), nimgs)\n",
    "pred_data = {}\n",
    "for idx in idx_list:\n",
    "    inp, tar = val_dset[idx]\n",
    "    mmse_count = 50\n",
    "    pred_samples = []\n",
    "    for _ in range(mmse_count):\n",
    "        with torch.no_grad():\n",
    "            pred, td_data = model(tar[None,:1].cuda())\n",
    "            pred = pred.cpu().numpy()\n",
    "            pred_samples.append(pred)\n",
    "    print(pred.shape)\n",
    "    pred_mmse = np.concatenate(pred_samples, axis=0).mean(axis=0)[0]\n",
    "    pred_data[idx] = {'pred':pred_mmse, 'target':tar[0].numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.plot_utils import clean_ax\n",
    "\n",
    "_,ax = plt.subplots(figsize=(20,4),ncols=10,nrows=2)\n",
    "for i in range(10):\n",
    "    ddict = pred_data[idx_list[i]]\n",
    "    ax[0,i].imshow(ddict['target'], cmap='gray')\n",
    "    # ax[0,i].set_title('target')\n",
    "    ax[1,i].imshow(ddict['pred'], cmap='gray')\n",
    "    # ax[1,i].set_title('predicted')\n",
    "clean_ax(ax)\n",
    "ax[0,0].set_ylabel('target')\n",
    "ax[1,0].set_ylabel('predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
