{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from disentangle.data_loader.patch_index_manager import TilingMode\n",
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "from disentangle.analysis.forward_operator_parameters import get_forward_operator_parameters\n",
    "from disentangle.core.psnr import PSNR\n",
    "from finetunesplit.posterior_sampler import get_transform_obj, PosteriorSampler\n",
    "from disentangle.core.psnr import RangeInvariantPsnr\n",
    "\n",
    "from finetunesplit.asymmetric_transforms import TransformEnum\n",
    "from finetunesplit.calibration.calibration_coverage import compute_for_one_batch\n",
    "from finetunesplit.calibration.grid_search import grid_search\n",
    "from finetunesplit.calibration.grid_search import plot_coverage_plot\n",
    "from finetunesplit.calibration.grid_search import get_percentage_occurance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run ./nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237569",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2504/D21-M3-S0-L0/14\"\n",
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2504/D21-M3-S0-L0/12\"\n",
    "ckpt_dir = '/group/jug/ashesh/training/disentangle/2509/D24-M3-S0-L0/17'\n",
    "assert os.path.exists(ckpt_dir)\n",
    "\n",
    "image_size_for_grid_centers = None\n",
    "custom_image_size = None\n",
    "data_t_list = None #[0,1,2]\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "\n",
    "\n",
    "\n",
    "# coverage parameters.\n",
    "# correlation preserving transform\n",
    "corr_pres_trans=True\n",
    "# enable circular padded tranlation transform\n",
    "enable_translation_transform = False\n",
    "# we oscillate around the best t with a small delta\n",
    "delta_t = 0.1\n",
    "# homography transforms.\n",
    "aug_theta_max = 0.0\n",
    "aug_theta_z_max = 0\n",
    "aug_shift_max=0.0\n",
    "enable_homography_transform = aug_theta_max > 0 or aug_theta_z_max > 0 or aug_shift_max > 0\n",
    "\n",
    "# size of the block which is used to compute the correlation\n",
    "elem_size = 10\n",
    "mmse_count = 50\n",
    "# error is computed from the first prediction\n",
    "compute_error_from_first_prediction= True\n",
    "k_forward_pass = 2\n",
    "\n",
    "k_prediction_mode = 'entire'\n",
    "# whether to enable the hflip, vflip and 90 degree rotation\n",
    "with_transforms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_transforms:\n",
    "    ch1_transforms = [(TransformEnum.Rotate,{}),(TransformEnum.HFlip, {}),(TransformEnum.VFlip, {})]\n",
    "    ch2_transforms = [(TransformEnum.Rotate,{}),(TransformEnum.HFlip, {}),(TransformEnum.VFlip, {})]\n",
    "else:\n",
    "    ch1_transforms = [(TransformEnum.Identity, {})]\n",
    "    ch2_transforms = [(TransformEnum.Identity, {})]\n",
    "\n",
    "if enable_translation_transform:\n",
    "    ch1_transforms.append((TransformEnum.Translate, {}))\n",
    "    ch2_transforms.append((TransformEnum.Translate, {}))\n",
    "\n",
    "if enable_homography_transform:\n",
    "    dct = {'theta_max':aug_theta_max, 'theta_z_max':aug_theta_z_max, 'shift_max':aug_shift_max, 'device': 'cuda'}\n",
    "    print('Enabling homography transform', dct)\n",
    "    ch1_transforms.append((TransformEnum.DeepInV, dct))\n",
    "    ch2_transforms.append((TransformEnum.DeepInV, dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert k_prediction_mode in ['entire', 'only_transformed', 'only_first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "\n",
    "    if 'start_alpha' in config.data:\n",
    "        print('Disabling the mixing augmentation, if any')\n",
    "        config.data.start_alpha = None\n",
    "        config.data.end_alpha = None\n",
    "        config.data.alpha_weighted_target = False\n",
    "            \n",
    "    # config.model.skip_nboundary_pixels_from_loss = None\n",
    "    # if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "    #     config.model.n_levels = 4\n",
    "    # # if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "    #     config.data.sampler_type = SamplerType.DefaultSampler\n",
    "    #     config.loss.loss_type = LossType.Elbo\n",
    "    #     config.data.grid_size = config.data.image_size\n",
    "    # # if 'ch1_fpath_list' in config.data:\n",
    "    #     config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "    #     config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    # # if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "    #     if 'channel_2_downscale_factor' not in config.data:\n",
    "    #         config.data.channel_2_downscale_factor = 1\n",
    "    # # if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "    #     config.model.init_channel_count = 64\n",
    "    \n",
    "    # if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "    #     config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    # if dtype == DataType.HTIba1Ki67:\n",
    "    #     config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "    #     config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    # if 'lowres_merge_type' not in config.model.encoder:\n",
    "    #     config.model.encoder.lowres_merge_type = 0\n",
    "    # if 'validtarget_random_fraction' in config.data:\n",
    "    #     config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    # if config.data.data_type == DataType.TwoDset:\n",
    "    #     config.model.model_type = ModelType.LadderVae\n",
    "    #     for key in config.data.dset1:\n",
    "    #         config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    # if 'dump_kth_frame_prediction' in config.training:\n",
    "    #     config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    # # if 'input_is_sum' not in config.data:\n",
    "    #     config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential_cropped/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.noise_model_ch1_fpath = config.model.noise_model_ch1_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')\n",
    "# config.model.noise_model_ch2_fpath = config.model.noise_model_ch2_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e62d5d",
   "metadata": {},
   "source": [
    "### Finding the optimal mixing ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled, _ = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=2,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))\n",
    "pred = stitch_predictions(pred_tiled,val_dset )\n",
    "if 'target_idx_list' in config.data and config.data.target_idx_list is not None and len(config.data.target_idx_list) > pred[0].shape[-1]:\n",
    "    # it makes it a list. donot make it unless necessary.\n",
    "    pred = [pred[i][...,:len(config.data.target_idx_list)] for i in range(len(pred))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c94f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tar = model.data_mean['target'].cpu().numpy()\n",
    "std_tar = model.data_std['target'].cpu().numpy()\n",
    "assert mean_tar.shape == (1,2,1,1)\n",
    "assert mean_tar.shape == std_tar.shape\n",
    "\n",
    "inp_arr = []\n",
    "tar_arr = []\n",
    "for i in tqdm(range(len(val_dset))):\n",
    "    inp, tar = val_dset[i]\n",
    "    inp_arr.append(inp[None,:1])\n",
    "    tar_arr.append((tar - mean_tar)/std_tar)\n",
    "normalized_inp_patches = np.concatenate(inp_arr,axis=0)\n",
    "normalized_tar_patches = np.concatenate(tar_arr,axis=0)\n",
    "del inp_arr, tar_arr\n",
    "# inp_stitched = stitch_predictions(inp_arr, val_dset)\n",
    "# inp_stitched = [x[...,0] for x in inp_stitched]\n",
    "# tar_stitched = stitch_predictions(tar_arr, val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mixing_t, mu, sigma = get_forward_operator_parameters(val_dset, normalized_tar_patches, normalized_inp_patches, plot=True)\n",
    "forward_operator_params = {\n",
    "    'mixing_t_min': max(0.1,mixing_t - delta_t),\n",
    "    'mixing_t_max': min(0.9,mixing_t + delta_t),\n",
    "    'mu': mu,\n",
    "    'sigma': sigma,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tar_st = stitch_predictions(normalized_tar_patches, val_dset)\n",
    "inp_st = stitch_predictions(normalized_inp_patches, val_dset)\n",
    "inp_est = [x[...,0]*mixing_t + x[...,1]*(1-mixing_t) for x in tar_st] if isinstance(tar_st, list) else tar_st[...,0]*mixing_t + tar_st[...,1]*(1-mixing_t)\n",
    "inp_est = [x*sigma + mu for x in inp_est] if isinstance(inp_est, list) else inp_est*sigma + mu\n",
    "# PSNR(inp_st[0][...,0], inp_est[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTar = pred[0].shape[-1]\n",
    "is_list_prediction = isinstance(pred, list)\n",
    "tar_unnorm = (val_dset._data if not is_list_prediction else [val_dset.dsets[i]._data for i in range(len(val_dset.dsets))])\n",
    "\n",
    "if \"target_idx_list\" in config.data and config.data.target_idx_list is not None:\n",
    "    nTar =len(config.data.target_idx_list)\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp_unnorm = [x[...,config.data.input_idx] for x in tar_unnorm] if is_list_prediction else tar_unnorm[...,config.data.input_idx]\n",
    "    tar_unnorm = [x[...,:nTar] for x in tar_unnorm] if is_list_prediction else tar_unnorm[...,:nTar]\n",
    "else:\n",
    "    inp_unnorm = [x.mean(axis=-1) for x in tar_unnorm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "if is_list_prediction:\n",
    "    ax[0].imshow(pred[0][0,...,0])\n",
    "    ax[1].imshow(pred[0][0,...,1])\n",
    "else:\n",
    "    ax[0].imshow(pred[0,...,0])\n",
    "    ax[1].imshow(pred[0,...,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134763e2",
   "metadata": {},
   "source": [
    "### A model to yield augmented predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7616f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class NnModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NnModel, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)[0]\n",
    "\n",
    "singleoutput_model = NnModel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55526c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_all = get_transform_obj(ch1_transforms, ch2_transforms, correlation_preserving_transforms=corr_pres_trans)\n",
    "aug_model = PosteriorSampler(singleoutput_model, transform_all, forward_operator_params=forward_operator_params, k_predictions=mmse_count,\n",
    "                                       k_prediction_mode=k_prediction_mode, k_forward_pass=k_forward_pass,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(val_dset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "for batch in dloader:\n",
    "    inp_b, tar_b = batch\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, pred1_mmse = aug_model(inp_b.cuda())\n",
    "    output = [x.cpu().numpy() for x in output]\n",
    "    pred1_mmse = pred1_mmse.cpu().numpy()\n",
    "\n",
    "_,ax = plt.subplots(figsize=(6,6),ncols=2,nrows=2)\n",
    "img_idx = np.random.randint(low=0, high=len(tar_b))\n",
    "ax[0,0].set_title('Pred')\n",
    "ax[0,1].set_title('Target')\n",
    "ax[0,0].imshow(output[0][img_idx,0])\n",
    "ax[0,1].imshow(tar_b[img_idx,0])\n",
    "ax[1,0].imshow(output[0][img_idx,1])\n",
    "ax[1,1].imshow(tar_b[img_idx,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95749e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if custom_image_size is None:\n",
    "    skip_pixels = config.data.image_size - image_size_for_grid_centers\n",
    "else:\n",
    "    skip_pixels = custom_image_size - image_size_for_grid_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Looking at the sanity of LC setup.\n",
    "\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "# idx = np.random.randint(len(val_dset    ))\n",
    "# print(idx)\n",
    "# inp, tar = val_dset[idx]\n",
    "# ax[0].imshow(inp[0])\n",
    "# ax[1].imshow(inp[1])\n",
    "# ax[2].imshow(inp[2])\n",
    "# ax[3].imshow(tar[0])\n",
    "# ax[4].imshow(tar[1])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     inp_c = torch.Tensor(inp[None]).cuda()\n",
    "#     pred, _  = model(inp_c)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pred2, inp_c2 = aug_model.one_forward_pass(pred, inp_c[:,1:])\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "# # idx = np.random.randint(len(val_dset    ))\n",
    "# ax[0].imshow(inp_c2[0,0].cpu().numpy())\n",
    "# ax[1].imshow(inp_c2[0,1].cpu().numpy())\n",
    "# ax[2].imshow(inp_c2[0,2].cpu().numpy())\n",
    "# ax[3].imshow(pred2[0,0].cpu().numpy())\n",
    "# ax[4].imshow(pred2[0,1].cpu().numpy())\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pred3, inp_c3 = aug_model.one_forward_pass(pred2, inp_c[:,1:])\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "# # idx = np.random.randint(len(val_dset    ))\n",
    "# ax[0].imshow(inp_c3[0,0].cpu().numpy())\n",
    "# ax[1].imshow(inp_c3[0,1].cpu().numpy())\n",
    "# ax[2].imshow(inp_c3[0,2].cpu().numpy())\n",
    "# ax[3].imshow(pred3[0,0].cpu().numpy())\n",
    "# ax[4].imshow(pred3[0,1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_b_list = []\n",
    "var_list = []\n",
    "err_list  = []\n",
    "one_step_pred_mmse_list = []\n",
    "dloader = DataLoader(val_dset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "for batch in tqdm(dloader):\n",
    "    with torch.no_grad():\n",
    "        inp_b, tar_b = batch\n",
    "        tar_b_normalized = model.normalize_target(tar_b.cuda()).cpu().numpy()\n",
    "        pred_b, one_step_pred_mmse = aug_model(inp_b.cuda())\n",
    "        \n",
    "        pred_b = [x.cpu().numpy()[:,None] for x in pred_b]\n",
    "        pred_b = np.concatenate(pred_b, axis=1)\n",
    "        one_step_pred_mmse = one_step_pred_mmse.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        ec_pred_b = pred_b\n",
    "        ec_tar_b_normalized = tar_b_normalized\n",
    "        ec_one_step_pred_mmse = one_step_pred_mmse\n",
    "        if skip_pixels > 1:\n",
    "            ec_pred_b = pred_b[...,skip_pixels//2:-skip_pixels//2,skip_pixels//2:-skip_pixels//2]\n",
    "            ec_tar_b_normalized = tar_b_normalized[...,skip_pixels//2:-skip_pixels//2,skip_pixels//2:-skip_pixels//2]\n",
    "            ec_one_step_pred_mmse = one_step_pred_mmse[...,skip_pixels//2:-skip_pixels//2,skip_pixels//2:-skip_pixels//2]\n",
    "        \n",
    "        var_b, err_b = compute_for_one_batch(ec_pred_b, ec_tar_b_normalized, elem_size=elem_size,mmse_sample_for_error=ec_one_step_pred_mmse if compute_error_from_first_prediction else None,)\n",
    "        one_step_pred_mmse_list.append(one_step_pred_mmse)\n",
    "        # compute for one batch, both calibration and coverage. \n",
    "        pred_b_list.append(pred_b[:,0])\n",
    "        var_list.append(var_b)\n",
    "        err_list.append(err_b)\n",
    "\n",
    "pred_b = np.concatenate(pred_b_list, axis=0)\n",
    "var = np.concatenate(var_list, axis=0)\n",
    "err = np.concatenate(err_list, axis=0)\n",
    "one_step_pred_mmse = np.concatenate(one_step_pred_mmse_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_stitched  = stitch_predictions(pred_b, val_dset)\n",
    "pred_one_step_stitched = stitch_predictions(one_step_pred_mmse, val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06593ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,8),ncols=2,nrows=2)\n",
    "if is_list_prediction:\n",
    "    ax[0,0].imshow(pred_stitched[0][0,...,0])\n",
    "    ax[0,1].imshow(pred_stitched[0][0,...,1])\n",
    "    ax[1,0].imshow(pred_one_step_stitched[0][0,...,0])\n",
    "    ax[1,1].imshow(pred_one_step_stitched[0][0,...,1])\n",
    "else:\n",
    "    ax[0,0].imshow(pred_stitched[0,...,0])\n",
    "    ax[0,1].imshow(pred_stitched[0,...,1])\n",
    "    ax[1,0].imshow(pred_one_step_stitched[0,...,0])\n",
    "    ax[1,1].imshow(pred_one_step_stitched[0,...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aec859",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_list_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_list_prediction:\n",
    "    print(RangeInvariantPsnr(tar_unnorm[0][0,...,0]*1.0, pred_stitched[0][0,...,0]).item())\n",
    "else:\n",
    "    print(RangeInvariantPsnr(tar_unnorm[0,...,0]*1.0, pred_stitched[0,...,0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = []\n",
    "offsets = []\n",
    "achieved_percentiles = []\n",
    "for ch_idx in range(var.shape[1]):\n",
    "    print('Starting the grid search')\n",
    "    factor_ch, offset_ch, achieved_percentile_ch = grid_search(err[:,ch_idx], var[:,ch_idx], init_delta=10, init_factor=10,around_center=False)\n",
    "    factors.append(factor_ch)\n",
    "    offsets.append(offset_ch)\n",
    "    achieved_percentiles.append(achieved_percentile_ch)\n",
    "    \n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95265e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,ax = plt.subplots(figsize=(7,5))\n",
    "log_scale = True\n",
    "ch_idx = 1\n",
    "sns.histplot(var[:,ch_idx,:4].reshape(-1,), bins=1000,log_scale=log_scale, ax=ax, label='Unscaled_var', stat='probability')\n",
    "sns.histplot(factors[ch_idx]*var[:,ch_idx,:4].reshape(-1,) + offsets[ch_idx], bins=1000,log_scale=log_scale, ax=ax, label='Scaled_var', stat='probability')\n",
    "sns.histplot(err[:,ch_idx], bins=1000,log_scale=log_scale, ax=ax, label='err', stat='probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left_oriented = plot_coverage_plot(var, err, factors, offsets, around_center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_centered = plot_coverage_plot(var, err, factors, offsets, around_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = np.linspace(0,100,100)\n",
    "for col_idx in range(var.shape[1]):\n",
    "    act = data_centered[col_idx]['scaled'][1]\n",
    "    mean_err = np.abs(perfect - act).mean() \n",
    "    max_err = np.abs(perfect - act).max()\n",
    "    print(f'Centered: Channel {col_idx} MAE {mean_err:.2f}, MAX Err {max_err:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = np.linspace(0,100,100)\n",
    "for col_idx in range(var.shape[1]):\n",
    "    act = data_left_oriented[col_idx]['scaled'][1]\n",
    "    mean_err = np.abs(perfect - act).mean() \n",
    "    max_err = np.abs(perfect - act).max()\n",
    "    print(f'LeftOriented: Channel {col_idx} MAE {mean_err:.2f}, MAX Err {max_err:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff97d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeftOriented: Channel 0 MAE 5.19, MAX Err 12.85\n",
    "# LeftOriented: Channel 1 MAE 6.48, MAX Err 13.62\n",
    "# Centered: Channel 0 MAE 9.86, MAX Err 19.88\n",
    "# Centered: Channel 1 MAE 12.47, MAX Err 24.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "inp, _ = val_dset[0]\n",
    "inp = torch.Tensor(inp[None]).cuda()\n",
    "for _ in range(5):\n",
    "    out,_ = model(inp)\n",
    "    outs.append(out.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7964ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(outs[0] - outs[1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1799736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit_vdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
