{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from disentangle.data_loader.evaluation_dloader import EvaluationDloader\n",
    "from disentangle.data_loader.patch_index_manager import GridAlignement\n",
    "from disentangle.nets.model_utils import create_model\n",
    "from nis2pyr.reader import read_nd2file\n",
    "from disentangle.config_utils import load_config\n",
    "import nd2\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_7D(fpath):    \n",
    "    print(f'Loading from {fpath}')\n",
    "    with nd2.ND2File(fpath) as nd2file:\n",
    "        data = read_nd2file(nd2file)\n",
    "    return data\n",
    "\n",
    "def get_best_checkpoint(ckpt_dir):\n",
    "    output = []\n",
    "    for filename in glob.glob(ckpt_dir + \"/*_best.ckpt\"):\n",
    "        output.append(filename)\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2407/D28-M3-S0-L0/16\"\n",
    "ckpt_dir = \"/group/jug/ashesh/training/disentangle/2407/D28-M3-S0-L0/20\"\n",
    "data_dir = '/facility/imganfacusers/Elisa/DIF17/DIF_17_1'\n",
    "fnames = [x for x in sorted(os.listdir(data_dir)) if x.endswith('0001.nd2')]\n",
    "\n",
    "datafile = os.path.join(data_dir, fnames[16])\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_7D(datafile)\n",
    "data = data[0,0,:,1,...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z_idx = 8\n",
    "test_data= data[test_z_idx:test_z_idx+1].copy()\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_data -= config.data.background_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[8][1500:2500,1000:1500], vmax=130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.multicrops_dset import l2\n",
    "def sample_crop(sz):\n",
    "    t = np.random.randint(0, len(test_data))\n",
    "    x = np.random.randint(0, test_data.shape[1] - sz)\n",
    "    y = np.random.randint(0, test_data.shape[2] - sz)\n",
    "    crop = test_data[t, x:x+sz, y:y+sz]\n",
    "    return crop\n",
    "\n",
    "def compute_mean_std():\n",
    "    mean_inp = []\n",
    "    std_inp = []\n",
    "    for _ in range(30000):\n",
    "        crop = sample_crop(config.data.image_size)\n",
    "        mean_inp.append(np.mean(crop))\n",
    "        std_inp.append(np.std(crop))\n",
    "\n",
    "    output_mean = {}\n",
    "    output_std = {}\n",
    "    output_mean['input'] = np.array([np.mean(mean_inp)]).reshape(-1,1,1,1)\n",
    "    output_std['input'] = np.array([l2(std_inp)]).reshape(-1,1,1,1)\n",
    "    \n",
    "    output_mean['target'] = np.tile(output_mean['input'],(1,2,1,1))\n",
    "    output_std['target'] = np.tile(output_std['input'],(1,2,1,1))\n",
    "    return output_mean, output_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict, std_dict = compute_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(config, mean_dict.copy(),std_dict.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_fpath = get_best_checkpoint(ckpt_dir)\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model.eval()\n",
    "_= model.cuda()\n",
    "model.set_params_to_same_device_as(torch.Tensor(1).cuda())\n",
    "\n",
    "print('Loading from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(x):\n",
    "    return (x - mean_dict['input'].squeeze()) / std_dict['input'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_patch = test_data[0,1800:1928,1500:1628]\n",
    "plt.imshow(inp_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_for_different_output_size(inp_patch.shape[0])\n",
    "model.mode_pred = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = normalizer(inp_patch)\n",
    "with torch.no_grad():\n",
    "    out = model(torch.Tensor(inp[None,None]).cuda())\n",
    "out[0].shape\n",
    "plt.imshow(out[0][0,1].cpu().numpy(), vmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = EvaluationDloader(test_data, normalizer, lambda x: x, config.data.image_size, config.data.image_size//4, GridAlignement.Center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_dset_predictions(model, dset, batch_size, mmse_count=1, num_workers=4):\n",
    "    model.reset_for_different_output_size(dset[0].shape[0])\n",
    "    \n",
    "    dloader = DataLoader(dset, pin_memory=False, num_workers=num_workers, shuffle=False, batch_size=batch_size)\n",
    "    predictions = []\n",
    "    predictions_std = []\n",
    "    with torch.no_grad():\n",
    "        for inp in tqdm(dloader):\n",
    "            inp = inp.cuda()\n",
    "            recon_img_list = []\n",
    "            for mmse_idx in range(mmse_count):\n",
    "                imgs, _ = model(inp)\n",
    "                recon_img_list.append(imgs.cpu()[None])\n",
    "\n",
    "            samples = torch.cat(recon_img_list, dim=0)\n",
    "            mmse_imgs = torch.mean(samples, dim=0)\n",
    "            mmse_std = torch.std(samples, dim=0)\n",
    "            predictions.append(mmse_imgs.cpu().numpy())\n",
    "            predictions_std.append(mmse_std.cpu().numpy())\n",
    "    return np.concatenate(predictions, axis=0), np.concatenate(predictions_std, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, pred_std = get_dset_predictions(model, dset, batch_size*10, mmse_count=50, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "pred = stitch_predictions(pred_tiled,dset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.plot_utils import clean_ax\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "_,ax = plt.subplots(figsize=(16,8),ncols=4,nrows=2)\n",
    "ax= ax.reshape(-1,)\n",
    "t_idx =0\n",
    "sz = 300\n",
    "for i in range(len(ax)//2):\n",
    "    hs = np.random.randint(0, test_data.shape[1] - sz)\n",
    "    ws = np.random.randint(0, test_data.shape[2] - sz)\n",
    "    ax[2*i].imshow(test_data[t_idx,hs:hs+sz,ws:ws+sz], vmax=130)\n",
    "    ax[2*i+1].imshow(pred[t_idx,hs:hs+sz,ws:ws+sz,1])\n",
    "    ax[2*i].set_title(f'Input, {t_idx,hs,ws}')\n",
    "    ax[2*i+1].set_title('Puncta Removed')\n",
    "clean_ax(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nature methods plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames:7, [8,1500:2700,500:2200]\n",
    "# fnames:8, [7/8/9/10,:1400,:800] => good\n",
    "# fnames:8, [7,1000:2400,800:2200]\n",
    "# fnames[13], [9/11,900:1500,1000:2400]\n",
    "# fnames[14], [9,2400:3800,700:2000]\n",
    "# fnames[15] [9,2200:4500,500:1500]\n",
    "# fnames[15] [9,300:2400,1000:2800]\n",
    "# fnames[15] [9,500:2400,2800:3900]\n",
    "# fnames[15] [9, 2500:4500,600:1500]\n",
    "# fnames[16] [9,400:1500,500:1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir =os.path.join('/group/jug/ashesh/naturemethods/puncta/', os.path.basename(datafile).replace('.nd2',''))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[0,400:1600,1400:2600], vmax=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file = True\n",
    "hs_region = 400\n",
    "ws_region = 500\n",
    "# hs_region = 400\n",
    "# ws_region = 1400\n",
    "sz = 1200\n",
    "inp_region = test_data[0,hs_region:hs_region+sz,ws_region:ws_region+sz]\n",
    "pred_region = pred[0,hs_region:hs_region+sz,ws_region:ws_region+sz,1]\n",
    "plt.imshow(inp_region, vmax=130)\n",
    "if save_to_file:\n",
    "    fname_prefix = f'z.{test_z_idx}_region.{hs_region}-{ws_region}_sz.{sz}'\n",
    "    print(fname_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'inp.npy', inp_region)\n",
    "# np.save(f'pred.npy', pred_region)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "cropsz = 256\n",
    "\n",
    "_,ax = plt.subplots(figsize=(16,8),ncols=2,nrows=1)\n",
    "ax[0].imshow(inp_region, vmax=130)\n",
    "ax[1].imshow(pred_region)\n",
    "clean_ax(ax)\n",
    "hw_arr= [(900, 310),\n",
    "(628, 313),\n",
    "(758, 80),\n",
    "(605, 49),\n",
    "(424, 815),\n",
    "(449, 541),\n",
    "(92, 684),\n",
    "(587,844)\n",
    "]\n",
    "# hw_arr = [\n",
    "# (35, 50),\n",
    "#  (591,434),\n",
    "#  (911,568),\n",
    "#  (917,395),\n",
    "#  (127,684),\n",
    "#  (662,804),\n",
    "#  (350,179),\n",
    "#  (72,498),\n",
    "# ]\n",
    "for i, loc in enumerate(hw_arr):\n",
    "    (h_s, w_s) = loc\n",
    "    rect = patches.Rectangle((w_s, h_s), cropsz, cropsz, linewidth=1, edgecolor='w', facecolor='none', linestyle='--')\n",
    "    ax[0].add_patch(rect)\n",
    "    # add a number at the top left of the rectangle\n",
    "    ax[0].text(w_s, h_s, str(i+1), color='black', fontsize=14)\n",
    "\n",
    "# adjust the subplot gap\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "if save_to_file:    \n",
    "    fpath = os.path.join(output_dir, f'{fname_prefix}_full_region.png')\n",
    "    # save with high dpi\n",
    "    plt.savefig(fpath, dpi=100)\n",
    "    print('Saved to', fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crops = len(hw_arr)\n",
    "imgsz = 2.1\n",
    "# hw_arr = [(np.random.randint(0, inp_region.shape[0] - cropsz), np.random.randint(0, inp_region.shape[1] - cropsz)) for _ in range(num_crops)]\n",
    "\n",
    "_,ax = plt.subplots(figsize=(num_crops*imgsz,2*imgsz), ncols=num_crops, nrows=2)\n",
    "for i,(h,w) in enumerate(hw_arr):\n",
    "    print(f'{h},{w}')\n",
    "    ax[0,i].imshow(inp_region[h:h+cropsz,w:w+cropsz], vmax=130)\n",
    "    ax[0,i].text(10,30, str(i+1), color='black', fontsize=14)\n",
    "    ax[1,i].imshow(pred_region[h:h+cropsz,w:w+cropsz])\n",
    "    clean_ax(ax[:,i])\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "if save_to_file:\n",
    "    fpath = os.path.join(output_dir, f'{fname_prefix}_crops.png')\n",
    "    plt.savefig(fpath, dpi=100)\n",
    "    print('Saved to', fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 591,434\n",
    "# 911,568\n",
    "# 917,395\n",
    "# 127,684\n",
    "# 662,804\n",
    "# 350,179\n",
    "# 72,498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
