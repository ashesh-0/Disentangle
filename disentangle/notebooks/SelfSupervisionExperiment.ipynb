{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"/group/jug/ashesh/training/disentangle/2503/D17-M3-S0-L0/5\"\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237569",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from disentangle.data_loader.patch_index_manager import TilingMode\n",
    "\n",
    "image_size_for_grid_centers = 64\n",
    "mmse_count = 1\n",
    "custom_image_size = None\n",
    "use_selected_fpaths = ['Test1_Slice2_a/4.nd2']\n",
    "data_t_list = None #[0,1,2,3]\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "\n",
    "save_comparative_plots =False\n",
    "enable_calibration = False\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.All \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "        \n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    if 'validtarget_random_fraction' in config.data:\n",
    "        config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    if 'dump_kth_frame_prediction' in config.training:\n",
    "        config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    if 'input_is_sum' not in config.data:\n",
    "        config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773afc2a",
   "metadata": {},
   "source": [
    "## Replace the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.sox2golgi_v2_rawdata_loader import Sox2GolgiV2ChannelList\n",
    "from disentangle.data_loader.multifile_raw_dloader import SubDsetType\n",
    "import ml_collections\n",
    "with config.unlocked():\n",
    "    config.data.data_type = DataType.TavernaSox2GolgiV2\n",
    "    config.data.subdset_type = SubDsetType.MultiChannel\n",
    "    # all channels: ['555-647', 'GT_Cy5', 'GT_TRITC']\n",
    "    config.data.channel_idx_list = [\n",
    "            Sox2GolgiV2ChannelList.GT_TRITC,Sox2GolgiV2ChannelList.GT_Cy5, Sox2GolgiV2ChannelList.GT_555_647\n",
    "        ]\n",
    "    config.data.num_channels = len(config.data.channel_idx_list)\n",
    "    config.data.input_idx = 2\n",
    "    if use_selected_fpaths is not None:\n",
    "        config.data.use_selected_fpaths = use_selected_fpaths\n",
    "    config.data.target_idx_list = [0, 1]\n",
    "    config.model.num_targets = len(config.data.target_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2Golgi:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.noise_model_ch1_fpath = config.model.noise_model_ch1_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')\n",
    "# config.model.noise_model_ch2_fpath = config.model.noise_model_ch2_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # high val dset \n",
    "# import ml_collections\n",
    "# new_config = ml_collections.ConfigDict(config)\n",
    "# highsnr_val_dset = None\n",
    "# if 'poisson_noise_factor' in new_config.data and new_config.data.poisson_noise_factor > 0:\n",
    "#     new_config.data.poisson_noise_factor = -1\n",
    "#     _, highsnr_val_dset = create_dataset(new_config, data_dir, eval_datasplit_type=eval_datasplit_type,\n",
    "#                                         kwargs_dict=dloader_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_input_frame(idx, dset):\n",
    "    img_tuples, noise_tuples = dset._load_img(idx)\n",
    "    if len(noise_tuples) > 0:\n",
    "        factor = np.sqrt(2) if dset._input_is_sum else 1.0\n",
    "        img_tuples = [x + noise_tuples[0] * factor for x in img_tuples]\n",
    "\n",
    "    inp = 0\n",
    "    for nch in img_tuples:\n",
    "        inp += nch/len(img_tuples)\n",
    "    h_start, w_start = dset._get_deterministic_hw(idx)\n",
    "    return inp, h_start, w_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77918a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from disentangle.analysis.paper_plots import show_for_one, get_plotoutput_dir\n",
    "def get_hwt_start(idx):\n",
    "    h,w,t = val_dset.idx_manager.hwt_from_idx(idx, grid_size=64)\n",
    "    print(h,w,t)\n",
    "    pad = val_dset.per_side_overlap_pixelcount()\n",
    "    h =  h - pad\n",
    "    w = w - pad\n",
    "    return h,w,t\n",
    "\n",
    "def get_crop_from_fulldset_prediction(full_dset_pred, idx, patch_size=256):\n",
    "    h,w,t = get_hwt_start(idx)\n",
    "    return np.swapaxes(full_dset_pred[t,h:h+patch_size,w:w+patch_size].astype(np.float32)[None], 0, 3)[...,0]\n",
    "\n",
    "if save_comparative_plots:\n",
    "    assert eval_datasplit_type == DataSplitType.Test\n",
    "    # CCP vs Microtubules: 925, 659, 502\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_67.tif')\n",
    "    hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M5_Sk0/pred_disentangle_2403_D23-M3-S0-L0_29.tif')\n",
    "\n",
    "    # ER vs Microtubule 853, 859, 332\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_60.tif')\n",
    "\n",
    "    #  ER vs CCP 327, 479, 637, 568\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_59.tif')\n",
    "\n",
    "    #  F-actin vs ER 797\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M10_Sk0/pred_disentangle_2403_D23-M3-S0-L0_15.tif')\n",
    "\n",
    "    idx = 10#np.random.randint(len(val_dset))\n",
    "    patch_size = 500\n",
    "    mmse_count = 50\n",
    "    print(idx)\n",
    "    show_for_one(idx, val_dset, highsnr_val_dset, model, None, mmse_count=mmse_count, patch_size=patch_size, baseline_preds=[\n",
    "        get_crop_from_fulldset_prediction(hdn_usplitdata, idx).astype(np.float32),\n",
    "    ], num_samples=0)\n",
    "\n",
    "\n",
    "    plotsdir = get_plotoutput_dir(ckpt_dir, patch_size, mmse_count=mmse_count)\n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'patch_comparison_{idx}_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217aae0",
   "metadata": {},
   "source": [
    "## Self-supervision\n",
    "Here, we now do some self-supervised finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def zero_mean(x):\n",
    "    return x - torch.mean(x, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "def fix_range(gt, x):\n",
    "    a = torch.sum(gt * x, dim=1, keepdim=True) / (torch.sum(x * x, dim=1, keepdim=True))\n",
    "    return x * a\n",
    "\n",
    "\n",
    "def fix(gt, x):\n",
    "    return fix_range(gt, zero_mean(x))\n",
    "\n",
    "def RangeInvariantPsnr(gt, pred):\n",
    "    \"\"\"\n",
    "    NOTE: Works only for grayscale images.\n",
    "    Adapted from https://github.com/juglab/ScaleInvPSNR/blob/master/psnr.py\n",
    "    It rescales the prediction to ensure that the prediction has the same range as the ground truth.\n",
    "    \"\"\"\n",
    "    assert len(gt.shape) == 3, 'Images must be in shape: (batch,H,W)'\n",
    "    gt = gt.view(len(gt), -1)\n",
    "    pred = pred.view(len(gt), -1)\n",
    "    # ra = (torch.max(gt, dim=1).values - torch.min(gt, dim=1).values) / torch.std(gt, dim=1)\n",
    "    gt_ = zero_mean(gt) / torch.std(gt, dim=1, keepdim=True)\n",
    "    return _PSNR_internal(zero_mean(gt_), fix(gt_, pred), ra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "std_arr = []\n",
    "for i in tqdm(range(len(val_dset))):\n",
    "    inp_1, tar_1  = val_dset[i]\n",
    "    std_arr.append(np.std(inp_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac90982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.asymmetric_transforms import TransformAllChannels, VFlip, Rotate, HFlip\n",
    "transform_types = {0:[VFlip(), Rotate(),HFlip()], 1:[ VFlip(), HFlip(), Rotate()]}\n",
    "transform_all = TransformAllChannels(transform_types)\n",
    "content_std = np.quantile(std_arr, 0.99)\n",
    "idx_list = (np.where(np.array(std_arr) > content_std)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8903d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = val_dset[idx_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1db2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(9,3),ncols=3)\n",
    "ax[0].imshow(inp[0])\n",
    "ax[1].imshow(tar[0])\n",
    "ax[2].imshow(tar[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370392fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.asymmetric_transforms import get_inverse_transforms\n",
    "with torch.no_grad():\n",
    "    pred_one, _ = model(torch.Tensor(inp[None]).cuda())\n",
    "    transformed_pred, applied_transforms = transform_all(pred_one[:,:2])\n",
    "\n",
    "    t_val = 0.7\n",
    "    transformed_inp = transformed_pred[:,:1]* t_val + transformed_pred[:,1:] * (1-t_val)\n",
    "    # transformed_inp = (transformed_inp - transformed_inp.mean().item())/transformed_inp.std().item()\n",
    "    # transformed_inp = transformed_inp*inp.std() + inp.mean()\n",
    "    transformed_inp_pred, _ = model(transformed_inp)\n",
    "    inv_transform = get_inverse_transforms(applied_transforms)\n",
    "    inv_transformed_pred, _  = transform_all(transformed_inp_pred, params_dict = inv_transform, inverse=True)\n",
    "\n",
    "    # \n",
    "    inv_inp = inv_transformed_pred[:,:1]* t_val + inv_transformed_pred[:,1:] * (1-t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Orig', inp.mean(), inp.std())\n",
    "print('Transformed', transformed_inp.mean().item(), transformed_inp.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(21,6),ncols=7,nrows=2)\n",
    "\n",
    "ax[0,0].imshow(inp[0])\n",
    "ax[0,0].set_title('x')\n",
    "\n",
    "# original prediction\n",
    "ax[0,1].set_title('Pred(x)')\n",
    "ax[0,1].imshow(pred_one[0,0].detach().cpu().numpy())\n",
    "ax[1,1].imshow(pred_one[0,1].detach().cpu().numpy())\n",
    "\n",
    "# transformed prediction\n",
    "ax[0,2].set_title('T(Pred(x))')\n",
    "ax[0,2].imshow(transformed_pred[0,0].detach().cpu().numpy())\n",
    "ax[1,2].imshow(transformed_pred[0,1].detach().cpu().numpy())\n",
    "\n",
    "ax[0,3].set_title('x2 = Inp(T(Pred(x)))')\n",
    "ax[0,3].imshow(transformed_inp[0,0].detach().cpu().numpy())\n",
    "\n",
    "ax[0,4].set_title('$T^{-1}$(Pred(x2))')\n",
    "ax[0,4].imshow(inv_transformed_pred[0,0].detach().cpu().numpy())\n",
    "ax[1,4].imshow(inv_transformed_pred[0,1].detach().cpu().numpy())\n",
    "\n",
    "ax[0,5].set_title('Target')\n",
    "ax[0,5].imshow(tar[0])\n",
    "ax[1,5].imshow(tar[1])\n",
    "\n",
    "ax[0,5].set_ylabel('Channel 1')\n",
    "ax[1,5].set_ylabel('Channel 2')\n",
    "# make the label right side\n",
    "ax[0,5].yaxis.set_label_position(\"right\")\n",
    "ax[1,5].yaxis.set_label_position(\"right\")\n",
    "ax[1,0].axis('off')\n",
    "ax[1,3].axis('off')\n",
    "\n",
    "ax[0,6].set_title('$x_{rec}$ = Inp($T^{-1}$(Pred(x2)))')\n",
    "ax[0,6].imshow(inv_inp[0,0].detach().cpu().numpy())\n",
    "ax[1,6].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "# from disentangle.analysis.stitch_prediction import get_predictions as get_dset_predictions\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.where(logvar_tiled.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "pred = stitch_predictions(pred_tiled,val_dset, )\n",
    "if len(np.unique(logvar_tiled)) == 1:\n",
    "    logvar = None\n",
    "else:\n",
    "    logvar = stitch_predictions(logvar_tiled,val_dset, )\n",
    "pred_std = stitch_predictions(pred_std_tiled,val_dset, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_list_prediction = isinstance(pred, list)\n",
    "tar_unnorm = (val_dset._data if not is_list_prediction else [val_dset.dsets[i]._data for i in range(len(val_dset.dsets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67288f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66deb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "#     pred = pred[...,:len(config.data.target_idx_list)]\n",
    "#     pred_std = pred_std[...,:len(config.data.target_idx_list)]\n",
    "nTar = pred[0].shape[-1]\n",
    "\n",
    "if \"target_idx_list\" in config.data and config.data.target_idx_list is not None:\n",
    "    nTar =len(config.data.target_idx_list)\n",
    "    pred = pred[..., :len(config.data.target_idx_list)] if not is_list_prediction else [pred[i][..., :len(config.data.target_idx_list)] for i in range(len(pred))]\n",
    "    pred_std = pred_std[...,:len(config.data.target_idx_list)] if not is_list_prediction else [pred_std[i][..., :len(config.data.target_idx_list)] for i in range(len(pred_std))]\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp_unnorm = [x[...,config.data.input_idx] for x in tar_unnorm]\n",
    "    tar_unnorm = [x[...,:nTar] for x in tar_unnorm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3602c8",
   "metadata": {},
   "source": [
    "### Optimal Estimation of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ec0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.psnr import RangeInvariantPsnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mean_psnr_arr = []\n",
    "std_psnr_arr = []\n",
    "t_values = np.arange(0.0,1.0, 0.05) \n",
    "for t in tqdm(t_values):\n",
    "    inp_tiled = [(t *pred[i][...,0] + (1-t)*pred[i][...,1]) for i in range(len(pred))]\n",
    "    psnr_values = [RangeInvariantPsnr(inp_unnorm[i]*1.0, inp_tiled[i]).item() for i in range(len(inp_unnorm))]\n",
    "    mean_psnr_arr.append(np.mean(psnr_values))\n",
    "    std_psnr_arr.append(np.std(psnr_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e04e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(mean_psnr_arr)\n",
    "print(f'Best t value: {t_values[best_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_values, mean_psnr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71660b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax  = plt.subplots(figsize=(8,4),ncols=2)\n",
    "ax[0].imshow(inp_tiled[0][0])\n",
    "ax[1].imshow(inp_unnorm[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0,-ignored_pixels:,-ignored_pixels:,].std() ==0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "# actual_ignored_pixels = print_ignored_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23db3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean[\"target\"], model.data_std[\"target\"]\n",
    "sep_mean = sep_mean.squeeze().reshape(1, 1, 1, -1)\n",
    "sep_std = sep_std.squeeze().reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape, sep_mean.shape, sep_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_list_prediction:\n",
    "    pred_unnorm = [pred[i] * sep_std.cpu().numpy() + sep_mean.cpu().numpy() for i in range(len(pred))]\n",
    "else:\n",
    "    pred_unnorm = pred * sep_std.cpu().numpy() + sep_mean.cpu().numpy()\n",
    "\n",
    "if ckpt_dir == '/group/jug/ashesh/training/disentangle/2404/D17-M3-S0-L8/4':\n",
    "    print(\"Reversing the order of channels\")\n",
    "    pred_unnorm = [x[...,::-1] for x in pred_unnorm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac44cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import compute_high_snr_stats\n",
    "stats_dict = compute_high_snr_stats(tar_unnorm, pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "ncols = pred_unnorm[0].shape[-1]\n",
    "imgsz = 4\n",
    "_,ax = plt.subplots(figsize=((1+ncols)*imgsz,2*imgsz),nrows=2,ncols=ncols + 1)\n",
    "img_idx = np.random.randint(len(tar_unnorm))\n",
    "sz = 600\n",
    "\n",
    "hs = np.random.randint(tar_unnorm[0].shape[1]-sz)\n",
    "ws = np.random.randint(tar_unnorm[0].shape[2]-sz)\n",
    "print(img_idx, hs, ws)\n",
    "\n",
    "for i in range(ncols):\n",
    "    vmin = tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i].min()\n",
    "    vmax = tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i].max()\n",
    "    ax[0,i+1].imshow(tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i], vmin=vmin, vmax=vmax)\n",
    "    ax[1,i+1].imshow(pred_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz,i], vmin=vmin, vmax=vmax)\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp = inp_unnorm[img_idx][0]\n",
    "else:\n",
    "    inp = np.mean(tar_unnorm[img_idx][0], axis=-1)\n",
    "\n",
    "    \n",
    "ax[0,0].imshow(inp)\n",
    "rect = patches.Rectangle((ws, hs), sz,sz, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0,0].add_patch(rect)\n",
    "\n",
    "ax[1,0].imshow(inp[hs:hs+sz, ws:ws+sz])\n",
    "plt.subplots_adjust(wspace=0.03, hspace=0.03)\n",
    "ax[0,0].set_title('Input')\n",
    "twinx = ax[0,-1].twinx()\n",
    "twinx.set_ylabel('Target')\n",
    "clean_ax(twinx)\n",
    "twinx = ax[1,-1].twinx()\n",
    "clean_ax(twinx)\n",
    "twinx.set_ylabel('Prediction')\n",
    "clean_ax(ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189205d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba25fd8",
   "metadata": {},
   "source": [
    "## SSL finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from finetunesplit.loss import SSL_loss\n",
    "def pred_func(inp):\n",
    "    return model(inp)[0][:,:2]\n",
    "\n",
    "\n",
    "# define a learnable scalar and an offset \n",
    "scalar1 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset1 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "\n",
    "scalar2 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "mixing_ratio = torch.nn.Parameter(torch.tensor(0.7).cuda())\n",
    "# define an optimizer\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "opt = torch.optim.Adamax([scalar1, offset1, scalar2, offset2, mixing_ratio], lr=1e-3, weight_decay=0)\n",
    "\n",
    "max_step_count = 50000\n",
    "batch_size = 16\n",
    "\n",
    "loss_arr = []\n",
    "best_loss = 1e6\n",
    "best_scalars = None\n",
    "best_offsets = None\n",
    "\n",
    "scalar1_arr = []\n",
    "offset1_arr = []\n",
    "\n",
    "scalar2_arr = []\n",
    "offset2_arr = []\n",
    "mixing_ratio_arr= []\n",
    "cnt = 0\n",
    "while True:\n",
    "    dloader = DataLoader(val_dset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    for i, (inp, tar) in tqdm(enumerate(dloader)):\n",
    "        if i >= max_step_count:\n",
    "            break\n",
    "        inp = inp.cuda()\n",
    "        # reset the gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        loss_dict = SSL_loss(pred_func, inp, transform_all, mixing_ratio=mixing_ratio, scalar1=scalar1, offset1=offset1, scalar2=scalar2, offset2=offset2)\n",
    "        loss = loss_dict['loss_inp']\n",
    "        loss.backward()\n",
    "        loss_arr.append(loss.item())\n",
    "        \n",
    "        scalar1_arr.append(scalar1.item())\n",
    "        offset1_arr.append(offset1.item())\n",
    "        scalar2_arr.append(scalar2.item())\n",
    "        offset2_arr.append(offset2.item())\n",
    "        cnt += len(inp)\n",
    "        mixing_ratio_arr.append(mixing_ratio.item())\n",
    "        opt.step()\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            print(f'Loss: {loss.item():.2f}')\n",
    "            best_scalar = [scalar1.item(), scalar2.item()]\n",
    "            best_offset = [offset1.item(), offset2.item()]\n",
    "        # print(f'Loss: {loss.item():.2f}')\n",
    "        if cnt >= max_step_count:\n",
    "            break\n",
    "    if cnt >= max_step_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b84afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.Series(loss_arr).rolling(5).mean().plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c02845",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scalar, best_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54563870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDataset:\n",
    "    def __init__(self, dset, scalar, offset):\n",
    "        self.dset = dset\n",
    "        self.scalar = scalar\n",
    "        self.offset = offset\n",
    "    def __len__(self):\n",
    "        return len(self.dset)\n",
    "    def __getitem__(self, idx):\n",
    "        inp, tar = self.dset[idx]\n",
    "        return inp * self.scalar + self.offset, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95550dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_val_dset = ScaledDataset(val_dset, best_scalar[0], best_offset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9493e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, scaled_val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stitch_predictions(pred_tiled,val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(pred[0][0,...,0])\n",
    "ax[1].imshow(pred[0][0,...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4388ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import avg_range_inv_psnr\n",
    "tar0 = [x[...,0] for x in tar_unnorm]\n",
    "pred0 = [x[...,0] for x in pred]\n",
    "\n",
    "tar1 = [x[...,1] for x in tar_unnorm]\n",
    "pred1 = [x[...,1] for x in pred]\n",
    "psnr_ch0 = avg_range_inv_psnr(np.concatenate(tar0,axis=0), np.concatenate(pred0, axis=0))\n",
    "psnr_ch1 = avg_range_inv_psnr(np.concatenate(tar1,axis=0), np.concatenate(pred1, axis=0))\n",
    "\n",
    "# stats_dict = compute_high_snr_stats(tar_unnorm, pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_ch0, psnr_ch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4b601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
