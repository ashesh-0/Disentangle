{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c90081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_normalization_utils import get_input_normalized, get_input_unnormalized\n",
    "from disentangle.data_loader.patch_index_manager import TilingMode\n",
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "from disentangle.data_loader.sox2golgi_v2_rawdata_loader import Sox2GolgiV2ChannelList\n",
    "from disentangle.data_loader.multifile_raw_dloader import SubDsetType\n",
    "import ml_collections\n",
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from disentangle.analysis.paper_plots import show_for_one, get_plotoutput_dir\n",
    "from disentangle.analysis.ssl_normalization_utils import normalize_input\n",
    "from finetunesplit.asymmetric_transforms import TransformAllChannels, VFlip, Rotate, HFlip, DeepinvTransform\n",
    "import deepinv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ckpt_dir = '/group/jug/ashesh/training/disentangle/2504/D21-M3-S0-L0/14'\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2504/D21-M3-S0-L2/3'\n",
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2503/D17-M3-S0-L0/5\"\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2404/D21-M3-S0-L8/1'\n",
    "assert os.path.exists(ckpt_dir)\n",
    "image_size_for_grid_centers = None\n",
    "mmse_count = 2\n",
    "custom_image_size = None\n",
    "\n",
    "use_selected_fpaths = None#['Test1_Slice2_a/4.nd2']\n",
    "use_first_k_images = 1\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "real_input = True\n",
    "\n",
    "save_comparative_plots =False\n",
    "enable_calibration = False\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "\n",
    "\n",
    "# augmentation related\n",
    "aug_theta_max = 0\n",
    "aug_theta_z_max = 0\n",
    "aug_shift_max=0.0\n",
    "\n",
    "# finetuningng related \n",
    "max_step_count_step1 = 20000\n",
    "max_step_count_step2 =20000 \n",
    "skip_pixels = 4\n",
    "lr_step1 = 1e-3\n",
    "lr_step2 = 1e-5\n",
    "lookback = 10\n",
    "k_augmentations=8\n",
    "optimaization_mode = 'twostep'\n",
    "k_moment_value = 3\n",
    "\n",
    "outputdir = '/group/jug/ashesh/finetuning_results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_t_list = None\n",
    "if use_first_k_images is not None:\n",
    "    data_t_list = np.arange(use_first_k_images).tolist()\n",
    "\n",
    "assert optimaization_mode in ['onestep', 'twostep'], f\"Invalid optimization mode: {optimaization_mode}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "        \n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    if 'validtarget_random_fraction' in config.data:\n",
    "        config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    if 'dump_kth_frame_prediction' in config.training:\n",
    "        config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    if 'input_is_sum' not in config.data:\n",
    "        config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773afc2a",
   "metadata": {},
   "source": [
    "## Replace the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with config.unlocked():\n",
    "    if config.data.data_type in [DataType.TavernaSox2Golgi]:\n",
    "        config.data.data_type = DataType.TavernaSox2GolgiV2\n",
    "        config.data.subdset_type = SubDsetType.MultiChannel\n",
    "        if real_input:\n",
    "            print('Real Input being used')\n",
    "            # all channels: ['555-647', 'GT_Cy5', 'GT_TRITC']\n",
    "            config.data.channel_idx_list = [\n",
    "                    Sox2GolgiV2ChannelList.GT_TRITC,Sox2GolgiV2ChannelList.GT_Cy5, Sox2GolgiV2ChannelList.GT_555_647\n",
    "                ]\n",
    "            config.data.input_idx = 2\n",
    "        else:\n",
    "            print('Real Input not being used')\n",
    "            config.data.channel_idx_list = [\n",
    "                    Sox2GolgiV2ChannelList.GT_TRITC,Sox2GolgiV2ChannelList.GT_Cy5\n",
    "                ]\n",
    "            config.data.input_idx = None\n",
    "\n",
    "        config.data.num_channels = len(config.data.channel_idx_list)\n",
    "    if use_selected_fpaths is not None:\n",
    "        config.data.use_selected_fpaths = use_selected_fpaths\n",
    "    config.data.target_idx_list = [0, 1]\n",
    "    config.model.num_targets = len(config.data.target_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2Golgi:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.noise_model_ch1_fpath = config.model.noise_model_ch1_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')\n",
    "# config.model.noise_model_ch2_fpath = config.model.noise_model_ch2_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.core.tiff_reader import save_tiff\n",
    "# save_tiff('/group/jug/ashesh/data/sox2_one_img.tiff', val_dset.dsets[0]._data[0,...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # high val dset \n",
    "# import ml_collections\n",
    "# new_config = ml_collections.ConfigDict(config)\n",
    "# highsnr_val_dset = None\n",
    "# if 'poisson_noise_factor' in new_config.data and new_config.data.poisson_noise_factor > 0:\n",
    "#     new_config.data.poisson_noise_factor = -1\n",
    "#     _, highsnr_val_dset = create_dataset(new_config, data_dir, eval_datasplit_type=eval_datasplit_type,\n",
    "#                                         kwargs_dict=dloader_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77918a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert save_comparative_plots is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217aae0",
   "metadata": {},
   "source": [
    "## Self-supervision\n",
    "Here, we now do some self-supervised finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "from deepinv.transform.projective import Homography\n",
    "from finetunesplit.asymmetric_transforms import get_inverse_transforms\n",
    "from disentangle.core.psnr import RangeInvariantPsnr\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ef5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_channels = np.mean(pred_tiled, axis=(2,3)).mean(axis=0)\n",
    "std_channels = np.std(pred_tiled, axis=(2,3)).mean(axis=0)\n",
    "mean_channels, std_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647410cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.loss.ssl_finetuning import get_stats_loss_func\n",
    "stats_loss_func = get_stats_loss_func(pred_tiled, k_moment_value)\n",
    "stats_loss_func(torch.Tensor(pred_tiled[:15]))\n",
    "# def k_moment(data, k):\n",
    "#     # data: N x C x H x W\n",
    "#     dif = data - np.mean(data, axis=(2,3))[...,None, None]\n",
    "#     moment = np.mean(dif**k, axis=(2,3))\n",
    "#     neg_vals = moment < 0\n",
    "#     moment = np.power(np.abs(moment), 1/k)\n",
    "#     moment[neg_vals] = -moment[neg_vals]\n",
    "#     return moment.mean(axis=0)\n",
    "\n",
    "# k_moment(pred_tiled, 2)\n",
    "# import torch\n",
    "# def get_stats_loss_func():\n",
    "#     mean_channels = torch.Tensor(np.mean(pred_tiled, axis=(2,3)).mean(axis=0))\n",
    "#     std_channels = torch.Tensor(np.std(pred_tiled, axis=(2,3)).mean(axis=0))\n",
    "#     def stats_loss_func(two_channel_prediction):\n",
    "#         mean_pred = torch.mean(two_channel_prediction, dim=(2,3)).mean(dim=0)\n",
    "#         std_pred = torch.std(two_channel_prediction, dim=(2,3)).mean(dim=0)\n",
    "#         device = std_pred.device\n",
    "#         print('est_moment', mean_pred)\n",
    "#         print('actual_moment', mean_channels)\n",
    "#         mean_err =  mean_channels.to(device) - mean_pred\n",
    "#         mean_err = torch.clip(mean_err, min=0)\n",
    "#         print('est_moment', std_pred)\n",
    "#         print('actual_moment', std_channels)\n",
    "\n",
    "#         std_err = std_channels.to(device) - std_pred\n",
    "#         std_err = torch.clip(std_err, min=0)\n",
    "#         mean_loss = torch.mean(mean_err)\n",
    "#         std_loss = torch.mean(std_err)\n",
    "#         return  mean_loss + std_loss\n",
    "#     return stats_loss_func\n",
    "# stats_loss_func = get_stats_loss_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10cb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.where(logvar_tiled.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "pred = stitch_predictions(pred_tiled,val_dset, )\n",
    "if len(np.unique(logvar_tiled)) == 1:\n",
    "    logvar = None\n",
    "else:\n",
    "    logvar = stitch_predictions(logvar_tiled,val_dset, )\n",
    "pred_std = stitch_predictions(pred_std_tiled,val_dset, )\n",
    "\n",
    "pred_original = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_list_prediction = isinstance(pred, list)\n",
    "tar_unnorm = (val_dset._data if not is_list_prediction else [val_dset.dsets[i]._data for i in range(len(val_dset.dsets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67288f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66deb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTar = pred[0].shape[-1]\n",
    "if \"target_idx_list\" in config.data and config.data.target_idx_list is not None:\n",
    "    nTar =len(config.data.target_idx_list)\n",
    "    # pred = pred[..., :len(config.data.target_idx_list)] if not is_list_prediction else [pred[i][..., :len(config.data.target_idx_list)] for i in range(len(pred))]\n",
    "    # pred_std = pred_std[...,:len(config.data.target_idx_list)] if not is_list_prediction else [pred_std[i][..., :len(config.data.target_idx_list)] for i in range(len(pred_std))]\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp_unnorm = [x[...,config.data.input_idx] for x in tar_unnorm]\n",
    "    tar_unnorm = [x[...,:nTar] for x in tar_unnorm]\n",
    "else:\n",
    "    inp_unnorm = [x.mean(axis=-1) for x in tar_unnorm]\n",
    "\n",
    "actual_input = normalize_input(inp_unnorm, val_dset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3602c8",
   "metadata": {},
   "source": [
    "### Optimal Estimation of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mean_psnr_arr = []\n",
    "std_psnr_arr = []\n",
    "t_values = np.arange(0.0,1.0, 0.05) \n",
    "for t in tqdm(t_values):\n",
    "    inp_tiled = [(t *pred[i][...,0] + (1-t)*pred[i][...,1]) for i in range(len(pred))]\n",
    "    psnr_values = [RangeInvariantPsnr(inp_unnorm[i]*1.0, inp_tiled[i]).item() for i in range(len(inp_unnorm))]\n",
    "    mean_psnr_arr.append(np.mean(psnr_values))\n",
    "    std_psnr_arr.append(np.std(psnr_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e04e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(mean_psnr_arr)\n",
    "best_t_estimate = t_values[best_idx]\n",
    "print(f'Best t value: {best_t_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_values, mean_psnr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0,-ignored_pixels:,-ignored_pixels:,].std() ==0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23db3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean[\"target\"], model.data_std[\"target\"]\n",
    "sep_mean = sep_mean.squeeze().reshape(1, 1, 1, -1)\n",
    "sep_std = sep_std.squeeze().reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape, sep_mean.shape, sep_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unnorm_pred(pred_arr):\n",
    "    if is_list_prediction:\n",
    "        pred_unnorm = [pred_arr[i] * sep_std.cpu().numpy() + sep_mean.cpu().numpy() for i in range(len(pred_arr))]\n",
    "    else:\n",
    "        pred_unnorm = pred_arr * sep_std.cpu().numpy() + sep_mean.cpu().numpy()\n",
    "    return pred_unnorm\n",
    "\n",
    "def normalize_channels(channel_arr):\n",
    "    if is_list_prediction:\n",
    "        pred_unnorm = [(channel_arr[i] - sep_mean.cpu().numpy())/sep_std.cpu().numpy() for i in range(len(channel_arr))]\n",
    "    else:\n",
    "        pred_unnorm = (channel_arr - sep_mean.cpu().numpy())/ sep_std.cpu().numpy()\n",
    "    return pred_unnorm\n",
    "\n",
    "pred_unnorm = get_unnorm_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac44cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import compute_high_snr_stats\n",
    "stats_dict = compute_high_snr_stats(tar_unnorm, pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764818c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_input = get_input_normalized(pred_original,best_t_estimate, channel_pos='last')\n",
    "print('MSE-input', ' '.join([f'{np.mean((gt_tmp - pred_tmp)**2):.2f}' for gt_tmp,pred_tmp in zip(actual_input, estimated_input)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_inp, std_inp = val_dset.dsets[0].get_mean_std_for_input()\n",
    "mean_inp = mean_inp.reshape(-1,)[0]\n",
    "std_inp = std_inp.reshape(-1,)[0]\n",
    "(mean_inp, std_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_one_sample\n",
    "img_idx, hs, ws = plot_one_sample(normalize_channels(tar_unnorm), pred, inp_unnorm, config, best_t_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba25fd8",
   "metadata": {},
   "source": [
    "## SSL finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from finetunesplit.loss import SSL_loss\n",
    "from disentangle.loss.ssl_finetuning import finetune_two_forward_passes\n",
    "from finetunesplit.asymmetric_transforms import TransformAllChannels, VFlip, Rotate, HFlip, DeepinvTransform\n",
    "from deepinv.transform.projective import Homography\n",
    "\n",
    "def reload():\n",
    "    print('Loading checkpoint from', ckpt_fpath)\n",
    "    checkpoint = torch.load(ckpt_fpath)\n",
    "    _ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_types = {0:[VFlip(), Rotate(),HFlip()], 1:[ VFlip(), HFlip(), Rotate()]}\n",
    "if aug_shift_max > 0 or aug_theta_z_max or aug_theta_max > 0:\n",
    "    trans_homo = Homography(n_trans = 1, zoom_factor_min=1.0, theta_max=aug_theta_max, \n",
    "                            theta_z_max=aug_theta_z_max, \n",
    "                            skew_max=0, \n",
    "                            shift_max=aug_shift_max,\n",
    "                            x_stretch_factor_min = 1,\n",
    "                            y_stretch_factor_min = 1, device = model.device)\n",
    "    transform_types[0].append(DeepinvTransform(trans_homo))\n",
    "    transform_types[1].append(DeepinvTransform(trans_homo))\n",
    "\n",
    "\n",
    "transform_all = TransformAllChannels(transform_types)\n",
    "\n",
    "# define a learnable scalar and an offset \n",
    "factor1 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset1 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "\n",
    "factor2 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "mixing_ratio = torch.nn.Parameter(torch.tensor(best_t_estimate).cuda())\n",
    "\n",
    "if optimaization_mode == 'twostep':\n",
    "    optimization_params = [factor1, offset1]\n",
    "    finetuning_output_dict = finetune_two_forward_passes(model, val_dset, transform_all, \n",
    "                                                        max_step_count=max_step_count_step1, \n",
    "                                                        batch_size=batch_size, \n",
    "                                                        skip_pixels=skip_pixels,\n",
    "                                    scalar_params_dict={'factor1':factor1, 'offset1':offset1, 'factor2':factor2, 'offset2':offset2, 'mixing_ratio':mixing_ratio},\n",
    "                                    optimization_params_dict={'lr':lr_step1, 'parameters': optimization_params},\n",
    "                                    lookback=lookback,\n",
    "                                    k_augmentations=k_augmentations,\n",
    "                                    stats_enforcing_loss_fn=lambda x : stats_loss_func(x)\n",
    "                                    )\n",
    "    best_factors = finetuning_output_dict['best_factors']\n",
    "    best_offsets = finetuning_output_dict['best_offsets']\n",
    "elif optimaization_mode == 'onestep':\n",
    "    print('Skipping the first optimization step')\n",
    "    best_factors = [factor1.item(), factor2.item()]\n",
    "    best_offsets = [offset1.item(), offset2.item()]\n",
    "\n",
    "print(best_factors, best_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "subdir = '_'.join(ckpt_dir.split('/')[-3:])\n",
    "subsubdir = f'{optimaization_mode}_B-{batch_size}_lr-{lr_step1}-{lr_step2}_kaug-{k_augmentations}_maxstep-{max_step_count_step1}-{max_step_count_step2}_ang-{aug_theta_max}_angz-{aug_theta_z_max}_shift-{aug_shift_max}'\n",
    "timesubdir = datetime.now().strftime(\"%Y%m%d\")\n",
    "direc = os.path.join(subdir,subsubdir,timesubdir)\n",
    "print(direc)\n",
    "if optimaization_mode == 'twostep':\n",
    "    fpath = os.path.join(outputdir, direc, 'after_step1.ckpt')\n",
    "    os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "    # save the model weights.\n",
    "    torch.save(model.state_dict(), fpath)\n",
    "    print(f'Saved the model weights to {fpath}')\n",
    "    # save the factors and offsets\n",
    "    fpath = os.path.join(outputdir, direc, 'factors_offsets.txt')\n",
    "    with open(fpath, 'w') as f:\n",
    "        f.write(f'Factor1{best_factors[0]} Offset1{best_offsets[0]} Factor2{best_factors[1]} Offset2{best_offsets[1]}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0462285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_finetuning_loss\n",
    "if optimaization_mode == 'twostep':\n",
    "    plot_finetuning_loss(finetuning_output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54563870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDataset:\n",
    "    def __init__(self, dset, scalar, offset):\n",
    "        self.dset = dset\n",
    "        self.scalar = scalar\n",
    "        self.offset = offset\n",
    "    def __len__(self):\n",
    "        return len(self.dset)\n",
    "    def __getitem__(self, idx):\n",
    "        inp, tar = self.dset[idx]\n",
    "        return inp * self.scalar + self.offset, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95550dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_val_dset = ScaledDataset(val_dset, best_factors[0], best_offsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9493e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, scaled_val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stitch_predictions(pred_tiled,val_dset)\n",
    "pred_unnorm = get_unnorm_pred(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff58347",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_one_sample(normalize_channels(tar_unnorm), pred, inp_unnorm, config, best_t_estimate, img_idx=img_idx, hs=hs, ws=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4388ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import avg_range_inv_psnr\n",
    "tar0 = [x[...,0] for x in tar_unnorm]\n",
    "pred0 = [x[...,0] for x in pred_unnorm]\n",
    "\n",
    "tar1 = [x[...,1] for x in tar_unnorm]\n",
    "pred1 = [x[...,1] for x in pred_unnorm]\n",
    "psnr_ch0 = avg_range_inv_psnr(np.concatenate(tar0,axis=0), np.concatenate(pred0, axis=0))\n",
    "psnr_ch1 = avg_range_inv_psnr(np.concatenate(tar1,axis=0), np.concatenate(pred1, axis=0))\n",
    "\n",
    "estimated_input = get_input_normalized(pred,best_t_estimate, channel_pos='last')\n",
    "mse_input_str = 'MSE-input ' +' '.join([f'{np.mean((gt_tmp - pred_tmp)**2):.2f}' for gt_tmp,pred_tmp in zip(actual_input, estimated_input)])\n",
    "print(mse_input_str)\n",
    "print('PSNR', psnr_ch0, psnr_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cdba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_range_inv_psnr(np.concatenate(tar0[:1],axis=0), np.concatenate(pred0[:1], axis=0)),avg_range_inv_psnr(np.concatenate(tar1[:1],axis=0), np.concatenate(pred1[:1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1:{best_factors[0]:.2f} Off1:{best_offsets[0]:.2f} F2:{best_factors[1]:.2f} Off2:{best_offsets[1]:.2f}\\t\\t PSNR: {psnr_ch0[0]:.2f} {psnr_ch1[0]:.2f} {mse_input_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Target 2 Min:{tar1[0].min():.1f}, Max:{tar1[0].max():.1f}, Mean:{tar1[0].mean():.1f}, Std:{tar1[0].std():.1f}')\n",
    "print(f'Pred 2 Min:{pred1[0].min():.1f}, Max:{pred1[0].max():.1f}, Mean:{pred1[0].mean():.1f}, Std:{pred1[0].std():.1f}')\n",
    "print(f'Target 1 Min:{tar0[0].min():.1f}, Max:{tar0[0].max():.1f}, Mean:{tar0[0].mean():.1f}, Std:{tar0[0].std():.1f}')\n",
    "print(f'Pred 1 Min:{pred0[0].min():.1f}, Max:{pred0[0].max():.1f}, Mean:{pred0[0].mean():.1f}, Std:{pred0[0].std():.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6429bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload()\n",
    "# batch_size = 128\n",
    "print(max_step_count_step2)\n",
    "# best_factors[0], best_offsets[0]\n",
    "finetuning_output_dict = finetune_two_forward_passes(model, val_dset, transform_all, max_step_count=max_step_count_step2, \n",
    "                                                     batch_size=batch_size, skip_pixels=skip_pixels,\n",
    "                                scalar_params_dict={'factor1':torch.Tensor([best_factors[0]]).cuda(), \n",
    "                                                    'offset1':torch.Tensor([best_offsets[0]]).cuda(), \n",
    "                                                    'factor2':torch.Tensor([best_factors[1]]).cuda(), \n",
    "                                                    'offset2':torch.Tensor([best_offsets[1]]).cuda(), \n",
    "                                                    'mixing_ratio':mixing_ratio},\n",
    "                                optimization_params_dict={'lr':lr_step2, \n",
    "                                                        #   'parameters': model.first_bottom_up.parameters()\n",
    "                                                        'parameters': model.parameters()\n",
    "                                                          },\n",
    "                                lookback=lookback,\n",
    "                                                                k_augmentations=k_augmentations,\n",
    "                                                                stats_enforcing_loss_fn=lambda x : stats_loss_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_finetuning_loss\n",
    "plot_finetuning_loss(finetuning_output_dict, loss_rolling=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c742ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, scaled_val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312917f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stitch_predictions(pred_tiled,val_dset)\n",
    "pred_unnorm = get_unnorm_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf71a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(pred[0][0,...,0])\n",
    "ax[1].imshow(pred[0][0,...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_one_sample(normalize_channels(tar_unnorm), pred, inp_unnorm, config, best_t_estimate, img_idx=img_idx, hs=hs, ws=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import avg_range_inv_psnr\n",
    "tar0 = [x[...,0] for x in tar_unnorm]\n",
    "pred0 = [x[...,0] for x in pred_unnorm]\n",
    "\n",
    "tar1 = [x[...,1] for x in tar_unnorm]\n",
    "pred1 = [x[...,1] for x in pred_unnorm]\n",
    "psnr_ch0 = avg_range_inv_psnr(np.concatenate(tar0,axis=0), np.concatenate(pred0, axis=0))\n",
    "psnr_ch1 = avg_range_inv_psnr(np.concatenate(tar1,axis=0), np.concatenate(pred1, axis=0))\n",
    "\n",
    "estimated_input = get_input_normalized(pred,best_t_estimate, channel_pos='last')\n",
    "mse_input_str = 'MSE-input ' +' '.join([f'{np.mean((gt_tmp - pred_tmp)**2):.2f}' for gt_tmp,pred_tmp in zip(actual_input, estimated_input)])\n",
    "print(mse_input_str)\n",
    "print('PSNR', psnr_ch0, psnr_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ccd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1:{best_factors[0]:.2f} Off1:{best_offsets[0]:.2f} F2:{best_factors[1]:.2f} Off2:{best_offsets[1]:.2f}\\t\\t PSNR: {psnr_ch0[0]:.2f} {psnr_ch1[0]:.2f} {mse_input_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff722a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_range_inv_psnr(np.concatenate(tar0[:1],axis=0), np.concatenate(pred0[:1], axis=0)),avg_range_inv_psnr(np.concatenate(tar1[:1],axis=0), np.concatenate(pred1[:1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(outputdir, direc, 'after_step2.ckpt')\n",
    "os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "# save the model weights.\n",
    "torch.save(model.state_dict(), fpath)\n",
    "print(f'Saved the model weights to {fpath}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03574c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_raw = val_dset.dsets[0]._data[0,400:656,256:512,0]\n",
    "# plt.imshow(test_img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db74f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finetunesplit.aug_patch_shuffle import GridShuffle\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# trans = GridShuffle(256, 128)\n",
    "# test_img = torch.Tensor(test_img_raw[None, None]*1.0)\n",
    "# pred, ddict = trans(test_img)\n",
    "# trans.set_params(ddict['inverse']['shuffle_order'])\n",
    "# inv_pred, _ = trans(pred)\n",
    "# _, ax = plt.subplots(figsize=(15,5),ncols=3)\n",
    "# ax[0].imshow(test_img[0,0])\n",
    "# ax[1].imshow(pred[0,0])\n",
    "# ax[2].imshow(inv_pred[0,0])\n",
    "# ax[0].set_title('Original')\n",
    "# ax[1].set_title('Shuffled')\n",
    "# ax[2].set_title('Inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62e6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
