{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c90081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_normalization_utils import get_input_normalized, get_input_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"/group/jug/ashesh/training/disentangle/2503/D17-M3-S0-L0/5\"\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2404/D21-M3-S0-L8/1'\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237569",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from disentangle.data_loader.patch_index_manager import TilingMode\n",
    "\n",
    "image_size_for_grid_centers = 64\n",
    "mmse_count = 2\n",
    "custom_image_size = None\n",
    "use_selected_fpaths = None#['Test1_Slice2_a/4.nd2']\n",
    "data_t_list = [0]\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "real_input = True\n",
    "\n",
    "save_comparative_plots =False\n",
    "enable_calibration = False\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "        \n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    if 'validtarget_random_fraction' in config.data:\n",
    "        config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    if 'dump_kth_frame_prediction' in config.training:\n",
    "        config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    if 'input_is_sum' not in config.data:\n",
    "        config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773afc2a",
   "metadata": {},
   "source": [
    "## Replace the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.sox2golgi_v2_rawdata_loader import Sox2GolgiV2ChannelList\n",
    "from disentangle.data_loader.multifile_raw_dloader import SubDsetType\n",
    "import ml_collections\n",
    "with config.unlocked():\n",
    "    if config.data.data_type in [DataType.TavernaSox2Golgi]:\n",
    "        config.data.data_type = DataType.TavernaSox2GolgiV2\n",
    "        config.data.subdset_type = SubDsetType.MultiChannel\n",
    "        if real_input:\n",
    "            print('Real Input being used')\n",
    "            # all channels: ['555-647', 'GT_Cy5', 'GT_TRITC']\n",
    "            config.data.channel_idx_list = [\n",
    "                    Sox2GolgiV2ChannelList.GT_TRITC,Sox2GolgiV2ChannelList.GT_Cy5, Sox2GolgiV2ChannelList.GT_555_647\n",
    "                ]\n",
    "            config.data.input_idx = 2\n",
    "        else:\n",
    "            print('Real Input not being used')\n",
    "            config.data.channel_idx_list = [\n",
    "                    Sox2GolgiV2ChannelList.GT_TRITC,Sox2GolgiV2ChannelList.GT_Cy5\n",
    "                ]\n",
    "            config.data.input_idx = None\n",
    "\n",
    "        config.data.num_channels = len(config.data.channel_idx_list)\n",
    "    if use_selected_fpaths is not None:\n",
    "        config.data.use_selected_fpaths = use_selected_fpaths\n",
    "    config.data.target_idx_list = [0, 1]\n",
    "    config.model.num_targets = len(config.data.target_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2Golgi:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.noise_model_ch1_fpath = config.model.noise_model_ch1_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')\n",
    "# config.model.noise_model_ch2_fpath = config.model.noise_model_ch2_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8edeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dset.dsets[0]._data[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # high val dset \n",
    "# import ml_collections\n",
    "# new_config = ml_collections.ConfigDict(config)\n",
    "# highsnr_val_dset = None\n",
    "# if 'poisson_noise_factor' in new_config.data and new_config.data.poisson_noise_factor > 0:\n",
    "#     new_config.data.poisson_noise_factor = -1\n",
    "#     _, highsnr_val_dset = create_dataset(new_config, data_dir, eval_datasplit_type=eval_datasplit_type,\n",
    "#                                         kwargs_dict=dloader_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_input_frame(idx, dset):\n",
    "    img_tuples, noise_tuples = dset._load_img(idx)\n",
    "    if len(noise_tuples) > 0:\n",
    "        factor = np.sqrt(2) if dset._input_is_sum else 1.0\n",
    "        img_tuples = [x + noise_tuples[0] * factor for x in img_tuples]\n",
    "\n",
    "    inp = 0\n",
    "    for nch in img_tuples:\n",
    "        inp += nch/len(img_tuples)\n",
    "    h_start, w_start = dset._get_deterministic_hw(idx)\n",
    "    return inp, h_start, w_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77918a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from disentangle.analysis.paper_plots import show_for_one, get_plotoutput_dir\n",
    "def get_hwt_start(idx):\n",
    "    h,w,t = val_dset.idx_manager.hwt_from_idx(idx, grid_size=64)\n",
    "    print(h,w,t)\n",
    "    pad = val_dset.per_side_overlap_pixelcount()\n",
    "    h =  h - pad\n",
    "    w = w - pad\n",
    "    return h,w,t\n",
    "\n",
    "def get_crop_from_fulldset_prediction(full_dset_pred, idx, patch_size=256):\n",
    "    h,w,t = get_hwt_start(idx)\n",
    "    return np.swapaxes(full_dset_pred[t,h:h+patch_size,w:w+patch_size].astype(np.float32)[None], 0, 3)[...,0]\n",
    "\n",
    "if save_comparative_plots:\n",
    "    assert eval_datasplit_type == DataSplitType.Test\n",
    "    # CCP vs Microtubules: 925, 659, 502\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_67.tif')\n",
    "    hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M5_Sk0/pred_disentangle_2403_D23-M3-S0-L0_29.tif')\n",
    "\n",
    "    # ER vs Microtubule 853, 859, 332\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_60.tif')\n",
    "\n",
    "    #  ER vs CCP 327, 479, 637, 568\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_59.tif')\n",
    "\n",
    "    #  F-actin vs ER 797\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M10_Sk0/pred_disentangle_2403_D23-M3-S0-L0_15.tif')\n",
    "\n",
    "    idx = 10#np.random.randint(len(val_dset))\n",
    "    patch_size = 500\n",
    "    mmse_count = 50\n",
    "    print(idx)\n",
    "    show_for_one(idx, val_dset, highsnr_val_dset, model, None, mmse_count=mmse_count, patch_size=patch_size, baseline_preds=[\n",
    "        get_crop_from_fulldset_prediction(hdn_usplitdata, idx).astype(np.float32),\n",
    "    ], num_samples=0)\n",
    "\n",
    "\n",
    "    plotsdir = get_plotoutput_dir(ckpt_dir, patch_size, mmse_count=mmse_count)\n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'patch_comparison_{idx}_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217aae0",
   "metadata": {},
   "source": [
    "## Self-supervision\n",
    "Here, we now do some self-supervised finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def zero_mean(x):\n",
    "#     return x - torch.mean(x, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "# def fix_range(gt, x):\n",
    "#     a = torch.sum(gt * x, dim=1, keepdim=True) / (torch.sum(x * x, dim=1, keepdim=True))\n",
    "#     return x * a\n",
    "\n",
    "\n",
    "# def fix(gt, x):\n",
    "#     return fix_range(gt, zero_mean(x))\n",
    "\n",
    "# def RangeInvariantPsnr(gt, pred):\n",
    "#     \"\"\"\n",
    "#     NOTE: Works only for grayscale images.\n",
    "#     Adapted from https://github.com/juglab/ScaleInvPSNR/blob/master/psnr.py\n",
    "#     It rescales the prediction to ensure that the prediction has the same range as the ground truth.\n",
    "#     \"\"\"\n",
    "#     assert len(gt.shape) == 3, 'Images must be in shape: (batch,H,W)'\n",
    "#     gt = gt.view(len(gt), -1)\n",
    "#     pred = pred.view(len(gt), -1)\n",
    "#     # ra = (torch.max(gt, dim=1).values - torch.min(gt, dim=1).values) / torch.std(gt, dim=1)\n",
    "#     gt_ = zero_mean(gt) / torch.std(gt, dim=1, keepdim=True)\n",
    "#     return _PSNR_internal(zero_mean(gt_), fix(gt_, pred), ra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "std_arr = []\n",
    "for i in tqdm(range(len(val_dset))):\n",
    "    inp_1, tar_1  = val_dset[i]\n",
    "    std_arr.append(np.std(inp_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac90982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.asymmetric_transforms import TransformAllChannels, VFlip, Rotate, HFlip, DeepinvTransform\n",
    "from deepinv.transform.projective import Homography\n",
    "\n",
    "\n",
    "trans_homo = Homography(n_trans = 1, zoom_factor_min=1.0, theta_max=30, theta_z_max=180, skew_max=0, shift_max=0.5,\n",
    "                        x_stretch_factor_min = 1,\n",
    "                        y_stretch_factor_min = 1, device = model.device)\n",
    "transform_types = {0:[VFlip(), Rotate(),HFlip(), DeepinvTransform(trans_homo)], 1:[ VFlip(), HFlip(), Rotate(), DeepinvTransform(trans_homo)]}\n",
    "transform_all = TransformAllChannels(transform_types)\n",
    "content_std = np.quantile(std_arr, 0.99)\n",
    "idx_list = (np.where(np.array(std_arr) > content_std)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8903d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = val_dset[idx_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1db2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(9,3),ncols=3)\n",
    "ax[0].imshow(inp[0])\n",
    "ax[1].imshow(tar[0])\n",
    "ax[2].imshow(tar[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ad874",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dset.dsets[0]._data[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370392fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.asymmetric_transforms import get_inverse_transforms\n",
    "with torch.no_grad():\n",
    "    pred_one, _ = model(torch.Tensor(inp[None]).cuda())\n",
    "    transformed_pred, applied_transforms = transform_all(pred_one[:,:2])\n",
    "\n",
    "    t_val = 0.7\n",
    "    transformed_inp = get_input_normalized(transformed_pred, t_val, channel_pos='second')[:,None]\n",
    "    # transformed_inp = (transformed_inp - transformed_inp.mean().item())/transformed_inp.std().item()\n",
    "    # transformed_inp = transformed_inp*inp.std() + inp.mean()\n",
    "    transformed_inp_pred, _ = model(transformed_inp)\n",
    "    inv_transform, _ = get_inverse_transforms(applied_transforms)\n",
    "    inv_transformed_pred, _  = transform_all(transformed_inp_pred, params_dict = inv_transform, inverse=True)\n",
    "\n",
    "    # \n",
    "    inv_inp = get_input_normalized(inv_transformed_pred, t_val, channel_pos='second')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Orig', inp.mean(), inp.std())\n",
    "print('Transformed', transformed_inp.mean().item(), transformed_inp.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(21,6),ncols=7,nrows=2)\n",
    "\n",
    "ax[0,0].imshow(inp[0])\n",
    "ax[0,0].set_title('x')\n",
    "\n",
    "# original prediction\n",
    "ax[0,1].set_title('Pred(x)')\n",
    "ax[0,1].imshow(pred_one[0,0].detach().cpu().numpy())\n",
    "ax[1,1].imshow(pred_one[0,1].detach().cpu().numpy())\n",
    "\n",
    "# transformed prediction\n",
    "ax[0,2].set_title('T(Pred(x))')\n",
    "ax[0,2].imshow(transformed_pred[0,0].detach().cpu().numpy())\n",
    "ax[1,2].imshow(transformed_pred[0,1].detach().cpu().numpy())\n",
    "\n",
    "ax[0,3].set_title('x2 = Inp(T(Pred(x)))')\n",
    "ax[0,3].imshow(transformed_inp[0,0].detach().cpu().numpy())\n",
    "\n",
    "ax[0,4].set_title('$T^{-1}$(Pred(x2))')\n",
    "ax[0,4].imshow(inv_transformed_pred[0,0].detach().cpu().numpy())\n",
    "ax[1,4].imshow(inv_transformed_pred[0,1].detach().cpu().numpy())\n",
    "\n",
    "ax[0,5].set_title('Target')\n",
    "ax[0,5].imshow(tar[0])\n",
    "ax[1,5].imshow(tar[1])\n",
    "\n",
    "ax[0,5].set_ylabel('Channel 1')\n",
    "ax[1,5].set_ylabel('Channel 2')\n",
    "# make the label right side\n",
    "ax[0,5].yaxis.set_label_position(\"right\")\n",
    "ax[1,5].yaxis.set_label_position(\"right\")\n",
    "ax[1,0].axis('off')\n",
    "ax[1,3].axis('off')\n",
    "\n",
    "ax[0,6].set_title('$x_{rec}$ = Inp($T^{-1}$(Pred(x2)))')\n",
    "ax[0,6].imshow(inv_inp[0,0].detach().cpu().numpy())\n",
    "ax[1,6].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "# from disentangle.analysis.stitch_prediction import get_predictions as get_dset_predictions\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.where(logvar_tiled.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "pred = stitch_predictions(pred_tiled,val_dset, )\n",
    "if len(np.unique(logvar_tiled)) == 1:\n",
    "    logvar = None\n",
    "else:\n",
    "    logvar = stitch_predictions(logvar_tiled,val_dset, )\n",
    "pred_std = stitch_predictions(pred_std_tiled,val_dset, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_list_prediction = isinstance(pred, list)\n",
    "tar_unnorm = (val_dset._data if not is_list_prediction else [val_dset.dsets[i]._data for i in range(len(val_dset.dsets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67288f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66deb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTar = pred[0].shape[-1]\n",
    "if \"target_idx_list\" in config.data and config.data.target_idx_list is not None:\n",
    "    nTar =len(config.data.target_idx_list)\n",
    "    # pred = pred[..., :len(config.data.target_idx_list)] if not is_list_prediction else [pred[i][..., :len(config.data.target_idx_list)] for i in range(len(pred))]\n",
    "    # pred_std = pred_std[...,:len(config.data.target_idx_list)] if not is_list_prediction else [pred_std[i][..., :len(config.data.target_idx_list)] for i in range(len(pred_std))]\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp_unnorm = [x[...,config.data.input_idx] for x in tar_unnorm]\n",
    "    tar_unnorm = [x[...,:nTar] for x in tar_unnorm]\n",
    "else:\n",
    "    inp_unnorm = [x.mean(axis=-1) for x in tar_unnorm]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3602c8",
   "metadata": {},
   "source": [
    "### Optimal Estimation of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ec0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.psnr import RangeInvariantPsnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "mean_psnr_arr = []\n",
    "std_psnr_arr = []\n",
    "t_values = np.arange(0.0,1.0, 0.05) \n",
    "for t in tqdm(t_values):\n",
    "    inp_tiled = [(t *pred[i][...,0] + (1-t)*pred[i][...,1]) for i in range(len(pred))]\n",
    "    psnr_values = [RangeInvariantPsnr(inp_unnorm[i]*1.0, inp_tiled[i]).item() for i in range(len(inp_unnorm))]\n",
    "    mean_psnr_arr.append(np.mean(psnr_values))\n",
    "    std_psnr_arr.append(np.std(psnr_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e04e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(mean_psnr_arr)\n",
    "best_t_estimate = t_values[best_idx]\n",
    "print(f'Best t value: {best_t_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_values, mean_psnr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71660b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax  = plt.subplots(figsize=(8,4),ncols=2)\n",
    "# ax[0].imshow(inp_tiled[0][0])\n",
    "# ax[1].imshow(inp_unnorm[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0,-ignored_pixels:,-ignored_pixels:,].std() ==0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "# actual_ignored_pixels = print_ignored_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23db3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean[\"target\"], model.data_std[\"target\"]\n",
    "sep_mean = sep_mean.squeeze().reshape(1, 1, 1, -1)\n",
    "sep_std = sep_std.squeeze().reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape, sep_mean.shape, sep_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unnorm_pred(pred_arr):\n",
    "    if is_list_prediction:\n",
    "        pred_unnorm = [pred_arr[i] * sep_std.cpu().numpy() + sep_mean.cpu().numpy() for i in range(len(pred_arr))]\n",
    "    else:\n",
    "        pred_unnorm = pred_arr * sep_std.cpu().numpy() + sep_mean.cpu().numpy()\n",
    "    return pred_unnorm\n",
    "\n",
    "def normalize_channels(channel_arr):\n",
    "    if is_list_prediction:\n",
    "        pred_unnorm = [(channel_arr[i] - sep_mean.cpu().numpy())/sep_std.cpu().numpy() for i in range(len(channel_arr))]\n",
    "    else:\n",
    "        pred_unnorm = (channel_arr - sep_mean.cpu().numpy())/ sep_std.cpu().numpy()\n",
    "    return pred_unnorm\n",
    "\n",
    "pred_unnorm = get_unnorm_pred(pred)\n",
    "# if ckpt_dir in ['/group/jug/ashesh/training/disentangle/2404/D17-M3-S0-L8/4', '/group/jug/ashesh/training/disentangle/2404/D21-M3-S0-L8/1']:\n",
    "#     print(\"Reversing the order of channels\")\n",
    "#     pred_unnorm = [x[...,::-1] for x in pred_unnorm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac44cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import compute_high_snr_stats\n",
    "stats_dict = compute_high_snr_stats(tar_unnorm, pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce819b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_inp, std_inp = val_dset.dsets[0].get_mean_std_for_input()\n",
    "mean_inp = mean_inp.reshape(-1,)[0]\n",
    "std_inp = std_inp.reshape(-1,)[0]\n",
    "(mean_inp, std_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_one_sample\n",
    "img_idx, hs, ws = plot_one_sample(normalize_channels(tar_unnorm), pred, inp_unnorm, config, best_t_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba25fd8",
   "metadata": {},
   "source": [
    "## SSL finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from finetunesplit.loss import SSL_loss\n",
    "from disentangle.loss.ssl_finetuning import finetune_two_forward_passes\n",
    "from finetunesplit.asymmetric_transforms import TransformAllChannels, VFlip, Rotate, HFlip, DeepinvTransform\n",
    "from deepinv.transform.projective import Homography\n",
    "\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "\n",
    "# setting the transformation\n",
    "\n",
    "\n",
    "trans_homo = Homography(n_trans = 1, zoom_factor_min=1.0, theta_max=10, theta_z_max=180, skew_max=0, shift_max=0.5,\n",
    "                        x_stretch_factor_min = 1,\n",
    "                        y_stretch_factor_min = 1, device = model.device)\n",
    "transform_types = {0:[VFlip(), Rotate(),HFlip(), DeepinvTransform(trans_homo)], 1:[ VFlip(), HFlip(), Rotate(), DeepinvTransform(trans_homo)]}\n",
    "\n",
    "# transform_types = {0:[VFlip(), Rotate(),HFlip()], 1:[ VFlip(), HFlip(), Rotate()]}\n",
    "# transform_all = TransformAllChannels(transform_types)\n",
    "\n",
    "# def pred_func(inp):\n",
    "#     return model(inp)[0][:,:2]\n",
    "\n",
    "\n",
    "# define a learnable scalar and an offset \n",
    "factor1 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset1 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "\n",
    "factor2 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "mixing_ratio = torch.nn.Parameter(torch.tensor(best_t_estimate).cuda())\n",
    "\n",
    "# optimization_params = [factor1, offset1, factor2, offset2, mixing_ratio]\n",
    "# optimization_params = [factor1, offset1, factor2, offset2]\n",
    "optimization_params = [factor2, offset2]\n",
    "max_step_count = 10000\n",
    "batch_size = 16\n",
    "skip_pixels = 16\n",
    "lr = 1e-3\n",
    "lookback = 10\n",
    "finetuning_output_dict = finetune_two_forward_passes(model, val_dset, transform_all, max_step_count=max_step_count, batch_size=batch_size, skip_pixels=skip_pixels,\n",
    "                                scalar_params_dict={'factor1':factor1, 'offset1':offset1, 'factor2':factor2, 'offset2':offset2, 'mixing_ratio':mixing_ratio},\n",
    "                                optimization_params_dict={'lr':lr, 'parameters': optimization_params},\n",
    "                                lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0462285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_finetuning_loss\n",
    "plot_finetuning_loss(finetuning_output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d48d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor2 = torch.nn.Parameter(torch.tensor(finetuning_output_dict['best_factors'][1]).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(finetuning_output_dict['best_offsets'][1]).cuda())\n",
    "\n",
    "optimization_params = [factor1, offset1]\n",
    "max_step_count = 10000\n",
    "batch_size = 16\n",
    "skip_pixels = 16\n",
    "lr = 1e-3\n",
    "lookback = 10\n",
    "finetuning_output_dict = finetune_two_forward_passes(model, val_dset, transform_all, max_step_count=max_step_count, batch_size=batch_size, skip_pixels=skip_pixels,\n",
    "                                scalar_params_dict={'factor1':factor1, 'offset1':offset1, 'factor2':factor2, 'offset2':offset2, 'mixing_ratio':mixing_ratio},\n",
    "                                optimization_params_dict={'lr':lr, 'parameters': optimization_params},\n",
    "                                lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_finetuning_loss\n",
    "plot_finetuning_loss(finetuning_output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c02845",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_factors = finetuning_output_dict['best_factors']\n",
    "best_offsets = finetuning_output_dict['best_offsets']\n",
    "(best_factors, best_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54563870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDataset:\n",
    "    def __init__(self, dset, scalar, offset):\n",
    "        self.dset = dset\n",
    "        self.scalar = scalar\n",
    "        self.offset = offset\n",
    "    def __len__(self):\n",
    "        return len(self.dset)\n",
    "    def __getitem__(self, idx):\n",
    "        inp, tar = self.dset[idx]\n",
    "        return inp * self.scalar + self.offset, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95550dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_val_dset = ScaledDataset(val_dset, best_factors[0], best_offsets[0])\n",
    "# scaled_val_dset = ScaledDataset(val_dset, scalar1_arr[-1], offset1_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9493e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, scaled_val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stitch_predictions(pred_tiled,val_dset)\n",
    "pred_unnorm = get_unnorm_pred(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff58347",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_one_sample(normalize_channels(tar_unnorm), pred, inp_unnorm, config, best_t_estimate, img_idx=img_idx, hs=hs, ws=ws)\n",
    "# import matplotlib.patches as patches\n",
    "# ncols = tar_unnorm[0].shape[-1] + 1\n",
    "# imgsz = 4\n",
    "# _,ax = plt.subplots(figsize=((1+ncols)*imgsz,2*imgsz),nrows=2,ncols=ncols + 1)\n",
    "# print(img_idx, hs, ws)\n",
    "\n",
    "# for i in range(ncols-1):\n",
    "#     # vmin = tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i].min()\n",
    "#     # vmax = tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i].max()\n",
    "#     ax[0,i+1].imshow(tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i])\n",
    "#     ax[1,i+1].imshow(pred[img_idx][0,hs:hs+sz, ws:ws+sz,i])\n",
    "\n",
    "# if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "#     inp = inp_unnorm[img_idx][0]\n",
    "# else:\n",
    "#     inp = np.mean(tar_unnorm[img_idx][0], axis=-1)\n",
    "\n",
    "# inp = (inp - mean_inp)/std_inp\n",
    "    \n",
    "# ax[0,0].imshow(inp)\n",
    "# rect = patches.Rectangle((ws, hs), sz,sz, linewidth=2, edgecolor='r', facecolor='none')\n",
    "# ax[0,0].add_patch(rect)\n",
    "\n",
    "# ax[1,0].imshow(inp[hs:hs+sz, ws:ws+sz])\n",
    "# # reconstructed input\n",
    "# inp_recons = pred[img_idx][0,...,0] *best_t_estimate + pred[img_idx][0,...,1] * (1-best_t_estimate)\n",
    "# ax[1,-1].imshow(inp_recons[hs:hs+sz, ws:ws+sz])\n",
    "# psnr_inp = f'{RangeInvariantPsnr(inp[None]*1.0, inp_recons[None]).item():.1f}'\n",
    "# ax[1, -1].set_title(f'Recons Input (PSNR {psnr_inp})')\n",
    "\n",
    "# ax[0, -1].axis(\"off\")\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.03, hspace=0.03)\n",
    "# ax[0,0].set_title('Input')\n",
    "# twinx = ax[0,-2].twinx()\n",
    "# twinx.set_ylabel('Target')\n",
    "# clean_ax(twinx)\n",
    "# twinx = ax[1,-2].twinx()\n",
    "# clean_ax(twinx)\n",
    "# twinx.set_ylabel('Prediction')\n",
    "# clean_ax(ax)\n",
    "# # plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4388ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import avg_range_inv_psnr\n",
    "tar0 = [x[...,0] for x in tar_unnorm]\n",
    "pred0 = [x[...,0] for x in pred_unnorm]\n",
    "\n",
    "tar1 = [x[...,1] for x in tar_unnorm]\n",
    "pred1 = [x[...,1] for x in pred_unnorm]\n",
    "psnr_ch0 = avg_range_inv_psnr(np.concatenate(tar0,axis=0), np.concatenate(pred0, axis=0))\n",
    "psnr_ch1 = avg_range_inv_psnr(np.concatenate(tar1,axis=0), np.concatenate(pred1, axis=0))\n",
    "print(psnr_ch0, psnr_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1:{best_factors[0]:.2f} Off1:{best_offsets[0]:.2f} F2:{best_factors[1]:.2f} Off2:{best_offsets[1]:.2f}\\t\\t PSNR: {psnr_ch0[0]:.2f} {psnr_ch1[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor+offset: ([1.0589449405670166, 0.5071319341659546]) => 27.4, 36.13\n",
    "# factor+offset: ([1.01511812210083, 0.7669262886047363], => (26.96, 0.0) (34.96, 0.0)\n",
    "# factor+offset: ([0.8788655400276184, 0.7334750294685364]) => (26.44, 0.0) (33.99, 0.0)\n",
    "# factor+offset: ([0.9193213582038879, 0.8820053339004517],(26.46, 0.0) (34.0, 0.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6429bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_count = 10000\n",
    "batch_size = 16\n",
    "skip_pixels = 16\n",
    "lr = 1e-4\n",
    "lookback = 10\n",
    "# best_factors[0], best_offsets[0]\n",
    "finetuning_output_dict = finetune_two_forward_passes(model, val_dset, transform_all, max_step_count=max_step_count, batch_size=batch_size, skip_pixels=skip_pixels,\n",
    "                                scalar_params_dict={'factor1':best_factors[0], 'offset1':best_offsets[0], 'factor2':best_factors[1], 'offset2':best_offsets[1], \n",
    "                                                    'mixing_ratio':mixing_ratio},\n",
    "                                optimization_params_dict={'lr':lr, 'parameters': model.first_bottom_up[0].parameters()},\n",
    "                                lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.Series(finetuning_output_dict['loss_inp']).rolling(5).mean().plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c742ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, scaled_val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312917f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stitch_predictions(pred_tiled,val_dset)\n",
    "pred_unnorm = get_unnorm_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.scripts.evaluate import avg_range_inv_psnr\n",
    "tar0 = [x[...,0] for x in tar_unnorm]\n",
    "pred0 = [x[...,0] for x in pred_unnorm]\n",
    "\n",
    "tar1 = [x[...,1] for x in tar_unnorm]\n",
    "pred1 = [x[...,1] for x in pred_unnorm]\n",
    "psnr_ch0 = avg_range_inv_psnr(np.concatenate(tar0,axis=0), np.concatenate(pred0, axis=0))\n",
    "psnr_ch1 = avg_range_inv_psnr(np.concatenate(tar1,axis=0), np.concatenate(pred1, axis=0))\n",
    "psnr_ch0, psnr_ch1\n",
    "# stats_dict = compute_high_snr_stats(tar_unnorm, pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf71a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(pred[0][0,...,0])\n",
    "ax[1].imshow(pred[0][0,...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "ncols = tar_unnorm[0].shape[-1] + 1\n",
    "imgsz = 4\n",
    "_,ax = plt.subplots(figsize=((1+ncols)*imgsz,2*imgsz),nrows=2,ncols=ncols + 1)\n",
    "print(img_idx, hs, ws)\n",
    "\n",
    "for i in range(ncols-1):\n",
    "    ax[0,i+1].imshow(tar_unnorm[img_idx][0,hs:hs+sz, ws:ws+sz ,i])\n",
    "    ax[1,i+1].imshow(pred[img_idx][0,hs:hs+sz, ws:ws+sz,i])\n",
    "\n",
    "if 'input_idx' in config.data and config.data.input_idx is not None:\n",
    "    inp = inp_unnorm[img_idx][0]\n",
    "else:\n",
    "    inp = np.mean(tar_unnorm[img_idx][0], axis=-1)\n",
    "\n",
    "    \n",
    "ax[0,0].imshow(inp)\n",
    "rect = patches.Rectangle((ws, hs), sz,sz, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0,0].add_patch(rect)\n",
    "\n",
    "ax[1,0].imshow(inp[hs:hs+sz, ws:ws+sz])\n",
    "# reconstructed input\n",
    "inp_recons = pred[img_idx][0,...,0] *best_t_estimate + pred[img_idx][0,...,1] * (1-best_t_estimate)\n",
    "ax[1,-1].imshow(inp_recons[hs:hs+sz, ws:ws+sz])\n",
    "psnr_inp = f'{RangeInvariantPsnr(inp[None]*1.0, inp_recons[None]).item():.1f}'\n",
    "ax[1, -1].set_title(f'Recons Input (PSNR {psnr_inp})')\n",
    "\n",
    "ax[0, -1].axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.03, hspace=0.03)\n",
    "ax[0,0].set_title('Input')\n",
    "twinx = ax[0,-2].twinx()\n",
    "twinx.set_ylabel('Target')\n",
    "clean_ax(twinx)\n",
    "twinx = ax[1,-2].twinx()\n",
    "clean_ax(twinx)\n",
    "twinx.set_ylabel('Prediction')\n",
    "clean_ax(ax)\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d9b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
