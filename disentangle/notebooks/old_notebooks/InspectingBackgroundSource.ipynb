{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ec4ad9",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The objective is to inspect how the background prediction happens in the model. I'll try to change the background and see what weights needs to change to allow this to happen. \n",
    "Idea is to look at which region in the network is responsible for it. \n",
    "## How to quantify this? \n",
    "1. Look at how much weights have changed. \n",
    "    a. The magnitude of change in weights.\n",
    "    b. The fractional change in weights. \n",
    "    c. The number of weights that have changed above a certain threshold.\n",
    "\n",
    "2. Restrict different layers and see how long does it take to get this effect. \n",
    "3. Also inspect if this change in weights is generalizable to other images or it is specific to just this image ? \n",
    "4. Inspect how the model trained with a large patch size behaves as compared to the same architecture trained with a small patch size.\n",
    "5. Inspect the above with UNet and with HVAE. The motivation is to see if stochasticity has any role to play in this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two environments(debug and prod). From where you want to fetch the code and data? \n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(DEBUG)\n",
    "%run ./nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stats_'+'_'.join(ckpt_dir.split('/')[-4:]) + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"/home/ashesh.ashesh/training/disentangle/2310/D3-M3-S0-L0/6\"\n",
    "# 211/D3-M3-S0-L0/0\n",
    "# 2210/D3-M3-S0-L0/128\n",
    "# 2210/D3-M3-S0-L0/129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27410ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /home/ubuntu/ashesh/training/disentangle/2209/D3-M9-S0-L0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = int(ckpt_dir.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237569",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    if dtype == DataType.CustomSinosoid:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "else:\n",
    "    if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "    elif dtype == DataType.Prevedel_EMBL:\n",
    "        data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "    elif dtype == DataType.AllenCellMito:\n",
    "        data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "    elif dtype == DataType.SeparateTiffData:\n",
    "        data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "    elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "        data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "    elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "        data_dir = f'{DATA_ROOT}/pavia2'\n",
    "    elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "    elif dtype == DataType.ShroffMitoEr:\n",
    "        data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "    elif dtype == DataType.HTIba1Ki67:\n",
    "        data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "        \n",
    "#     2720*2720: microscopy dataset.\n",
    "\n",
    "image_size_for_grid_centers = None\n",
    "mmse_count = 1\n",
    "custom_image_size = None\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test\n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.Iba1Ki64\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if config.model.model_type not in [ModelType.UNet, ModelType.BraveNet]:\n",
    "#     with torch.no_grad():\n",
    "#         inp, tar = val_dset[0][:2]\n",
    "#         out, td_data = model(torch.Tensor(inp[None]).cuda())\n",
    "#         print(td_data['z'][-1].shape)\n",
    "#         print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = max(len(inp_tmp),3)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(len(inp_tmp)):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "ax[1,0].imshow(tar_tmp[0]+tar_tmp[1])\n",
    "ax[1,1].imshow(tar_tmp[0])\n",
    "ax[1,2].imshow(tar_tmp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "# from disentangle.analysis.stitch_prediction import get_predictions as get_dset_predictions\n",
    "\n",
    "pred_tiled, rec_loss, logvar, patch_psnr_tuple = get_dset_predictions(model, val_dset,batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               mmse_count=mmse_count,\n",
    "                                                model_type = config.model.model_type,\n",
    "                                              )\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp,np.mean(tmp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee076ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch wise PSNR, as computed during training [ 4.71 23.01] 13.860000000000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535169c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = np.where(logvar.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(logvar[::50].squeeze().reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "pred = stitch_predictions(pred_tiled,val_dset, smoothening_pixelcount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09091e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[np.isnan(pred)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0,-ignored_pixels:,-ignored_pixels:,].std() ==0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = print_ignored_pixels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8474735",
   "metadata": {},
   "source": [
    "## Ignore the pixels which are present in the last few rows and columns. \n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ignored_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadedfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_last_pixels = 32 if config.data.data_type in [DataType.OptiMEM100_014,\n",
    "                                                      DataType.SemiSupBloodVesselsEMBL, \n",
    "                                                      DataType.Pavia2VanillaSplitting,\n",
    "                                                      DataType.ExpansionMicroscopyMitoTub,\n",
    "                                                      DataType.ShroffMitoEr,\n",
    "                                                      DataType.HTIba1Ki67] else 0\n",
    "ignore_first_pixels = 0\n",
    "\n",
    "assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}'\n",
    "print(ignored_last_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = val_dset._data\n",
    "def ignore_pixels(arr):\n",
    "    if ignore_first_pixels:\n",
    "        arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "    if ignored_last_pixels:\n",
    "        arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "    return arr\n",
    "\n",
    "pred = ignore_pixels(pred)\n",
    "tar = ignore_pixels(tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.plot_utils import *\n",
    "# def add_pixel_kde(ax,\n",
    "#                   rect: List[float],\n",
    "#                   data1: np.ndarray,\n",
    "#                   data2: Union[np.ndarray, None],\n",
    "#                   min_labelsize: int,\n",
    "#                   color1='r',\n",
    "#                   color2='black',\n",
    "#                   color_xtick='white',\n",
    "#                   label1='Target',\n",
    "#                   label2='Predicted'):\n",
    "#     \"\"\"\n",
    "#     Adds KDE (density plot) of data1(eg: target) and data2(ex: predicted) image pixel values as an inset\n",
    "#     \"\"\"\n",
    "#     inset_ax = add_subplot_axes(ax, rect, facecolor=\"None\", min_labelsize=min_labelsize)\n",
    "    \n",
    "#     inset_ax.tick_params(axis='x', colors=color_xtick)\n",
    "\n",
    "#     sns.kdeplot(data=data1.reshape(-1, ), ax=inset_ax, color=color1, label=label1)\n",
    "#     if data2 is not None:\n",
    "#         sns.kdeplot(data=data2.reshape(-1, ), ax=inset_ax, color=color2, label=label2)\n",
    "#     inset_ax.set_xlim(left=0)\n",
    "#     xticks = inset_ax.get_xticks()\n",
    "#     # inset_ax.set_xticks([xticks[0], xticks[-1]])\n",
    "#     inset_ax.set_xticks([])\n",
    "#     clean_for_xaxis_plot(inset_ax)\n",
    "\n",
    "\n",
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "\n",
    "# inset_rect=[0.1,0.1,0.4,0.2]\n",
    "# inset_min_labelsize=10\n",
    "# color_ch_list=['goldenrod','cyan']\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(15,10),ncols=3,nrows=2)\n",
    "# idx = 8\n",
    "# pred1_crop  = ch1_pred_unnorm[idx,1116:1372,1064:1320].copy()\n",
    "# pred2_crop  = ch2_pred_unnorm[idx,1116:1372,1064:1320].copy()\n",
    "# pred1_crop[pred1_crop<0] = 0\n",
    "# pred2_crop[pred2_crop<0] = 0\n",
    "\n",
    "# tar1_crop   =  tar[idx,1116:1372,1064:1320,0]\n",
    "# tar2_crop   =  tar[idx,1116:1372,1064:1320,1]\n",
    "\n",
    "# ax[0,0].imshow(tar1_crop+tar2_crop)\n",
    "# ax[0,1].imshow(tar1_crop)\n",
    "# ax[0,2].imshow(tar2_crop)\n",
    "\n",
    "# ax[1,0].imshow(pred1_crop+pred2_crop)\n",
    "# ax[1,1].imshow(pred1_crop)\n",
    "# ax[1,2].imshow(pred2_crop)\n",
    "# clean_ax(ax)\n",
    "# add_pixel_kde(ax[0,0], inset_rect, \n",
    "#               tar1_crop, \n",
    "#               tar2_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1=color_ch_list[0], color2=color_ch_list[1])\n",
    "\n",
    "# add_pixel_kde(ax[1,1], inset_rect, \n",
    "#               pred1_crop, \n",
    "#               tar1_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1='red', color2=color_ch_list[0])\n",
    "# add_pixel_kde(ax[1,2], inset_rect, \n",
    "#               pred2_crop, \n",
    "#               tar2_crop, \n",
    "#               inset_min_labelsize,\n",
    "#                 label1='Ch1', label2='Ch2', color1='red', color2=color_ch_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "def _avg_psnr(target, prediction, psnr_fn):\n",
    "    output = np.mean([psnr_fn(target[i:i + 1], prediction[i:i + 1]).item() for i in range(len(prediction))])\n",
    "    return round(output, 2)\n",
    "\n",
    "\n",
    "def avg_range_inv_psnr(target, prediction):\n",
    "    return _avg_psnr(target, prediction, RangeInvariantPsnr)\n",
    "\n",
    "\n",
    "def avg_psnr(target, prediction):\n",
    "    return _avg_psnr(target, prediction, PSNR)\n",
    "\n",
    "\n",
    "def compute_masked_psnr(mask, tar1, tar2, pred1, pred2):\n",
    "    mask = mask.astype(bool)\n",
    "    mask = mask[..., 0]\n",
    "    tmp_tar1 = tar1[mask].reshape((len(tar1), -1, 1))\n",
    "    tmp_pred1 = pred1[mask].reshape((len(tar1), -1, 1))\n",
    "    tmp_tar2 = tar2[mask].reshape((len(tar2), -1, 1))\n",
    "    tmp_pred2 = pred2[mask].reshape((len(tar2), -1, 1))\n",
    "    psnr1 = avg_range_inv_psnr(tmp_tar1, tmp_pred1)\n",
    "    psnr2 = avg_range_inv_psnr(tmp_tar2, tmp_pred2)\n",
    "    return psnr1, psnr2\n",
    "\n",
    "def avg_ssim(target, prediction):\n",
    "    ssim = [structural_similarity(target[i],prediction[i], data_range=(target[i].max() - target[i].min())) for i in range(len(target))]\n",
    "    return np.mean(ssim),np.std(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean, model.data_std\n",
    "if isinstance(sep_mean, dict):\n",
    "    sep_mean = sep_mean['target']\n",
    "    sep_std = sep_std['target']\n",
    "    \n",
    "sep_mean = sep_mean.squeeze()[None,None,None]\n",
    "sep_std = sep_std.squeeze()[None,None,None]\n",
    "\n",
    "tar_normalized = (tar - sep_mean.cpu().numpy())/sep_std.cpu().numpy()\n",
    "tar1 =tar_normalized[...,0]\n",
    "tar2 =tar_normalized[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2402048",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = [0.01, 0.1,0.5,0.9,0.95, 0.99,1]\n",
    "print('Nuc:', np.quantile(tar_normalized[...,0], q_vals).round(2))\n",
    "print('Tub:', np.quantile(tar_normalized[...,1], q_vals).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c445e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nuc:', np.quantile(tar[...,0], q_vals))\n",
    "print('Tub:', np.quantile(tar[...,1], q_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(6,6))\n",
    "# sns.histplot(tar[:,...,0].reshape(-1,), color='g', label='Nuc')\n",
    "# sns.histplot(tar[:,...,1].reshape(-1,), color='r', label='Tub')\n",
    "\n",
    "sns.histplot(tar[:,::10,::10,0].reshape(-1,), color='g', label='Nuc', kde=True)\n",
    "sns.histplot(tar[:,::10,::10,1].reshape(-1,), color='r', label='Tub', kde=True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb572707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.data_loader.schroff_rawdata_loader import mito_channel_fnames\n",
    "# from disentangle.core.tiff_reader import load_tiff\n",
    "# import seaborn as sns\n",
    "\n",
    "# fpaths = [os.path.join(datapath, x) for x in mito_channel_fnames()]\n",
    "# fpath = fpaths[0]\n",
    "# print(fpath)\n",
    "# img = load_tiff(fpaths[0])\n",
    "# temp = img.copy()\n",
    "# sns.histplot(temp[:,:,::10,::10].reshape(-1,))\n",
    "# plt.hist(temp[:,:,::10,::10].reshape(-1,),bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24708c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(12,12),ncols=2,nrows=2)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "ax[0,0].imshow(pred[idx,:,:,0])\n",
    "ax[0,1].imshow(pred[idx,:,:,1])\n",
    "ax[1,0].imshow(tar1[idx,:,:])\n",
    "ax[1,1].imshow(tar2[idx,:,:])\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is already normalized. no need to do it. \n",
    "pred1, pred2 = pred[...,0].astype(np.float32), pred[...,1].astype(np.float32)\n",
    "pred_inp = (pred1 + pred2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "ch1_pred_unnorm = 2 * pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "ch2_pred_unnorm = 2 * pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a885569",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.model_type == ModelType.LadderVaeSemiSupervised:\n",
    "    raise NotImplementedError(\"SSIM is incorrectly implemented here.\")\n",
    "    pred_inp = pred[...,2].astype(np.float32)\n",
    "#     tar1 is the input. tar2 is the target. \n",
    "    rmse1 =np.sqrt(((pred1 - tar2)**2).reshape(len(pred1),-1).mean(axis=1))\n",
    "    rmse2 =np.sqrt(((pred_inp - tar1)**2).reshape(len(pred2),-1).mean(axis=1)) \n",
    "\n",
    "    rmse = (rmse1 + rmse2)/2\n",
    "    rmse = np.round(rmse,3)\n",
    "\n",
    "    ssim1_mean, ssim1_std = avg_ssim(tar2, pred1)\n",
    "    ssim2_mean, ssim2_std = avg_ssim(tar1, pred_inp)\n",
    "    \n",
    "    psnr1 = avg_psnr(tar2, pred1)\n",
    "    psnr2 = avg_psnr(tar1, pred_inp)\n",
    "    rinv_psnr1 = avg_range_inv_psnr(tar2, pred1)\n",
    "    rinv_psnr2 = avg_range_inv_psnr(tar1, pred_inp)\n",
    "    \n",
    "else:\n",
    "    rmse1 =np.sqrt(((pred1 - tar1)**2).reshape(len(pred1),-1).mean(axis=1))\n",
    "    rmse2 =np.sqrt(((pred2 - tar2)**2).reshape(len(pred2),-1).mean(axis=1)) \n",
    "\n",
    "    rmse = (rmse1 + rmse2)/2\n",
    "    rmse = np.round(rmse,3)\n",
    "    psnr1 = avg_psnr(tar1, pred1) \n",
    "    psnr2 = avg_psnr(tar2, pred2)\n",
    "    rinv_psnr1 = avg_range_inv_psnr(tar1, pred1)\n",
    "    rinv_psnr2 = avg_range_inv_psnr(tar2, pred2)\n",
    "    ssim1_mean, ssim1_std = avg_ssim(tar[...,0], ch1_pred_unnorm)\n",
    "    ssim2_mean, ssim2_std = avg_ssim(tar[...,1], ch2_pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar[...,0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87868b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{custom_image_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "print('Rec Loss',np.round(rec_loss.mean(),3) )\n",
    "print('RMSE', np.mean(rmse1).round(3), np.mean(rmse2).round(3), np.mean(rmse).round(3))\n",
    "print('PSNR', psnr1, psnr2)\n",
    "print('RangeInvPSNR',rinv_psnr1, rinv_psnr2 )\n",
    "print('SSIM',round(ssim1_mean,3), round(ssim2_mean,3),'Â±',round((ssim1_std + ssim2_std)/2,4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65357dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a42a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def reload(model):\n",
    "    checkpoint = torch.load(ckpt_fpath)\n",
    "    _ = model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "def train(cur_model, background_increment_factor=0.0, ch0_offset=0, val_idx=0, step_count=100, lr=1e-3,\n",
    "          original_model=None,inner_pad=0, use_predicted_tar=True):\n",
    "    if use_predicted_tar:\n",
    "        raw_inp, _ = val_dset[val_idx]\n",
    "        out, _ = cur_model(torch.Tensor(raw_inp[None]).cuda())\n",
    "        raw_tar = get_img_from_forward_output(out, cur_model, unnormalized=True).detach().cpu().numpy()[0]\n",
    "    else:\n",
    "        raw_inp, raw_tar = val_dset[val_idx]\n",
    "    \n",
    "    raw_tar = raw_tar * (1+background_increment_factor)\n",
    "    raw_tar = np.concatenate([raw_tar[:1] + ch0_offset, raw_tar[1:] - ch0_offset], axis=0)\n",
    "\n",
    "    cur_model.train()\n",
    "    cur_model.mode_pred = False\n",
    "    inp = torch.Tensor(raw_inp[None]).cuda()\n",
    "    tar = torch.Tensor(raw_tar[None]).cuda()\n",
    "    tar = model.normalize_target(tar)\n",
    "    optimizer = optim.Adamax(cur_model.parameters(), lr=lr, weight_decay=0)\n",
    "    losses = []\n",
    "    rec_losses = []\n",
    "    reg_losses = []\n",
    "    for _ in tqdm(range(step_count)):\n",
    "        loss, loss_dict = one_step(cur_model, inp, tar, optimizer, original_model, inner_pad)\n",
    "        losses.append(loss)\n",
    "        rec_losses.append(loss_dict['rec_loss'])\n",
    "        reg_losses.append(loss_dict['reg_loss'])\n",
    "    return {'loss':losses, 'rec_loss':rec_losses, 'reg_loss':reg_losses}, (raw_inp, raw_tar)\n",
    "\n",
    "def weight_regularization_loss(cur_model, original_model):\n",
    "    original_model_dict = {k:v.detach() for k,v in original_model.named_parameters()}\n",
    "    loss = 0\n",
    "    for name, param in cur_model.named_parameters():\n",
    "        loss += torch.mean(torch.abs(original_model_dict[name] - param))\n",
    "    return loss/len(original_model_dict)\n",
    "\n",
    "def one_step(cur_model, inp, tar, optimizer, original_model, inner_pad):\n",
    "    out = cur_model(inp)[0]\n",
    "    # ll = cur_model.likelihood(out, tar)[0]\n",
    "    pred = get_img_from_forward_output(out, cur_model, unnormalized=False)\n",
    "    rec_loss = (pred - tar)**2\n",
    "    if inner_pad > 0:\n",
    "        rec_loss = rec_loss[...,inner_pad:-inner_pad, inner_pad:-inner_pad]\n",
    "\n",
    "    rec_loss = rec_loss.mean()\n",
    "    reg_loss = 100 * weight_regularization_loss(cur_model, original_model) \n",
    "    loss = rec_loss + reg_loss * 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), {'rec_loss': rec_loss.item(), 'reg_loss': reg_loss.item()}\n",
    "\n",
    "# pred, td_data = model(inpt)\n",
    "# pred = get_img_from_forward_output(pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = 0\n",
    "inp, tar = val_dset[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(tar[0], [0.01,0.1, 0.2, 0.5, 0.9, 0.99]))\n",
    "print(np.quantile(tar[1], [0.01,0.1, 0.2, 0.5, 0.9, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def get_cur_model():\n",
    "    skip_updates_to = ['top_down_layers.0', 'likelihood', 'final_top_down']\n",
    "    reload(model)\n",
    "    cur_model = deepcopy(model)\n",
    "    for name, param in cur_model.named_parameters():\n",
    "        if any([name.startswith(x) for x in skip_updates_to]):\n",
    "            param.requires_grad = False\n",
    "            # print(name, 'frozen')\n",
    "    return cur_model\n",
    "\n",
    "cur_model = get_cur_model()\n",
    "val_idx = 0\n",
    "\n",
    "loss_dict, inptar = train(cur_model, background_increment_factor = 0, ch0_offset=100, step_count=20, lr=1e-4,\n",
    "                       original_model=model,val_idx=val_idx, inner_pad=inp.shape[-1]//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a32c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = cur_model(torch.Tensor(inp[None]).cuda())\n",
    "pred_now = get_img_from_forward_output(out, cur_model, unnormalized=True).detach().cpu().numpy()[0]\n",
    "out, _ = model(torch.Tensor(inp[None]).cuda())\n",
    "pred_orig = get_img_from_forward_output(out, model, unnormalized=True).detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "tar_now = inptar[1]\n",
    "vmin0 = min(tar_now[0].min(), tar[0].min())\n",
    "vmax0 = max(tar_now[0].max(), tar[0].max())\n",
    "vmin1 = min(tar_now[1].min(), tar[1].min())\n",
    "vmax1 = min(tar_now[1].max(), tar[1].max())\n",
    "\n",
    "_,ax = plt.subplots(ncols=4,nrows=2, figsize=(10,5))\n",
    "ax[0,0].imshow(tar[0], vmin=vmin0, vmax=vmax0)\n",
    "ax[0,1].imshow(tar_now[0], vmin=vmin0, vmax=vmax0)\n",
    "ax[0,2].imshow(pred_orig[0], vmin=vmin0, vmax=vmax0)\n",
    "ax[0,3].imshow(pred_now[0], vmin=vmin0, vmax=vmax0)\n",
    "\n",
    "ax[1,0].imshow(tar[1], vmin=vmin1, vmax=vmax1)\n",
    "ax[1,1].imshow(tar_now[1], vmin=vmin1, vmax=vmax1)\n",
    "ax[1,2].imshow(pred_orig[1], vmin=vmin1, vmax=vmax1)\n",
    "ax[1,3].imshow(pred_now[1], vmin=vmin1, vmax=vmax1)\n",
    "ax[0,0].set_title('tar orig')\n",
    "ax[0,1].set_title('tar now')\n",
    "ax[0,2].set_title('pred orig')\n",
    "ax[0,3].set_title('pred now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f775bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_dict(model):\n",
    "    param_dict = {}\n",
    "    for k, v in model.named_parameters():\n",
    "        param_dict[k] = v\n",
    "    return param_dict\n",
    "\n",
    "def get_sortedfirstk(dic, reverse=True, k=10):\n",
    "    return sorted([(k,v) for k,v in dic.items()], key=lambda x: x[1], reverse=reverse)[:k]\n",
    "\n",
    "def compare_two_models(m1, m2):\n",
    "    m1_dict = get_param_dict(m1)\n",
    "    m2_dict = get_param_dict(m2)\n",
    "    maxpos_diff_dict = {}\n",
    "    maxneg_diff_dict = {}\n",
    "    avg_diff_dict = {}\n",
    "\n",
    "    for k in m1_dict.keys():\n",
    "        assert k in m2_dict.keys()\n",
    "        diff = m1_dict[k].data - m2_dict[k].data\n",
    "        maxpos_diff_dict[k] = diff.max().item()\n",
    "        maxneg_diff_dict[k] = diff.min().item()\n",
    "        avg_diff_dict[k] = diff.abs().mean().item()\n",
    "    return maxpos_diff_dict, maxneg_diff_dict, avg_diff_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ade73",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpos_diff_dict, maxneg_diff_dict, avg_diff_dict = compare_two_models(model, cur_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d11310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(arr):\n",
    "    for k,v in arr:\n",
    "        print(k,f'\\t {v:.3f}')\n",
    "\n",
    "# pretty_print(sorted([(k,v) for k,v in maxpos_diff_dict.items()], key=lambda x: x[1], reverse=True)[:10])\n",
    "pretty_print(get_sortedfirstk(maxpos_diff_dict, reverse=True, k=10))\n",
    "print('')\n",
    "print('')\n",
    "pretty_print(get_sortedfirstk(maxneg_diff_dict, reverse=False, k=10))\n",
    "# pretty_print(sorted([(k,v) for k,v in maxneg_diff_dict.items()], key=lambda x: x[1], reverse=True)[-10:])\n",
    "\n",
    "# plt.bar(range(len(maxpos_diff_dict)), list(maxpos_diff_dict.values()), align='center')\n",
    "# plt.xticks(range(len(maxpos_diff_dict)), list(maxpos_diff_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(1,3, figsize=(9,3))\n",
    "ax[0].plot(loss_dict['loss'])\n",
    "ax[1].plot(np.log(loss_dict['rec_loss']))\n",
    "ax[2].plot(loss_dict['reg_loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bce857e",
   "metadata": {},
   "source": [
    "## doing it for the whole validation dset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpos_val = {}\n",
    "maxneg_val = {}\n",
    "avg_val = {}\n",
    "\n",
    "maxpos_counter = {}\n",
    "maxneg_counter = {}\n",
    "avg_counter = {}\n",
    "dset_loss_dict = {'loss':[], 'rec_loss':[], 'reg_loss':[]}\n",
    "topk = 10\n",
    "\n",
    "\n",
    "for val_idx in range(len(val_dset)):\n",
    "    inp, tar = val_dset[val_idx]\n",
    "    reload(model)\n",
    "    cur_model = deepcopy(model)\n",
    "    loss_dict, inptar = train(cur_model, background_increment_factor = 0, ch0_offset=100, step_count=20, lr=1e-4,\n",
    "                        original_model=model,val_idx=val_idx, inner_pad=inp.shape[-1]//4)\n",
    "    dset_loss_dict['loss'] += loss_dict['loss']\n",
    "    dset_loss_dict['rec_loss'] += loss_dict['rec_loss']\n",
    "    dset_loss_dict['reg_loss'] += loss_dict['reg_loss']\n",
    "\n",
    "    \n",
    "    maxpos_diff_dict, maxneg_diff_dict, avg_diff_dict = compare_two_models(model, cur_model)\n",
    "    for k,v in get_sortedfirstk(maxpos_diff_dict, k=topk, reverse=True):\n",
    "        maxpos_val[k] = maxpos_val.get(k,0) + v\n",
    "        maxpos_counter[k] = maxpos_counter.get(k,0) + 1\n",
    "    \n",
    "    for k,v in get_sortedfirstk(maxneg_diff_dict, k=topk, reverse=False):\n",
    "        maxneg_val[k] = maxneg_val.get(k,0) + v\n",
    "        maxneg_counter[k] = maxneg_counter.get(k,0) + 1\n",
    "    \n",
    "    for k,v in get_sortedfirstk(avg_diff_dict, k=topk, reverse=True):\n",
    "        avg_val[k] = avg_val.get(k,0) + v\n",
    "        avg_counter[k] = avg_counter.get(k,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(maxpos_val, orient='index').sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(maxneg_counter, orient='index').sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0f073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
