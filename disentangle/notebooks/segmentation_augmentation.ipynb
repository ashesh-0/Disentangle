{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_objects(mask):\n",
    "    \"\"\"Extract individual objects from segmentation mask\"\"\"\n",
    "    labeled = label(mask)\n",
    "    return [mask[minr:maxr, minc:maxc] \n",
    "            for region in regionprops(labeled) \n",
    "            for (minr, minc, maxr, maxc) in [region.bbox]]\n",
    "\n",
    "def rotate_object(obj, angle):\n",
    "    \"\"\"Rotate object by arbitrary angle with padding\"\"\"\n",
    "    return rotate(obj, angle, resize=True, order=0, \n",
    "                 preserve_range=True).astype(bool)\n",
    "\n",
    "def random_placement(canvas, objects):\n",
    "    \"\"\"Place objects randomly on empty canvas\"\"\"\n",
    "    h, w = canvas.shape\n",
    "    for obj in objects:\n",
    "        oh, ow = obj.shape\n",
    "        if (max_x := w - ow) >= 0 and (max_y := h - oh) >= 0:\n",
    "            x, y = np.random.randint(0, max_x+1), np.random.randint(0, max_y+1)\n",
    "            canvas[y:y+oh, x:x+ow] |= obj\n",
    "    return canvas\n",
    "\n",
    "# Example usage\n",
    "mask = np.zeros((128, 128), dtype=bool)\n",
    "mask[10:31, 10:31] = True  # Square object\n",
    "rr, cc = np.ogrid[:128, :128]\n",
    "mask[(rr - 80)**2 + (cc - 80)**2 <= 225] = True  # Circular object (radius 15)\n",
    "\n",
    "# Processing pipeline\n",
    "objects = extract_objects(mask)\n",
    "rotated = [rotate_object(obj, np.random.uniform(0, 360)) for obj in objects]\n",
    "result = random_placement(np.zeros_like(mask), rotated)\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(mask, cmap='gray'), ax1.set_title('Original Mask')\n",
    "# ax2.imshow(np.hstack([rotate_object(obj, 45) for obj in objects]),  # Example 45Â° rotation\n",
    "#            cmap='gray'), ax2.set_title('Rotated Objects')\n",
    "ax2.imshow(result, cmap='gray'), ax2.set_title('Final Composition')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio.v3 as imageio\n",
    "# import napari\n",
    "\n",
    "# from micro_sam import instance_segmentation, util\n",
    "# from micro_sam.multi_dimensional_segmentation import automatic_3d_segmentation\n",
    "# from disentangle.core.tiff_reader import load_tiff\n",
    "\n",
    "# def cell_segmentation():\n",
    "#     \"\"\"Run the instance segmentation functionality from micro_sam for segmentation of\n",
    "#     HeLA cells. You need to run examples/annotator_2d.py:hela_2d_annotator once before\n",
    "#     running this script so that all required data is downloaded and pre-computed.\n",
    "#     \"\"\"\n",
    "#     image_path = \"/home/ashesh.ashesh/code/Disentangle/disentangle/notebooks/test_img.tiff\"\n",
    "#     embedding_path = \"../embeddings/embeddings-hela2d.zarr\"\n",
    "\n",
    "#     # Load the image, the SAM Model, and the pre-computed embeddings.\n",
    "#     image = load_tiff(image_path)\n",
    "#     predictor = util.get_sam_model()\n",
    "#     embeddings = util.precompute_image_embeddings(predictor, image, save_path=embedding_path)\n",
    "\n",
    "#     # Use the instance segmentation logic of Segment Anything.\n",
    "#     # This works by covering the image with a grid of points, getting the masks for all the poitns\n",
    "#     # and only keeping the plausible ones (according to the model predictions).\n",
    "#     # While the functionality here does the same as the implementation from Segment Anything,\n",
    "#     # we enable changing the hyperparameters, e.g. 'pred_iou_thresh', without recomputing masks and embeddings,\n",
    "#     # to support (interactive) evaluation of different hyperparameters.\n",
    "\n",
    "#     # Create the automatic mask generator class.\n",
    "#     amg = instance_segmentation.AutomaticMaskGenerator(predictor)\n",
    "\n",
    "#     # Initialize the mask generator with the image and the pre-computed embeddings.\n",
    "#     amg.initialize(image, embeddings, verbose=True)\n",
    "\n",
    "#     # Generate the instance segmentation. You can call this again for different values of 'pred_iou_thresh'\n",
    "#     # without having to call initialize again.\n",
    "#     instances = amg.generate(pred_iou_thresh=0.88)\n",
    "#     # instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#     #     instances, with_background=True\n",
    "#     # )\n",
    "\n",
    "#     # # instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#     # #     instances, shape=image.shape, with_background=True\n",
    "#     # # )\n",
    "\n",
    "#     # # Show the results.\n",
    "#     # v = napari.Viewer()\n",
    "#     # v.add_image(image)\n",
    "#     # v.add_labels(instances)\n",
    "#     # napari.run()\n",
    "#     return image, instances\n",
    "\n",
    "\n",
    "# def cell_segmentation_with_tiling():\n",
    "#     \"\"\"Run the instance segmentation functionality from micro_sam for segmentation of\n",
    "#     cells in a large image. You need to run examples/annotator_2d.py:wholeslide_annotator once before\n",
    "#     running this script so that all required data is downloaded and pre-computed.\n",
    "#     \"\"\"\n",
    "#     image_path = \"../data/whole-slide-example-image.tif\"\n",
    "#     embedding_path = \"../embeddings/whole-slide-embeddings.zarr\"\n",
    "\n",
    "#     # Load the image, the SAM Model, and the pre-computed embeddings.\n",
    "#     image = imageio.imread(image_path)\n",
    "#     predictor = util.get_sam_model()\n",
    "#     embeddings = util.precompute_image_embeddings(\n",
    "#         predictor, image, save_path=embedding_path, tile_shape=(1024, 1024), halo=(256, 256)\n",
    "#     )\n",
    "\n",
    "#     # Use the instance segmentation logic of Segment Anything.\n",
    "#     # This works by covering the image with a grid of points, getting the masks for all the poitns\n",
    "#     # and only keeping the plausible ones (according to the model predictions).\n",
    "#     # The functionality here is similar to the instance segmentation in Segment Anything,\n",
    "#     # but uses the pre-computed tiled embeddings.\n",
    "\n",
    "#     # Create the automatic mask generator class.\n",
    "#     amg = instance_segmentation.TiledAutomaticMaskGenerator(predictor)\n",
    "\n",
    "#     # Initialize the mask generator with the image and the pre-computed embeddings.\n",
    "#     amg.initialize(image, embeddings, verbose=True)\n",
    "\n",
    "#     # Generate the instance segmentation. You can call this again for different values of 'pred_iou_thresh'\n",
    "#     # without having to call initialize again.\n",
    "#     instances = amg.generate(pred_iou_thresh=0.88)\n",
    "#     instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#         instances, shape=image.shape, with_background=True\n",
    "#     )\n",
    "\n",
    "#     # Show the results.\n",
    "#     v = napari.Viewer()\n",
    "#     v.add_image(image)\n",
    "#     v.add_labels(instances)\n",
    "#     v.add_labels(instances)\n",
    "#     napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from cellpose import models, io\n",
    "from cellpose.io import imread\n",
    "\n",
    "io.logger_setup()\n",
    "\n",
    "# model_type='cyto' or 'nuclei' or 'cyto2' or 'cyto3'\n",
    "model = models.Cellpose(model_type='nuclei', gpu=True)\n",
    "\n",
    "# list of files\n",
    "# PUT PATH TO YOUR FILES HERE!\n",
    "files = ['/group/jug/ashesh/data/sox2_one_img.tiff']\n",
    "\n",
    "imgs = [imread(f) for f in files]\n",
    "nimg = len(imgs)\n",
    "\n",
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "channels = [[0,0]]\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
    "# you can set the average cell `diameter` in pixels yourself (recommended)\n",
    "# diameter can be a list or a single number for all images\n",
    "\n",
    "masks, flows, styles, diams = model.eval(imgs, diameter=None, channels=channels)\n",
    "\n",
    "\n",
    "### or to run one of the other models, or a custom model, specify a CellposeModel\n",
    "# model = models.CellposeModel(model_type='livecell_cp3')\n",
    "\n",
    "# masks, flows, styles = model.eval(imgs, diameter=30, channels=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(masks[0])\n",
    "ax[1].imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKGROUND_PATCHES= [ imgs[0][:200,:500].copy(), \n",
    "                     imgs[0][200:400,:400].copy(),\n",
    "                     imgs[0][100:300,:400].copy(),\n",
    "                     imgs[0][400:600,:300].copy()\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_objects(mask, img):\n",
    "    id_list = np.unique(mask)\n",
    "    # remove 0 \n",
    "    id_list = id_list[id_list != 0]\n",
    "    objects = []\n",
    "    for id in id_list:\n",
    "        obj_mask = mask == id\n",
    "        # find a bounding box around the object\n",
    "        y, x = np.where(obj_mask)\n",
    "        min_x, max_x = np.min(x), np.max(x)\n",
    "        min_y, max_y = np.min(y), np.max(y)\n",
    "        # extract the object\n",
    "        obj = img[min_y:max_y, min_x:max_x]\n",
    "        obj_mask = obj_mask[min_y:max_y, min_x:max_x]\n",
    "        # concaatenate the object and the mask\n",
    "        obj = np.concatenate((obj[None], obj_mask[None]), axis=0)\n",
    "        objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = find_objects(masks[0], imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "idx = 5\n",
    "ax[0].imshow(objects[idx][0])\n",
    "ax[1].imshow(objects[idx][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepinv.transform.projective import Homography\n",
    "import torch\n",
    "import kornia\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "\n",
    "\n",
    "def rotate(tensor, angle):\n",
    "    return kornia.geometry.transform.rotate(tensor, angle, \n",
    "                                            center=None, \n",
    "                                            mode='bilinear', \n",
    "                                            padding_mode='zeros', \n",
    "                                            align_corners=True)\n",
    "\n",
    "def random_flip(tensor, p = 0.5):\n",
    "    tensor = kornia.augmentation.RandomHorizontalFlip(p=p)(tensor)\n",
    "    tensor = kornia.augmentation.RandomVerticalFlip(p=p)(tensor)\n",
    "    return tensor\n",
    "\n",
    "def transform_object(tensor, max_angle=180):\n",
    "    assert tensor.ndim == 3, \"Tensor should be of shape (C, H, W)\"\n",
    "    # rotation.\n",
    "    angle = np.random.uniform(0, max_angle)*1.0\n",
    "    h,w = tensor.shape[-2:]\n",
    "    sz = int(np.ceil(np.sqrt(h**2 + w**2)))\n",
    "    tensor =torch.Tensor(tensor*1.0)\n",
    "    tensor = F.pad(tensor, ((sz-w)//2,(sz-w)//2,(sz-h)//2,(sz-h)//2))\n",
    "    object_rotated = rotate(tensor, torch.Tensor([angle]))\n",
    "    # torch.where(object_rotated != 0)\n",
    "    # crop it. \n",
    "    idx = object_rotated.nonzero()\n",
    "    # print(idx.shape)\n",
    "    x_min = idx[:, -2].min()\n",
    "    x_max = idx[:, -2].max()\n",
    "    y_min = idx[:, -1].min()\n",
    "    y_max = idx[:, -1].max()\n",
    "    print(x_min, x_max, y_min, y_max, object_rotated.shape)\n",
    "    object_rotated = object_rotated[...,x_min:x_max,y_min:y_max]\n",
    "    # randomly flip, it adds one more dimension.\n",
    "    object_rotated = random_flip(object_rotated)[0]\n",
    "    return object_rotated\n",
    "\n",
    "def get_object_ordering(objects, perm, square_size):\n",
    "    new_row_loc = []\n",
    "    next_pos = None\n",
    "    for i, idx in enumerate(perm):\n",
    "        if next_pos is None:\n",
    "            next_pos = objects[idx].shape[1]\n",
    "        else:\n",
    "            if next_pos > square_size:\n",
    "                new_row_loc.append(i)\n",
    "                next_pos = None\n",
    "    return new_row_loc        \n",
    "\n",
    "def get_combined_frame_dims(objects, perm, ordering):\n",
    "    combined_h = 0\n",
    "    combined_w = 0\n",
    "    row_h = 0\n",
    "    row_w = 0\n",
    "    i_start = 0\n",
    "    ordering_full = [x for x in ordering] + [len(objects)]\n",
    "    for i_end in ordering_full:\n",
    "        for i in range(i_start, i_end):\n",
    "            row_h = max(row_h, objects[perm[i]].shape[0])\n",
    "            row_w += objects[perm[i]].shape[1]\n",
    "        combined_h += row_h\n",
    "        combined_w = max(combined_w, row_w)\n",
    "        row_h = 0\n",
    "        row_w = 0\n",
    "        i_start = i_end\n",
    "    return combined_h, combined_w\n",
    "\n",
    "def get_background(size):\n",
    "    # create a white background\n",
    "    idx_list = np.random.permutation(len(BACKGROUND_PATCHES))\n",
    "    for idx in idx_list:\n",
    "        patch = BACKGROUND_PATCHES[idx]\n",
    "        h, w = patch.shape\n",
    "        if h >= size[0] and w >= size[1]:\n",
    "            # \n",
    "            patch = random_flip(patch * 1.0)[0,0]\n",
    "            print('after random_flip', patch.shape)\n",
    "            # crop it.\n",
    "            x_min = np.random.randint(0, h - size[0])\n",
    "            x_max = x_min + size[0]\n",
    "            y_min = np.random.randint(0, w - size[1])\n",
    "            y_max = y_min + size[1]\n",
    "            return patch[x_min:x_max, y_min:y_max] * 1.0\n",
    "        elif h >= size[1] and w >= size[0]:\n",
    "            # rotate by 90 degrees\n",
    "            patch = rotate(patch, 90) if np.random.rand() > 0.5 else rotate(patch, -90)\n",
    "            patch = random_flip(patch* 1.0)[0,0]\n",
    "            print('after random_flip', patch.shape)\n",
    "            h, w = patch.shape\n",
    "            # crop it.\n",
    "            x_min = np.random.randint(0, h - size[1])\n",
    "            x_max = x_min + size[1]\n",
    "            y_min = np.random.randint(0, w - size[0])\n",
    "            y_max = y_min + size[0]\n",
    "            return patch[x_min:x_max, y_min:y_max] * 1.0\n",
    "        \n",
    "    raise ValueError(f\"No background patch found that fits the size\")\n",
    "\n",
    "def get_rectrangle_ratio(objects, perm, ordering):\n",
    "    combined_h, combined_w = get_combined_frame_dims(objects, perm, ordering)\n",
    "    return max(combined_h / combined_w, combined_w / combined_h)\n",
    "\n",
    "def render_objects(objects, perm, ordering):\n",
    "    combined_h, combined_w = get_combined_frame_dims(objects, perm, ordering)\n",
    "    final_frame = get_background((combined_h, combined_w))\n",
    "    ordering_full = [x for x in ordering] + [len(objects)]\n",
    "\n",
    "    combined_h = 0\n",
    "    # combined_w = 0\n",
    "    row_h = 0\n",
    "    row_w = 0\n",
    "    i_start = 0\n",
    "    for i_end in ordering_full:\n",
    "        for i in range(i_start, i_end):\n",
    "            h,w = objects[perm[i]].shape\n",
    "            mask = objects[perm[i]] > 0\n",
    "            final_frame[combined_h:combined_h+h, row_w:row_w+w] = final_frame[combined_h:combined_h+h, row_w:row_w+w] + mask*objects[perm[i]]\n",
    "            row_h = max(row_h, objects[perm[i]].shape[0])\n",
    "            row_w += objects[perm[i]].shape[1]\n",
    "        combined_h += row_h\n",
    "        # combined_w = max(combined_w, row_w)\n",
    "        row_h = 0\n",
    "        row_w = 0\n",
    "        i_start = i_end\n",
    "    return final_frame\n",
    "\n",
    "\n",
    "def combine_objects(objects):\n",
    "    area = 0\n",
    "    for obj in objects:\n",
    "        h,w = obj.shape\n",
    "        area += h*w\n",
    "\n",
    "    square_size = int(np.ceil(np.sqrt(area)))\n",
    "    h_max = max([x.shape[0] for x in objects])\n",
    "    w_max = max([x.shape[1] for x in objects])\n",
    "    square_size = max(max(square_size, h_max), w_max)\n",
    "    # find a generator for all permutations from 0 to n-1\n",
    "\n",
    "    n = len(objects)  # Change as needed\n",
    "    best_perm = None\n",
    "    best_ratio = None\n",
    "    for perm in itertools.permutations(range(n)):\n",
    "        ordering = get_object_ordering(objects, perm, square_size)\n",
    "        ratio = get_rectrangle_ratio(objects, ordering)\n",
    "        if best_ratio is None or ratio < best_ratio:\n",
    "            best_perm = perm\n",
    "            best_ratio = ratio\n",
    "\n",
    "    combined_img = render_objects(objects, best_perm, square_size)\n",
    "    return combined_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(18,3),ncols=6)\n",
    "for i in range(6):\n",
    "    ax[i].imshow(get_background((160, 160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_outputs = []\n",
    "idx_list = np.random.randint(0, len(objects), 4)\n",
    "for i in range(10):\n",
    "    trans_objects = []\n",
    "    for i in idx_list:\n",
    "        tensor =torch.Tensor(objects[i]*1.0)\n",
    "        new_obj = transform_object((tensor[0]*tensor[1])[None], max_angle=180)\n",
    "        trans_objects.append(new_obj.squeeze())\n",
    "        # print(obj.shape)\n",
    "\n",
    "    output = render_objects(trans_objects, [0,1,2,3], [2])\n",
    "    rendered_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(15,6),ncols=5,nrows=2)\n",
    "for i in range(10):\n",
    "    ax[i//5][i%5].imshow(rendered_outputs[i])\n",
    "    # ax[i//3][i%3].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
