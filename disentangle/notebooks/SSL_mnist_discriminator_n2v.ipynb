{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Here, we play with discriminators. The idea is to be able to discriminate between the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.configs.mnist_config import get_config\n",
    "from disentangle.training import create_dataset\n",
    "# from disentangle.loss.ssl_finetuning import finetune_two_forward_passes\n",
    "from disentangle.loss.ssl_with_discriminator_n2v import finetune_with_D_two_forward_passes_n2v\n",
    "from disentangle.nets.model_utils import create_model\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "k_moment_value = 2\n",
    "best_t_estimate = 0.5\n",
    "psnr_evaluation = False\n",
    "\n",
    "max_step_count = 200_000\n",
    "skip_pixels=0\n",
    "validation_step_freq = 5000\n",
    "# k_augmentations = 1\n",
    "enable_mixing_aug = False\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "# D_mode='-1_1'\n",
    "# D_realimg_key='inp'\n",
    "# D_fakeimg_key='predInp1'\n",
    "# D_gp_lambda=0.0\n",
    "# external_real_data_probability = 1.0\n",
    "# train_G_on_both_real_and_fake = False\n",
    "# use_embedding_network = True\n",
    "# embedding_zdim = 16\n",
    "# start_adv_loss_step = 20_000\n",
    "\n",
    "# enable_supervised_loss = False\n",
    "# how many discriminator steps per generator step\n",
    "# k_Dsteps_perG = 0.1\n",
    "# D_loss_scalar = (0.0001, 0.0001)\n",
    "# D_loss_scalar = (0.0, 0.0)\n",
    "# D_loss_scalar = (1.0, 1.0)\n",
    "# D_only_one_channel_idx = None\n",
    "# Ddense = True\n",
    "# tv_weight = 0.2\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embFpath = f'/group/jug/ashesh/data/MNIST/models/mnist_input_compressor_Dwn4_Z{embedding_zdim}.pth'\n",
    "\n",
    "config = get_config()\n",
    "config.data.color_ch = 2\n",
    "datadir = '/group/jug/ashesh/data/MNIST/'\n",
    "train_dset, val_dset = create_dataset(config, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert D_realimg_key in ['inp', 'inv_inp2', 'predInp1']\n",
    "# if D_realimg_key == 'inp':\n",
    "#     assert external_real_data_probability == 1.0\n",
    "#     assert train_G_on_both_real_and_fake == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean, data_std = train_dset.get_mean_std()\n",
    "model = create_model(config, data_mean, data_std, val_idx_manager=None)\n",
    "model = model.cuda()\n",
    "model.set_params_to_same_device_as(torch.Tensor([1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_dset.train_mode()\n",
    "data = []\n",
    "k_times = 5\n",
    "for _ in tqdm(range(k_times)):\n",
    "    for idx in range(len(train_dset)):\n",
    "        _, tar = train_dset[idx]\n",
    "        data.append(tar)\n",
    "\n",
    "data = torch.stack(data, dim=0)\n",
    "data_normalized = data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(20,4),ncols=10,nrows=2)\n",
    "for i in range(10):\n",
    "    ax[0,i].imshow(data[i,0].cpu().numpy(), cmap='gray')\n",
    "    ax[0,i].axis('off')\n",
    "    ax[1,i].imshow(data[i,1].cpu().numpy(), cmap='gray')\n",
    "    ax[1,i].axis('off')\n",
    "# reduce the space between subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.loss.ssl_finetuning import get_stats_loss_func\n",
    "import numpy as np\n",
    "stats_loss_func = get_stats_loss_func(data_normalized, k_moment_value)\n",
    "stats_loss_func(torch.Tensor(data_normalized[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nimgs = 5*2\n",
    "imgsz = 2\n",
    "_,ax = plt.subplots(figsize=(6*imgsz,imgsz*nimgs//2), ncols=6, nrows=nimgs//2)\n",
    "ax[0,0].set_title('input')\n",
    "ax[0,1].set_title('target C1')\n",
    "ax[0,2].set_title('target C2')\n",
    "\n",
    "ax[0,3].set_title('input')\n",
    "ax[0,4].set_title('target C1')\n",
    "ax[0,5].set_title('target C2')\n",
    "\n",
    "for i in range(nimgs):\n",
    "    row_idx = i//2\n",
    "    col_idx = 3 * (i%2)\n",
    "    idx = np.random.randint(len(train_dset))\n",
    "    inp, tar = train_dset[idx]\n",
    "    ax[row_idx,col_idx+0].imshow(inp[0], cmap='gray')\n",
    "    ax[row_idx,col_idx+0].axis('off')\n",
    "    ax[row_idx,col_idx+1].imshow(tar[0], cmap='gray')\n",
    "    ax[row_idx,col_idx+1].axis('off')\n",
    "    ax[row_idx,col_idx+2].imshow(tar[1], cmap='gray')\n",
    "    ax[row_idx,col_idx+2].axis('off')\n",
    "# remve space between subplots\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.mask_generator import get_n2v_based_input_target\n",
    "nimgs = 5\n",
    "imgsz = 2\n",
    "_,ax = plt.subplots(figsize=(6*imgsz,imgsz*nimgs), ncols=6, nrows=nimgs)\n",
    "for row_idx in range(nimgs):\n",
    "    idx = np.random.randint(len(train_dset))\n",
    "    inp, tar = train_dset[idx]\n",
    "    inp = torch.Tensor(inp[None])\n",
    "    inp_1, inp_2, inp_2_tar = get_n2v_based_input_target(inp)\n",
    "    ax[row_idx,0].imshow(inp[0,0].cpu().numpy(), cmap='gray')\n",
    "    ax[row_idx,0].axis('off')\n",
    "    ax[row_idx,1].imshow(inp_1[0,0].cpu().numpy(), cmap='gray')\n",
    "    ax[row_idx,1].axis('off')\n",
    "    ax[row_idx,2].imshow(inp_2[0,0].cpu().numpy(), cmap='gray')\n",
    "    ax[row_idx,2].axis('off')\n",
    "    ax[row_idx,3].imshow((inp_1*inp_2)[0,0].cpu().numpy(), cmap='gray')\n",
    "    ax[row_idx,3].axis('off')\n",
    "    ax[row_idx,4].imshow(tar[0], cmap='gray')\n",
    "    ax[row_idx,4].axis('off')\n",
    "    ax[row_idx,5].imshow(tar[1], cmap='gray')\n",
    "    ax[row_idx,5].axis('off')\n",
    "\n",
    "# remove space between subplots\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "ax[0,0].set_title('Orig input')\n",
    "ax[0,1].set_title('Input')\n",
    "ax[0,2].set_title('Target')\n",
    "ax[0,3].set_title('Input x Target')\n",
    "ax[0,4].set_title('Orig Target C1')\n",
    "ax[0,5].set_title('Orig Target C2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.mnist_dset import get_transform_obj\n",
    "transform_all = get_transform_obj(config.data.ch0_transforms_params, config.data.ch1_transforms_params, device='cuda')\n",
    "# if D_realimg_key == 'inp':\n",
    "#         external_real_data = data_normalized.mean(axis=1, keepdims=True)\n",
    "\n",
    "# define a learnable scalar and an offset \n",
    "factor1 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset1 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "\n",
    "factor2 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "mixing_ratio = torch.nn.Parameter(torch.tensor(best_t_estimate).cuda())\n",
    "\n",
    "optimization_params = model.parameters()\n",
    "finetuning_output_dict = finetune_with_D_two_forward_passes_n2v(\n",
    "                                                        model, \n",
    "                                           val_dset, \n",
    "                                           val_dset, \n",
    "                                           transform_all, \n",
    "                                            max_step_count=max_step_count, \n",
    "                                            batch_size=batch_size,                    \n",
    "                                            scalar_params_dict={'factor1':factor1, 'offset1':offset1, 'mixing_ratio':mixing_ratio},\n",
    "                                            validation_step_freq=validation_step_freq,\n",
    "                                            optimization_params_dict={'lr':lr, 'parameters': optimization_params}, \n",
    "                                            num_workers=num_workers,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(finetuning_output_dict['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = val_dset[0]\n",
    "inp = torch.Tensor(inp[None]).cuda()\n",
    "inp = inp.repeat((1,2,1,1))\n",
    "pred, _ = model(torch.Tensor(inp).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[0,0].detach().cpu().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from disentangle.analysis.plot_utils import clean_ax\n",
    "nimgs = 3\n",
    "imgsz = 2\n",
    "offset = imgsz*nimgs*0.3\n",
    "_,ax = plt.subplots(figsize=(4*imgsz,2*imgsz*nimgs + offset),nrows=2*nimgs,ncols=4)\n",
    "\n",
    "val_dset.train_mode()\n",
    "for img_idx in range(nimgs):\n",
    "    inp, tar = val_dset[0]\n",
    "    inp = torch.Tensor(inp[None]).cuda()\n",
    "    inp = inp.repeat((1,2,1,1))\n",
    "    pred, _ = model(inp)\n",
    "\n",
    "\n",
    "    ax[2*img_idx,0].imshow(inp[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "    ax[2*img_idx,1].imshow(pred[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "    ax[2*img_idx,2].imshow(pred[0,1].cpu().detach().numpy(), cmap='gray')\n",
    "    ax[2*img_idx,3].imshow((pred[0,0] + pred[0,1]).cpu().detach().numpy(), cmap='gray')\n",
    "    ax[2*img_idx +1,1].imshow(tar[0].cpu().detach().numpy(), cmap='gray')\n",
    "    ax[2*img_idx +1,2].imshow(tar[1].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "    ax[2*img_idx,0].set_title('Input')\n",
    "    ax[2*img_idx,1].set_title('Pred ch0')\n",
    "    ax[2*img_idx,2].set_title('Pred ch1')\n",
    "    ax[2*img_idx,3].set_title('Pred ch0 + ch1')\n",
    "    ax[2*img_idx +1,1].set_title('Target ch0')\n",
    "    ax[2*img_idx +1,2].set_title('Target ch1')\n",
    "    ax[2*img_idx+1,0].axis('off')\n",
    "    ax[2*img_idx+1,3].axis('off')\n",
    "\n",
    "# remove space between subplots\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.02)\n",
    "clean_ax(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
