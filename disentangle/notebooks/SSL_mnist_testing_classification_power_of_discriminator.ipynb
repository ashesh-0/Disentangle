{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.configs.mnist_config import get_config\n",
    "from disentangle.training import create_dataset\n",
    "from disentangle.loss.ssl_finetuning import finetune_two_forward_passes\n",
    "from disentangle.nets.model_utils import create_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_moment_value = 2\n",
    "best_t_estimate = 0.5\n",
    "psnr_evaluation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "datadir = '/group/jug/ashesh/data/MNIST/'\n",
    "train_dset, val_dset = create_dataset(config, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean, data_std = train_dset.get_mean_std()\n",
    "model = create_model(config, data_mean, data_std, val_idx_manager=None)\n",
    "model = model.cuda()\n",
    "model.set_params_to_same_device_as(torch.Tensor([1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.loss.ssl_finetuning import get_stats_loss_func\n",
    "import numpy as np\n",
    "\n",
    "ch0 = val_dset._ch0_images\n",
    "ch1 = val_dset._ch1_images\n",
    "n = min(len(ch0), len(ch1))\n",
    "data = np.stack([ch0[:n], ch1[:n]], axis=1)\n",
    "print(data.shape)\n",
    "stats_loss_func = get_stats_loss_func(data/255.0, k_moment_value)\n",
    "stats_loss_func(torch.Tensor(data[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nimgs = 5*2\n",
    "imgsz = 2\n",
    "_,ax = plt.subplots(figsize=(6*imgsz,imgsz*nimgs//2), ncols=6, nrows=nimgs//2)\n",
    "ax[0,0].set_title('input')\n",
    "ax[0,1].set_title('target C1')\n",
    "ax[0,2].set_title('target C2')\n",
    "\n",
    "ax[0,3].set_title('input')\n",
    "ax[0,4].set_title('target C1')\n",
    "ax[0,5].set_title('target C2')\n",
    "\n",
    "for i in range(nimgs):\n",
    "    row_idx = i//2\n",
    "    col_idx = 3 * (i%2)\n",
    "    idx = np.random.randint(len(train_dset))\n",
    "    inp, tar = train_dset[idx]\n",
    "    ax[row_idx,col_idx+0].imshow(inp[0], cmap='gray')\n",
    "    ax[row_idx,col_idx+0].axis('off')\n",
    "    ax[row_idx,col_idx+1].imshow(tar[0], cmap='gray')\n",
    "    ax[row_idx,col_idx+1].axis('off')\n",
    "    ax[row_idx,col_idx+2].imshow(tar[1], cmap='gray')\n",
    "    ax[row_idx,col_idx+2].axis('off')\n",
    "# remve space between subplots\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_count = 200\n",
    "lambda_term = 0.1\n",
    "lr = 1e-4\n",
    "batch_size = 256\n",
    "enable_gradient_penalty = True\n",
    "discriminator_mode = '-1_1'\n",
    "assert discriminator_mode in ['-1_1', 'wgan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.nets.discriminator import Discriminator\n",
    "from disentangle.loss.discriminator_loss import update_gradients_with_discriminator_loss\n",
    "from tqdm import tqdm\n",
    "discriminator = Discriminator(channels=28*28, first_out_channel=128, dense=True).cuda()\n",
    "opt = torch.optim.Adam(discriminator.parameters(), lr=lr, weight_decay=0)\n",
    "dloader = torch.utils.data.DataLoader(train_dset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "d_pred_real = []\n",
    "d_pred_fake = []\n",
    "d_loss_gradient_penalty = []\n",
    "bar = tqdm(total=max_step_count)\n",
    "for step in range(max_step_count):\n",
    "    for i, (inp, tar) in enumerate(dloader):\n",
    "        opt.zero_grad()\n",
    "        if i >= 1:\n",
    "            break\n",
    "        # inp = inp.cuda()\n",
    "        ch1 = tar[:,:1].cuda()\n",
    "        ch2 = tar[:,1:2].cuda()\n",
    "        # print(inp.shape)\n",
    "        # print(tar.shape)\n",
    "        # print(inp[0].shape)\n",
    "        # print(tar[0].shape)\n",
    "        # print(tar[1].shape)\n",
    "        # print(tar[2].shape)\n",
    "        # print(tar[3].shape)\n",
    "\n",
    "        loss_dict = update_gradients_with_discriminator_loss(discriminator, ch1, ch2, lambda_term, enable_gradient_penalty=enable_gradient_penalty, mode=discriminator_mode)\n",
    "        opt.step()\n",
    "        # {'d_pred_real': d_pred_real.item(), 'd_pred_fake': d_pred_fake.item(), 'd_loss_gradient_penalty': d_loss_gradient_penalty.item()}\n",
    "        d_pred_real.append(loss_dict['d_pred_real'])\n",
    "        d_pred_fake.append(loss_dict['d_pred_fake'])\n",
    "        d_loss_gradient_penalty.append(loss_dict['d_loss_gradient_penalty'])\n",
    "        bar.update(1)\n",
    "        bar.set_postfix(d_pred_real=np.mean(d_pred_real), d_pred_fake=np.mean(d_pred_fake), d_loss_gradient_penalty=np.mean(d_loss_gradient_penalty))\n",
    "    \n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_,ax  = plt.subplots(figsize=(6,3),ncols=2)\n",
    "pd.Series(d_pred_real).rolling(10).mean().plot(label='d_pred_real', ax=ax[0])\n",
    "pd.Series(d_pred_fake).rolling(10).mean().plot(label='d_pred_fake', ax=ax[0])\n",
    "pd.Series(d_loss_gradient_penalty).rolling(10).mean().plot(label='gradient_penalty', ax=ax[1], logy=True)\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.mnist_dset import get_transform_obj\n",
    "transform_all = get_transform_obj(config.data.ch0_transforms_params, config.data.ch1_transforms_params, device='cuda')\n",
    "\n",
    "# define a learnable scalar and an offset \n",
    "factor1 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset1 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "\n",
    "factor2 = torch.nn.Parameter(torch.tensor(1.0).cuda())\n",
    "offset2 = torch.nn.Parameter(torch.tensor(0.0).cuda())\n",
    "mixing_ratio = torch.nn.Parameter(torch.tensor(best_t_estimate).cuda())\n",
    "\n",
    "optimization_params = model.parameters()\n",
    "finetuning_output_dict = finetune_two_forward_passes(model, val_dset, val_dset, transform_all, \n",
    "                                                    max_step_count=max_step_count, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    skip_pixels=skip_pixels,\n",
    "                                                    validation_step_freq=validation_step_freq,\n",
    "                                scalar_params_dict={'factor1':factor1, 'offset1':offset1, 'factor2':factor2, 'offset2':offset2, 'mixing_ratio':mixing_ratio},\n",
    "                                optimization_params_dict={'lr':lr, 'parameters': optimization_params},\n",
    "                                # lookback=lookback,\n",
    "                                k_augmentations=k_augmentations,\n",
    "                                stats_enforcing_loss_fn=lambda x : stats_loss_func(x),\n",
    "                                sample_mixing_ratio=enable_mixing_aug,\n",
    "                                psnr_evaluation=psnr_evaluation,\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.ssl_plots import plot_finetuning_loss\n",
    "plot_finetuning_loss(finetuning_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_output_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(12,6),nrows=2,ncols=4)\n",
    "\n",
    "val_dset.train_mode()\n",
    "inp, tar = val_dset[0]\n",
    "pred, _ = model(torch.Tensor(inp[None]).cuda())\n",
    "\n",
    "ax[0,0].imshow(inp[0].cpu().detach().numpy(), cmap='gray')\n",
    "ax[0,1].imshow(pred[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "ax[0,2].imshow(pred[0,1].cpu().detach().numpy(), cmap='gray')\n",
    "ax[0,3].imshow((pred[0,0] + pred[0,1]).cpu().detach().numpy(), cmap='gray')\n",
    "ax[1,0].imshow(tar[0].cpu().detach().numpy(), cmap='gray')\n",
    "ax[1,1].imshow(tar[1].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "ax[0,0].set_title('Input')\n",
    "ax[0,1].set_title('Pred ch0')\n",
    "ax[0,2].set_title('Pred ch1')\n",
    "ax[0,3].set_title('Pred ch0 + ch1')\n",
    "ax[1,0].set_title('Target ch0')\n",
    "ax[1,1].set_title('Target ch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
