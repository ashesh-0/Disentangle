{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio.v3 as imageio\n",
    "# import napari\n",
    "\n",
    "# from micro_sam import instance_segmentation, util\n",
    "# from micro_sam.multi_dimensional_segmentation import automatic_3d_segmentation\n",
    "# from disentangle.core.tiff_reader import load_tiff\n",
    "\n",
    "# def cell_segmentation():\n",
    "#     \"\"\"Run the instance segmentation functionality from micro_sam for segmentation of\n",
    "#     HeLA cells. You need to run examples/annotator_2d.py:hela_2d_annotator once before\n",
    "#     running this script so that all required data is downloaded and pre-computed.\n",
    "#     \"\"\"\n",
    "#     image_path = \"/home/ashesh.ashesh/code/Disentangle/disentangle/notebooks/test_img.tiff\"\n",
    "#     embedding_path = \"../embeddings/embeddings-hela2d.zarr\"\n",
    "\n",
    "#     # Load the image, the SAM Model, and the pre-computed embeddings.\n",
    "#     image = load_tiff(image_path)\n",
    "#     predictor = util.get_sam_model()\n",
    "#     embeddings = util.precompute_image_embeddings(predictor, image, save_path=embedding_path)\n",
    "\n",
    "#     # Use the instance segmentation logic of Segment Anything.\n",
    "#     # This works by covering the image with a grid of points, getting the masks for all the poitns\n",
    "#     # and only keeping the plausible ones (according to the model predictions).\n",
    "#     # While the functionality here does the same as the implementation from Segment Anything,\n",
    "#     # we enable changing the hyperparameters, e.g. 'pred_iou_thresh', without recomputing masks and embeddings,\n",
    "#     # to support (interactive) evaluation of different hyperparameters.\n",
    "\n",
    "#     # Create the automatic mask generator class.\n",
    "#     amg = instance_segmentation.AutomaticMaskGenerator(predictor)\n",
    "\n",
    "#     # Initialize the mask generator with the image and the pre-computed embeddings.\n",
    "#     amg.initialize(image, embeddings, verbose=True)\n",
    "\n",
    "#     # Generate the instance segmentation. You can call this again for different values of 'pred_iou_thresh'\n",
    "#     # without having to call initialize again.\n",
    "#     instances = amg.generate(pred_iou_thresh=0.88)\n",
    "#     # instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#     #     instances, with_background=True\n",
    "#     # )\n",
    "\n",
    "#     # # instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#     # #     instances, shape=image.shape, with_background=True\n",
    "#     # # )\n",
    "\n",
    "#     # # Show the results.\n",
    "#     # v = napari.Viewer()\n",
    "#     # v.add_image(image)\n",
    "#     # v.add_labels(instances)\n",
    "#     # napari.run()\n",
    "#     return image, instances\n",
    "\n",
    "\n",
    "# def cell_segmentation_with_tiling():\n",
    "#     \"\"\"Run the instance segmentation functionality from micro_sam for segmentation of\n",
    "#     cells in a large image. You need to run examples/annotator_2d.py:wholeslide_annotator once before\n",
    "#     running this script so that all required data is downloaded and pre-computed.\n",
    "#     \"\"\"\n",
    "#     image_path = \"../data/whole-slide-example-image.tif\"\n",
    "#     embedding_path = \"../embeddings/whole-slide-embeddings.zarr\"\n",
    "\n",
    "#     # Load the image, the SAM Model, and the pre-computed embeddings.\n",
    "#     image = imageio.imread(image_path)\n",
    "#     predictor = util.get_sam_model()\n",
    "#     embeddings = util.precompute_image_embeddings(\n",
    "#         predictor, image, save_path=embedding_path, tile_shape=(1024, 1024), halo=(256, 256)\n",
    "#     )\n",
    "\n",
    "#     # Use the instance segmentation logic of Segment Anything.\n",
    "#     # This works by covering the image with a grid of points, getting the masks for all the poitns\n",
    "#     # and only keeping the plausible ones (according to the model predictions).\n",
    "#     # The functionality here is similar to the instance segmentation in Segment Anything,\n",
    "#     # but uses the pre-computed tiled embeddings.\n",
    "\n",
    "#     # Create the automatic mask generator class.\n",
    "#     amg = instance_segmentation.TiledAutomaticMaskGenerator(predictor)\n",
    "\n",
    "#     # Initialize the mask generator with the image and the pre-computed embeddings.\n",
    "#     amg.initialize(image, embeddings, verbose=True)\n",
    "\n",
    "#     # Generate the instance segmentation. You can call this again for different values of 'pred_iou_thresh'\n",
    "#     # without having to call initialize again.\n",
    "#     instances = amg.generate(pred_iou_thresh=0.88)\n",
    "#     instances = instance_segmentation.mask_data_to_segmentation(\n",
    "#         instances, shape=image.shape, with_background=True\n",
    "#     )\n",
    "\n",
    "#     # Show the results.\n",
    "#     v = napari.Viewer()\n",
    "#     v.add_image(image)\n",
    "#     v.add_labels(instances)\n",
    "#     v.add_labels(instances)\n",
    "#     napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from cellpose import models, io\n",
    "from cellpose.io import imread\n",
    "\n",
    "io.logger_setup()\n",
    "\n",
    "# model_type='cyto' or 'nuclei' or 'cyto2' or 'cyto3'\n",
    "model = models.Cellpose(model_type='nuclei', gpu=True)\n",
    "\n",
    "# list of files\n",
    "# PUT PATH TO YOUR FILES HERE!\n",
    "files = ['/home/ashesh.ashesh/code/Disentangle/disentangle/notebooks/test_img.tiff']\n",
    "\n",
    "imgs = [imread(f) for f in files]\n",
    "nimg = len(imgs)\n",
    "\n",
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "channels = [[0,0]]\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
    "# you can set the average cell `diameter` in pixels yourself (recommended)\n",
    "# diameter can be a list or a single number for all images\n",
    "\n",
    "masks, flows, styles, diams = model.eval(imgs, diameter=None, channels=channels)\n",
    "\n",
    "\n",
    "### or to run one of the other models, or a custom model, specify a CellposeModel\n",
    "# model = models.CellposeModel(model_type='livecell_cp3')\n",
    "\n",
    "# masks, flows, styles = model.eval(imgs, diameter=30, channels=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "masks, flows, styles, diams = model.eval(imgs, diameter=None, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(masks[0].flatten()).value_counts().sort_index()\n",
    "# np.unique(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(masks[0])\n",
    "ax[1].imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "from disentangle.core.tiff_reader import load_tiff\n",
    "\n",
    "model = models.Cellpose(gpu=True, model_type='nuclei')\n",
    "channels = [0,0]\n",
    "imgs_2D =  load_tiff(\"/home/ashesh.ashesh/code/Disentangle/disentangle/notebooks/test_img.tiff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_2D = imgs_2D[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_2D = imgs_2D[:512, :512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, flows, styles, diams = model.eval([imgs_2D], diameter=None, flow_threshold=None, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
