{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Any\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# def get_name(metric_str):\n",
    "#     if 'Range Invariant Multiscale SSIM' in metric_str:\n",
    "#         return 'RISSIM'\n",
    "#     elif 'Multiscale SSIM' in metric_str:\n",
    "#         return 'MSSIM'\n",
    "#     elif 'PSNR' in metric_str:\n",
    "#         return 'PSNR'\n",
    "#     else:\n",
    "#         raise ValueError(\"Unknown metric name in str:\\t\", metric_str)\n",
    "\n",
    "# def get_metric_tokens(metric_str):\n",
    "#     tokens = [x for x in metric_str.split(\" \") if x != '']\n",
    "#     tokens = [x for x in tokens if '+-' in x]\n",
    "#     return tokens\n",
    "\n",
    "# class Metric(BaseModel):\n",
    "#     name: str  = \"\"\n",
    "#     mean: List[float]  = []\n",
    "#     std: List[float]  = []\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_str(cls, value:str) -> Any:\n",
    "#         if isinstance(value, str):\n",
    "#             name = get_name(value)\n",
    "#             tokens = get_metric_tokens(value)\n",
    "#             mean_data = [float(x.split('+')[0]) for x in tokens]\n",
    "#             std_data = [float(x.split('-')[1]) for x in tokens]\n",
    "#             return cls(name=name, mean=mean_data, std=std_data)\n",
    "\n",
    "#         return value\n",
    "\n",
    "# Metric.from_str('Range Invariant Multiscale SSIM on Highres 0.988+-0.004 0.995+-0.001    0.994+-0.0044')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "keys = {\"2ms\":\"2406/D25-M3-S0-L8/4\",\n",
    "        \"3ms\":\"2406/D25-M3-S0-L8/5\",\n",
    "        \"5ms\":\"2406/D25-M3-S0-L8/6\",\n",
    "        \"20ms\":\"2406/D25-M3-S0-L8/14\",\n",
    "        \"500ms\":\"2406/D25-M3-S0-L8/17\"}\n",
    "\n",
    "output_data_dir = '/group/jug/ashesh/naturemethods/nicola_outofNoiseDistribution/'\n",
    "\n",
    "def trained_on_ms(trained_ms):\n",
    "    model_token = keys[trained_ms].replace('/','_')\n",
    "    return f'stats_training_disentangle_{model_token}.pkl'\n",
    "\n",
    "def prediction_for_trained_on_ms(trained_ms):\n",
    "    return trained_on_ms(trained_ms).replace('stats_training_', 'pred_training_').replace('.pkl', '_1.tif')\n",
    "\n",
    "# stats_training_disentangle_2406_D25-M3-S0-L8_17.pkl\n",
    "all_ms = ['2ms', '3ms', '5ms', '20ms', '500ms']\n",
    "data_dict = defaultdict(dict)\n",
    "for eval_ms in all_ms:\n",
    "    for trained_ms in all_ms:\n",
    "        #           /group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/data.dset_type-3ms/stats_training_disentangle_2406_D25-M3-S0-L8_4.pkl\n",
    "        with open(f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/data.dset_type-{eval_ms}/{trained_on_ms(trained_ms)}', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            data_dict[eval_ms][trained_ms] = data\n",
    "# eval_ms = '2ms'\n",
    "# trained_ms = '500ms'\n",
    "# with open(f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/data.dset_type-{eval_ms}/{trained_on_ms(trained_ms)}', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['2ms']['500ms'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['2ms']['500ms']['msssim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_metric_data_df(metric:str,nchannels:int):\n",
    "    metric_dict = [defaultdict(dict) for _ in range(nchannels)]\n",
    "    metric_err_dict = [defaultdict(dict) for _ in range(nchannels)]\n",
    "    for eval_ms in all_ms:\n",
    "        for trained_ms in all_ms:\n",
    "            tmp_arr = data_dict[eval_ms][trained_ms][metric]\n",
    "            for i in range(nchannels):\n",
    "                met_mean, met_std = tmp_arr[i]\n",
    "                metric_dict[i][eval_ms][trained_ms] = met_mean\n",
    "                metric_err_dict[i][eval_ms][trained_ms] = met_std\n",
    "    \n",
    "    df_arr = [pd.DataFrame.from_dict(metric_dict[ch_idx]).T for ch_idx in range(nchannels)]\n",
    "    err_df_arr = [pd.DataFrame.from_dict(metric_err_dict[ch_idx]).T for ch_idx in range(nchannels)]\n",
    "    return df_arr, err_df_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "metric_list = ['rangeinvpsnr', 'ssim', 'ms3im', 'microssim', 'msssim']\n",
    "metric = 'microssim'\n",
    "savefig = True\n",
    "\n",
    "assert metric in metric_list\n",
    "nchannels = len(data_dict['2ms']['2ms']['rangeinvpsnr'])\n",
    "df_arr, err_df_arr = get_metric_data_df(metric, nchannels)\n",
    "\n",
    "\n",
    "\n",
    "_,ax = plt.subplots(figsize=(3*nchannels,2.4),ncols=nchannels)\n",
    "for i in range(nchannels):\n",
    "    ax[i].set_facecolor('lightgray')\n",
    "    df_arr[i].plot(style='o-',ax=ax[i], fontsize=9)\n",
    "    ax[i].set_xlabel('Evaluation Input Data', fontsize=10)\n",
    "    if i == 2:\n",
    "        ax[i].legend(loc='upper left', fontsize=9, title='Training Data', title_fontsize=9)\n",
    "\n",
    "    else:\n",
    "        ax[i].get_legend().remove()\n",
    "\n",
    "    # ax[i].set_xticks(fontsize=8)\n",
    "    # ax[i].set_xticks(df_arr[i].index.tolist())\n",
    "    \n",
    "    ax[i].grid()\n",
    "    if metric != 'rangeinvpsnr':\n",
    "        ax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    ax[i].set_xticklabels([0] + df_arr[i].index.tolist())\n",
    "\n",
    "\n",
    "if savefig:\n",
    "# filename should contain all cropping information\n",
    "    fname = f'{metric}_outofNoiseDistribution.png'\n",
    "    fpath = os.path.join(output_data_dir, fname)\n",
    "    print(fpath)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "_,ax = plt.subplots(figsize=(3*nchannels,2.4),ncols=nchannels,nrows=2)\n",
    "df_ssim, _ = get_metric_data_df('ssim', nchannels)\n",
    "df_msssim, _ = get_metric_data_df('msssim', nchannels)\n",
    "for i in range(nchannels):\n",
    "    ax[0,i].set_facecolor('lightgray')\n",
    "    df_ssim[i].plot(style='o-',ax=ax[0,i], fontsize=9, markersize=4)\n",
    "    # ax[0, i].set_xlabel('Evaluation Input Data', fontsize=9)\n",
    "\n",
    "    ax[1,i].set_facecolor('lightgray')\n",
    "    df_msssim[i].plot(style='o-',ax=ax[1,i], fontsize=9, markersize=4)\n",
    "    ax[1, i].set_xlabel('Evaluation Input Data', fontsize=10)\n",
    "    ax[1,i].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    ax[1,i].set_xticklabels([0] + df_arr[i].index.tolist())\n",
    "\n",
    "    ax[0,i].set_xticklabels([])\n",
    "    ax[0,i].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    for row_idx in range(2):\n",
    "        ax[row_idx,i].get_legend().remove()\n",
    "        ax[row_idx,i].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "        ax[row_idx,i].grid()\n",
    "\n",
    "if savefig:\n",
    "# filename should contain all cropping information\n",
    "    fname = f'ssim_msssim_outofNoiseDistribution.png'\n",
    "    fpath = os.path.join(output_data_dir, fname)\n",
    "    print(fpath)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "pred_data_dict = defaultdict(dict)\n",
    "for eval_ms in all_ms:\n",
    "    for trained_ms in all_ms:\n",
    "        fpath = f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/data.dset_type-{eval_ms}/{prediction_for_trained_on_ms(trained_ms)}'\n",
    "        pred_data_dict[eval_ms][trained_ms] = load_tiff(fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = len(all_ms)\n",
    "nrows = nchannels\n",
    "img_sz = 3\n",
    "img_idx=0\n",
    "hs = 1100\n",
    "ws = 100\n",
    "imgN = 500\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols*img_sz, nrows*img_sz))\n",
    "eval_ms = '500ms'\n",
    "for tr_ms in all_ms:\n",
    "    tmp_ = pred_data_dict[eval_ms][tr_ms]\n",
    "    for ch_idx in range(nchannels):\n",
    "        ax[ch_idx, all_ms.index(tr_ms)].imshow(tmp_[img_idx,hs:hs+imgN,ws:ws+imgN,ch_idx], cmap='magma')\n",
    "        ax[ch_idx, all_ms.index(tr_ms)].axis('off')\n",
    "        ax[0, all_ms.index(tr_ms)].set_title('Tr_' + tr_ms)\n",
    "\n",
    "# remove space between subplots\n",
    "plt.subplots_adjust(wspace=0.03, hspace=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of prediction across noise levels.\n",
    "Here, we look at some region of the prediction for different noise levels. We want to see how details appear disappear with change in noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data_dict['2ms']['2ms'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ncols = len(all_ms)\n",
    "nrows = nchannels\n",
    "img_sz = 3\n",
    "img_idx=np.random.randint(pred_data_dict['2ms']['2ms'].shape[0])\n",
    "imgN = 300\n",
    "hs = np.random.randint(pred_data_dict['2ms']['2ms'].shape[1] -imgN)\n",
    "ws = np.random.randint(pred_data_dict['2ms']['2ms'].shape[2] -imgN)\n",
    "print(img_idx, hs,ws)\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols*img_sz, nrows*img_sz))\n",
    "for ms_level in all_ms:\n",
    "    tmp_ = pred_data_dict[ms_level][ms_level]\n",
    "    for ch_idx in range(nchannels):\n",
    "        ax[ch_idx, all_ms.index(ms_level)].imshow(tmp_[img_idx,hs:hs+imgN,ws:ws+imgN,ch_idx], cmap='magma')\n",
    "        ax[ch_idx, all_ms.index(ms_level)].axis('off')\n",
    "        ax[0, all_ms.index(ms_level)].set_title(ms_level)\n",
    "\n",
    "# remove space between subplots\n",
    "plt.subplots_adjust(wspace=0.03, hspace=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.config_utils import load_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.configs.nikola_7D_config import get_config\n",
    "from disentangle.data_loader.nikola_7D_rawdata_loader import get_train_val_data\n",
    "from disentangle.core.data_split_type import DataSplitType\n",
    "gt_dict = {}\n",
    "for ms_level in all_ms:\n",
    "    config = load_config(os.path.join('/group/jug/ashesh/training/disentangle/',keys[ms_level]))\n",
    "    datadir = '/group/jug/ashesh/data/nikola_data/20240531/'\n",
    "    data = get_train_val_data(datadir, config.data, DataSplitType.Test,\n",
    "                                config.training.val_fraction, config.training.test_fraction)\n",
    "    gt_dict[ms_level] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
