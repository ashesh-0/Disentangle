{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from disentangle.data_loader.evaluation_dloader import EvaluationDloader, GridAlignement\n",
    "# from disentangle.data_loader.patch_index_manager import GridAlignement\n",
    "from disentangle.nets.model_utils import create_model\n",
    "from nis2pyr.reader import read_nd2file\n",
    "from disentangle.config_utils import load_config\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "import nd2\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_7D(fpath):    \n",
    "    print(f'Loading from {fpath}')\n",
    "    with nd2.ND2File(fpath) as nd2file:\n",
    "        data = read_nd2file(nd2file)\n",
    "    return data\n",
    "\n",
    "def get_best_checkpoint(ckpt_dir):\n",
    "    output = []\n",
    "    for filename in glob.glob(ckpt_dir + \"/*_best.ckpt\"):\n",
    "        output.append(filename)\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2407/D28-M3-S0-L0/16\"\n",
    "# ckpt_dir = \"/group/jug/ashesh/training/disentangle/2407/D28-M3-S0-L0/22\"\n",
    "ckpt_dir = '/group/jug/ashesh/training/disentangle/2506/D28-M3-S0-L0/0'\n",
    "data_dir = '/group/jug/ashesh/data/Elisa/test'\n",
    "fnames = [x for x in sorted(os.listdir(data_dir)) if x.endswith('0001.nd2')]\n",
    "datafile = os.path.join(data_dir, fnames[0])\n",
    "# pixel resolution in nanometers\n",
    "resolution_nm = 285\n",
    "    \n",
    "# the other puncta removal dataset.\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2503/D28-M3-S0-L0/9'\n",
    "# data_dir = '/group/jug/ashesh/data/struct_noise_Feb25/'\n",
    "# from disentangle.core.tiff_reader import load_tiff\n",
    "# data = load_tiff(datafile)\n",
    "# data = data[:4096,1000:5096][None,]\n",
    "# data.shape\n",
    "\n",
    "# datafile = '/facility/imganfacusers/Ashesh/data_for_Ashesh_Feb_13/test_slice/DIF21_H9_WT_2_DIV50_2_1-Stitched-1.tif'\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_7D(datafile)\n",
    "print(data.shape)\n",
    "data = data[0,0,:,1,...,0]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch0 = load_tiff('/group/jug/ashesh/data/struct_noise_Feb25/ch0/10_c0.tif')\n",
    "# ch1 = load_tiff('/group/jug/ashesh/data/struct_noise_Feb25/ch1/10_c1.tif')\n",
    "# _,ax = plt.subplots(1,2, figsize=(10,5))\n",
    "# ax[0].imshow(ch0)\n",
    "# ax[1].imshow(ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[10,::5,::5][200:400,100:300], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z_idx = 10\n",
    "test_data= data[test_z_idx:test_z_idx+1].copy()\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_data -= config.data.background_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[10][1500:2500,1000:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.multicrops_dset import l2\n",
    "def sample_crop(sz):\n",
    "    t = np.random.randint(0, len(test_data))\n",
    "    x = np.random.randint(0, test_data.shape[1] - sz)\n",
    "    y = np.random.randint(0, test_data.shape[2] - sz)\n",
    "    crop = test_data[t, x:x+sz, y:y+sz]\n",
    "    return crop\n",
    "\n",
    "def compute_mean_std():\n",
    "    mean_inp = []\n",
    "    std_inp = []\n",
    "    for _ in range(30000):\n",
    "        crop = sample_crop(config.data.image_size)\n",
    "        mean_inp.append(np.mean(crop))\n",
    "        std_inp.append(np.std(crop))\n",
    "\n",
    "    output_mean = {}\n",
    "    output_std = {}\n",
    "    output_mean['input'] = np.array([np.mean(mean_inp)]).reshape(-1,1,1,1)\n",
    "    output_std['input'] = np.array([l2(std_inp)]).reshape(-1,1,1,1)\n",
    "    \n",
    "    output_mean['target'] = np.tile(output_mean['input'],(1,2,1,1))\n",
    "    output_std['target'] = np.tile(output_std['input'],(1,2,1,1))\n",
    "    return output_mean, output_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict, std_dict = compute_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(config, mean_dict.copy(),std_dict.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_fpath = get_best_checkpoint(ckpt_dir)\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model.eval()\n",
    "_= model.cuda()\n",
    "model.set_params_to_same_device_as(torch.Tensor(1).cuda())\n",
    "\n",
    "print('Loading from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(x):\n",
    "    return (x - mean_dict['input'].squeeze()) / std_dict['input'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_patch = test_data[0,1800:1928,1500:1628]\n",
    "plt.imshow(inp_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_for_different_output_size(inp_patch.shape[0])\n",
    "model.mode_pred = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = normalizer(inp_patch)\n",
    "with torch.no_grad():\n",
    "    out = model(torch.Tensor(inp[None,None]).cuda())\n",
    "out[0].shape\n",
    "plt.imshow(out[0][0,1].cpu().numpy(), vmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = EvaluationDloader(test_data, normalizer, lambda x: x, config.data.image_size, config.data.image_size//4, GridAlignement.Center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_dset_predictions(model, dset, batch_size, mmse_count=1, num_workers=4):\n",
    "    model.reset_for_different_output_size(dset[0].shape[0])\n",
    "    \n",
    "    dloader = DataLoader(dset, pin_memory=False, num_workers=num_workers, shuffle=False, batch_size=batch_size)\n",
    "    predictions = []\n",
    "    predictions_std = []\n",
    "    with torch.no_grad():\n",
    "        for inp in tqdm(dloader):\n",
    "            inp = inp.cuda()\n",
    "            recon_img_list = []\n",
    "            for mmse_idx in range(mmse_count):\n",
    "                imgs, _ = model(inp)\n",
    "                recon_img_list.append(imgs.cpu()[None])\n",
    "\n",
    "            samples = torch.cat(recon_img_list, dim=0)\n",
    "            mmse_imgs = torch.mean(samples, dim=0)\n",
    "            mmse_std = torch.std(samples, dim=0)\n",
    "            predictions.append(mmse_imgs.cpu().numpy())\n",
    "            predictions_std.append(mmse_std.cpu().numpy())\n",
    "    return np.concatenate(predictions, axis=0), np.concatenate(predictions_std, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiled, pred_std = get_dset_predictions(model, dset, batch_size*10, mmse_count=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from disentangle.data_loader.multifile_dset import MultiFileDset\n",
    "# from disentangle.data_loader.patch_index_manager import GridAlignement\n",
    "\n",
    "\n",
    "class PatchLocation:\n",
    "    \"\"\"\n",
    "    Encapsulates t_idx and spatial location.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h_idx_range, w_idx_range, t_idx):\n",
    "        self.t = t_idx\n",
    "        self.h_start, self.h_end = h_idx_range\n",
    "        self.w_start, self.w_end = w_idx_range\n",
    "\n",
    "    def __str__(self):\n",
    "        msg = f'T:{self.t} [{self.h_start}-{self.h_end}) [{self.w_start}-{self.w_end}) '\n",
    "        return msg\n",
    "\n",
    "\n",
    "def _get_location(extra_padding, hwt, pred_h, pred_w):\n",
    "    h_start, w_start, t_idx = hwt\n",
    "    h_start -= extra_padding\n",
    "    h_end = h_start + pred_h\n",
    "    w_start -= extra_padding\n",
    "    w_end = w_start + pred_w\n",
    "    return PatchLocation((h_start, h_end), (w_start, w_end), t_idx)\n",
    "\n",
    "\n",
    "def get_location_from_idx(dset, dset_input_idx, pred_h, pred_w):\n",
    "    \"\"\"\n",
    "    For a given idx of the dataset, it returns where exactly in the dataset, does this prediction lies. \n",
    "    Note that this prediction also has padded pixels and so a subset of it will be used in the final prediction.\n",
    "    Which time frame, which spatial location (h_start, h_end, w_start,w_end)\n",
    "    Args:\n",
    "        dset:\n",
    "        dset_input_idx:\n",
    "        pred_h:\n",
    "        pred_w:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    extra_padding = dset.per_side_overlap_pixelcount()\n",
    "    htw = dset.idx_manager.hwt_from_idx(dset_input_idx, grid_size=dset.get_grid_size())\n",
    "    loc = _get_location(extra_padding, htw, pred_h, pred_w)\n",
    "    return loc\n",
    "\n",
    "\n",
    "def set_skip_boundary_pixels_mask(mask, loc, skip_count):\n",
    "    if skip_count == 0:\n",
    "        return mask\n",
    "    assert skip_count > 0\n",
    "    assert loc.h_end - skip_count >= 0\n",
    "    assert loc.w_end - skip_count >= 0\n",
    "    mask[loc.t, :, loc.h_start:loc.h_start + skip_count, loc.w_start:loc.w_end] = False\n",
    "    mask[loc.t, :, loc.h_end - skip_count:loc.h_end, loc.w_start:loc.w_end] = False\n",
    "    mask[loc.t, :, loc.h_start:loc.h_end, loc.w_start:loc.w_start + skip_count] = False\n",
    "    mask[loc.t, :, loc.h_start:loc.h_end, loc.w_end - skip_count:loc.w_end] = False\n",
    "\n",
    "\n",
    "def set_skip_central_pixels_mask(mask, loc, skip_count):\n",
    "    if skip_count == 0:\n",
    "        return mask\n",
    "    assert skip_count > 0\n",
    "    h_mid = (loc.h_start + loc.h_end) // 2\n",
    "    w_mid = (loc.w_start + loc.w_end) // 2\n",
    "    l_skip = skip_count // 2\n",
    "    r_skip = skip_count - l_skip\n",
    "    mask[loc.t, :, h_mid - l_skip:h_mid + r_skip, w_mid - l_skip:w_mid + r_skip] = False\n",
    "\n",
    "\n",
    "def stitched_prediction_mask(dset, padded_patch_shape, skip_boundary_pixel_count, skip_central_pixel_count):\n",
    "    \"\"\"\n",
    "    Returns the boolean matrix. It will be 0 if it lies either in skipped boundaries or skipped central pixels\n",
    "    Args:\n",
    "        dset:\n",
    "        padded_patch_shape:\n",
    "        skip_boundary_pixel_count:\n",
    "        skip_central_pixel_count:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    N, H, W, C = dset.get_data_shape()\n",
    "    mask = np.full((N, C, H, W), True)\n",
    "    hN, wN = padded_patch_shape\n",
    "    for dset_input_idx in range(len(dset)):\n",
    "        loc = get_location_from_idx(dset, dset_input_idx, hN, wN)\n",
    "        set_skip_boundary_pixels_mask(mask, loc, skip_boundary_pixel_count)\n",
    "        set_skip_central_pixels_mask(mask, loc, skip_central_pixel_count)\n",
    "\n",
    "    old_img_sz = dset.get_img_sz()\n",
    "    dset.set_img_sz(dset._img_sz_for_hw)\n",
    "    mask = stitch_predictions(mask, dset)\n",
    "    dset.set_img_sz(old_img_sz)\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_pad(pred, loc, extra_padding, frame_shape, on_h_boundary, on_w_boundary, full_prediction=False):\n",
    "    if extra_padding > 0:\n",
    "        h_s = extra_padding\n",
    "\n",
    "        # rows\n",
    "        h_N = frame_shape[0]\n",
    "        if loc.h_end >= h_N:\n",
    "            assert loc.h_end - extra_padding <= h_N or full_prediction\n",
    "            if full_prediction:\n",
    "                h_e = loc.h_end - h_N\n",
    "            else:\n",
    "                h_e = extra_padding\n",
    "        elif on_h_boundary and full_prediction:\n",
    "            h_e = 0\n",
    "        else:\n",
    "            h_e = extra_padding\n",
    "\n",
    "        w_s = extra_padding\n",
    "\n",
    "        # columns\n",
    "        w_N = frame_shape[1]\n",
    "        if loc.w_end >= w_N:\n",
    "            assert loc.w_end - extra_padding <= w_N or full_prediction\n",
    "            if full_prediction:\n",
    "                w_e = loc.w_end - w_N\n",
    "            else:\n",
    "                w_e = extra_padding\n",
    "        elif on_w_boundary and full_prediction:\n",
    "            w_e = 0\n",
    "        else:\n",
    "            w_e = extra_padding\n",
    "\n",
    "        if h_e > 0 and w_e > 0:\n",
    "            return pred[h_s:-h_e, w_s:-w_e]\n",
    "        elif h_e > 0:\n",
    "            return pred[h_s:-h_e, w_s:]\n",
    "        elif w_e > 0:\n",
    "            return pred[h_s:, w_s:-w_e]\n",
    "        elif h_e == 0 and w_e == 0:\n",
    "            return pred[h_s:, w_s:]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def update_loc_for_final_insertion_full_pred(loc, extra_padding, frame_shape, on_h_boundary, on_w_boundary):\n",
    "    loc.h_start += extra_padding\n",
    "    loc.w_start += extra_padding\n",
    "    # rows\n",
    "    h_N = frame_shape[0]\n",
    "    if loc.h_end >= h_N:\n",
    "        loc.h_end = h_N\n",
    "    elif on_h_boundary:\n",
    "        assert loc.h_end == h_N\n",
    "    else:\n",
    "        loc.h_end -= extra_padding\n",
    "\n",
    "    w_N = frame_shape[1]\n",
    "    if loc.w_end >= w_N:\n",
    "        loc.w_end = w_N\n",
    "    elif on_w_boundary:\n",
    "        assert loc.w_end == w_N\n",
    "    else:\n",
    "        loc.w_end -= extra_padding\n",
    "    return loc\n",
    "\n",
    "\n",
    "def update_loc_for_final_insertion(loc, extra_padding):\n",
    "    loc.h_start += extra_padding\n",
    "    loc.w_start += extra_padding\n",
    "    loc.h_end -= extra_padding\n",
    "    loc.w_end -= extra_padding\n",
    "    return loc\n",
    "\n",
    "\n",
    "def stitch_predictions(predictions, dset, full_prediction=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        smoothening_pixelcount: number of pixels which can be interpolated\n",
    "    \"\"\"\n",
    "    # if isinstance(dset, MultiFileDset):\n",
    "    #     cum_count = 0\n",
    "    #     output = []\n",
    "    #     for dset in dset.dsets:\n",
    "    #         cnt = dset.idx_manager.grid_count()\n",
    "    #         output.append(\n",
    "    #             stitch_predictions(predictions[cum_count:cum_count + cnt], dset, full_prediction=full_prediction))\n",
    "    #         cum_count += cnt\n",
    "    #     return output\n",
    "\n",
    "    # else:\n",
    "    extra_padding = dset.per_side_overlap_pixelcount()\n",
    "    # if there are more channels, use all of them.\n",
    "    shape = list(dset.get_data_shape())\n",
    "    shape[-1] = max(shape[-1], predictions.shape[1])\n",
    "\n",
    "    output = np.zeros(shape, dtype=predictions.dtype)\n",
    "    frame_shape = dset.get_data_shape()[1:3]\n",
    "    for dset_input_idx in range(predictions.shape[0]):\n",
    "        loc = get_location_from_idx(dset, dset_input_idx, predictions.shape[-2], predictions.shape[-1])\n",
    "\n",
    "        cropped_pred_list = []\n",
    "        for ch_idx in range(predictions.shape[1]):\n",
    "            # class i\n",
    "            cropped_pred_i = remove_pad(predictions[dset_input_idx, ch_idx],\n",
    "                                        loc,\n",
    "                                        extra_padding,\n",
    "                                        frame_shape,\n",
    "                                        dset.idx_manager.on_bottom_boundary(dset_input_idx),\n",
    "                                        dset.idx_manager.on_right_boundary(dset_input_idx),\n",
    "                                        full_prediction=full_prediction)\n",
    "            cropped_pred_list.append(cropped_pred_i)\n",
    "\n",
    "        if full_prediction:\n",
    "            final_loc = update_loc_for_final_insertion_full_pred(\n",
    "                loc,\n",
    "                extra_padding,\n",
    "                frame_shape,\n",
    "                dset.idx_manager.on_bottom_boundary(dset_input_idx),\n",
    "                dset.idx_manager.on_right_boundary(dset_input_idx),\n",
    "            )\n",
    "        else:\n",
    "            final_loc = update_loc_for_final_insertion(loc, extra_padding)\n",
    "\n",
    "        for ch_idx in range(predictions.shape[1]):\n",
    "            output[final_loc.t, final_loc.h_start:final_loc.h_end, final_loc.w_start:final_loc.w_end,\n",
    "                    ch_idx] = cropped_pred_list[ch_idx]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def remove_terminal_zeros(pred):\n",
    "    he = 1\n",
    "    we = 1\n",
    "    while pred[:, -he:, -we:].std() == 0:\n",
    "        he += 1\n",
    "        we += 1\n",
    "    he -= 1\n",
    "    we -= 1\n",
    "    if he == 0 and we == 0:\n",
    "        return pred\n",
    "    return pred[:, :-he, :-we]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "pred = stitch_predictions(pred_tiled,dset)\n",
    "pred = pred*std_dict['target'].squeeze().reshape(1,1,1,2) + mean_dict['target'].squeeze().reshape(1,1,1,2)\n",
    "pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(12,4),ncols=3)\n",
    "hs = 0\n",
    "he = 2500\n",
    "ws = 0\n",
    "we = 2500\n",
    "ax[0].imshow(test_data[0,hs:he,ws:we])\n",
    "ax[1].imshow(pred[0,hs:he,ws:we,1])\n",
    "ax[2].imshow(pred[0,hs:he,ws:we,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.plot_utils import clean_ax\n",
    "# from matplotlib.colors import LogNorm\n",
    "\n",
    "# _,ax = plt.subplots(figsize=(16,8),ncols=4,nrows=2)\n",
    "# ax= ax.reshape(-1,)\n",
    "# t_idx =0\n",
    "# sz = 300\n",
    "# for i in range(len(ax)//2):\n",
    "#     hs = np.random.randint(0, test_data.shape[1] - sz)\n",
    "#     ws = np.random.randint(0, test_data.shape[2] - sz)\n",
    "#     ax[2*i].imshow(test_data[t_idx,hs:hs+sz,ws:ws+sz], vmax=130)\n",
    "#     ax[2*i+1].imshow(pred[t_idx,hs:hs+sz,ws:ws+sz,1])\n",
    "#     ax[2*i].set_title(f'Input, {t_idx,hs,ws}')\n",
    "#     ax[2*i+1].set_title('Puncta Removed')\n",
    "# clean_ax(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nature methods plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames:7, [8,1500:2700,500:2200]\n",
    "# fnames:8, [7/8/9/10,:1400,:800] => good\n",
    "# fnames:8, [7,1000:2400,800:2200]\n",
    "# fnames[13], [9/11,900:1500,1000:2400]\n",
    "# fnames[14], [9,2400:3800,700:2000]\n",
    "# fnames[15] [9,2200:4500,500:1500]\n",
    "# fnames[15] [9,300:2400,1000:2800]\n",
    "# fnames[15] [9,500:2400,2800:3900]\n",
    "# fnames[15] [9, 2500:4500,600:1500]\n",
    "# fnames[16] [9,400:1500,500:1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir =os.path.join('/group/jug/ashesh/naturemethods/puncta/', os.path.basename(datafile).replace('.nd2',''))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file = False\n",
    "# hs_region = 400\n",
    "# ws_region = 500\n",
    "hs_region = 400\n",
    "ws_region = 1400\n",
    "sz = 1200\n",
    "inp_region = test_data[0,hs_region:hs_region+sz,ws_region:ws_region+sz]\n",
    "pred_region = pred[0,hs_region:hs_region+sz,ws_region:ws_region+sz,1]\n",
    "vmin = int(np.floor(pred_region.min()))\n",
    "vmax = int(np.ceil(pred_region.max()))\n",
    "vmin, vmax\n",
    "plt.imshow(inp_region, vmax=vmax, vmin=vmin, cmap='gray')\n",
    "if save_to_file:\n",
    "    fname_prefix = f'z.{test_z_idx}_region.{hs_region}-{ws_region}_sz.{sz}'\n",
    "    print(fname_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'inp.npy', inp_region)\n",
    "# np.save(f'pred.npy', pred_region)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from disentangle.analysis.plot_utils import add_pixel_kde\n",
    "from disentangle.analysis.plot_utils import clean_ax\n",
    "from disentangle.analysis.plot_utils import clean_for_xaxis_plot, add_subplot_axes\n",
    "def hist_plot(ax, data, color='cyan', linewidth=2, **kwargs):\n",
    "    bins = np.histogram_bin_edges(data.flatten(), bins=100)\n",
    "    count = np.histogram(data.flatten(), bins=bins)[0]\n",
    "\n",
    "    ax.plot(bins[:-1], np.log(1+count), color=color, linewidth=linewidth, **kwargs)\n",
    "    ax.set_xlim([0, 1000])\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticks([xticks[0], xticks[-1]])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # clean_for_xaxis_plot(ax)\n",
    "    # ax.set_ylabel('log', fontsize=12, color='white')\n",
    "\n",
    "# color_ch_list = ['goldenrod', 'cyan']\n",
    "# color_pred = 'red'\n",
    "insetplot_xmax_value = 1000\n",
    "insetplot_xmin_value = 0\n",
    "inset_min_labelsize = 10\n",
    "\n",
    "cropsz = 256\n",
    "\n",
    "_,ax = plt.subplots(figsize=(16,8),ncols=2,nrows=1)\n",
    "puncta_mask = inp_region > vmax\n",
    "ax[0].imshow(inp_region, vmin=vmin, vmax=vmax, cmap='magma')\n",
    "\n",
    "# inset \n",
    "inset_ax = add_subplot_axes(ax[0], [0.035, 0.03, 0.3, 0.2], facecolor=\"None\", min_labelsize=inset_min_labelsize)\n",
    "inset_ax.tick_params(axis='x', colors='white')\n",
    "hist_plot(inset_ax, inp_region, color='cyan')\n",
    "inset_ax.spines['bottom'].set_linewidth(1)\n",
    "inset_ax.spines['bottom'].set_color('white')\n",
    "inset_ax.spines['left'].set_linewidth(1)\n",
    "inset_ax.spines['left'].set_color('white')\n",
    "inset_ax.set_yticks([])\n",
    "inset_ax.text(-0.1, 0.2, 'log scale', fontsize=12, color='white', rotation=90, transform=inset_ax.transAxes)\n",
    "\n",
    "\n",
    "new_mask = np.tile(puncta_mask[:,:,None],(1,1,3))\n",
    "new_mask[...,1] = 0\n",
    "new_mask[...,2] = 0\n",
    "new_mask = new_mask.astype(np.uint8)*255\n",
    "# ax[0].imshow(new_mask, alpha=1)\n",
    "ax[1].imshow(pred_region, cmap='magma')\n",
    "# inset \n",
    "inset_ax = add_subplot_axes(ax[1], [-0.05, 0.03, 0.3, 0.2], facecolor=\"None\", min_labelsize=inset_min_labelsize)\n",
    "inset_ax.tick_params(axis='x', colors='white')\n",
    "hist_plot(inset_ax, pred_region, color='red')\n",
    "hist_plot(inset_ax, inp_region, color='gray', linewidth=1, linestyle='--')\n",
    "\n",
    "inset_ax.spines['bottom'].set_linewidth(1)\n",
    "inset_ax.spines['bottom'].set_color('white')\n",
    "inset_ax.spines['left'].set_linewidth(1)\n",
    "inset_ax.spines['left'].set_color('white')\n",
    "\n",
    "inset_ax.set_yticks([])\n",
    "inset_ax.text(-0.1, 0.2, 'log scale', fontsize=12, color='white', rotation=90, transform=inset_ax.transAxes)\n",
    "\n",
    "clean_ax(ax)\n",
    "# hw_arr= [(900, 310),\n",
    "# (628, 313),\n",
    "# (758, 80),\n",
    "# (605, 49),\n",
    "# (424, 815),\n",
    "# (449, 541),\n",
    "# (92, 684),\n",
    "# (587,844)\n",
    "# ]\n",
    "hw_arr = [\n",
    "(35, 50),\n",
    " (591,434),\n",
    " (911,568),\n",
    " (917,395),\n",
    " (127,684),\n",
    " (662,804),\n",
    " (350,179),\n",
    " (72,498),\n",
    "]\n",
    "for i, loc in enumerate(hw_arr):\n",
    "    (h_s, w_s) = loc\n",
    "    rect = patches.Rectangle((w_s, h_s), cropsz, cropsz, linewidth=1, edgecolor='w', facecolor='none', linestyle='--')\n",
    "    ax[0].add_patch(rect)\n",
    "    # add a number at the top left of the rectangle\n",
    "    ax[0].text(w_s, h_s, str(i+1), color='white', fontsize=14)\n",
    "\n",
    "scalebar = ScaleBar(resolution_nm, \n",
    "                    \"nm\", \n",
    "                    # length_fraction=0.1, \n",
    "                    box_alpha=0.6, frameon=True, location='upper right', font_properties={'size':12})\n",
    "\n",
    "ax[0].add_artist(scalebar)\n",
    "\n",
    "# adjust the subplot gap\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "if save_to_file:    \n",
    "    fpath = os.path.join(output_dir, f'{fname_prefix}_full_region.png')\n",
    "    # save with high dpi\n",
    "    plt.savefig(fpath, dpi=100)\n",
    "    print('Saved to', fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sns.kdeplot(data=inp_region.flatten(), color='cyan', log_scale=[False, True])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crops = len(hw_arr)\n",
    "imgsz = 2.1\n",
    "# hw_arr = [(np.random.randint(0, inp_region.shape[0] - cropsz), np.random.randint(0, inp_region.shape[1] - cropsz)) for _ in range(num_crops)]\n",
    "\n",
    "_,ax = plt.subplots(figsize=(num_crops*imgsz,3*imgsz), ncols=num_crops, nrows=3)\n",
    "for i,(h,w) in enumerate(hw_arr):\n",
    "    print(f'{h},{w}')\n",
    "    inp_crop = inp_region[h:h+cropsz,w:w+cropsz]\n",
    "    ax[0,i].imshow(inp_crop, vmin=vmin, vmax=vmax, cmap='magma')\n",
    "    ax[0,i].text(10,30, str(i+1), color='white', fontsize=14)\n",
    "    pred_crop = pred_region[h:h+cropsz,w:w+cropsz]\n",
    "    # ax[1,i].imshow(np.stack([pred_crop,pred_crop,pred_crop], axis=-1),vmin=vmin/vmax, cmap='gray')\n",
    "    ax[1,i].imshow(pred_crop,vmin=vmin, vmax=vmax, cmap='magma')\n",
    "    diff_img = inp_crop - pred_crop\n",
    "    # vmin_diff = min(diff_img.min(), -1*diff_img.max())\n",
    "    vmax_diff = max(np.quantile(diff_img, 0.999), -1*diff_img.min())\n",
    "    vmin_diff = -1*vmax_diff\n",
    "    # vmin \n",
    "    ax[2,i].imshow(inp_crop - pred_crop, cmap='coolwarm', vmin=vmin_diff, vmax=vmax_diff)\n",
    "    clean_ax(ax[:,i])\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "if save_to_file:\n",
    "    fpath = os.path.join(output_dir, f'{fname_prefix}_crops.png')\n",
    "    plt.savefig(fpath, dpi=100)\n",
    "    print('Saved to', fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
