{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from disentangle.core.tiff_reader import load_tiff, save_tiff\n",
    "\n",
    "def convert_to_kth_data(fpath):\n",
    "    \"\"\"\n",
    "    In case we have the full prediction tiff file, we need to convert it to kth data format. one prediction per file. \n",
    "    \"\"\"\n",
    "    '/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D21-M3-S0-L8_6_1.tif'\n",
    "    fname = os.path.basename(fpath)\n",
    "    fdir = os.path.join(os.path.dirname(fpath), 'kth_{k}')\n",
    "    new_fpath_schema = os.path.join(fdir, fname)\n",
    "\n",
    "    data = load_tiff(fpath).squeeze()\n",
    "    assert len(data.shape) in [3,4]\n",
    "    if len(data.shape) == 3:\n",
    "        fpath = new_fpath_schema.format(k=0)\n",
    "        os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "        print('Saving to', fpath, 'shape', data.shape)\n",
    "        save_tiff(fpath,data)\n",
    "    else:\n",
    "        for k in range(data.shape[0]):\n",
    "            fpath = new_fpath_schema.format(k=k)\n",
    "            os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "            print('Saving to', fpath, 'shape', data[k].shape)\n",
    "            save_tiff(fpath,data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_to_kth_data('/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/pred_training_disentangle_2408_D24-M3-S0-L8_6_1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.train_val_data import get_train_val_data\n",
    "from disentangle.config_utils import load_config\n",
    "from disentangle.scripts.evaluate import get_data_dir\n",
    "from disentangle.core.data_split_type import DataSplitType\n",
    "from disentangle.core.tiff_reader import save_tiff, load_tiff\n",
    "import os\n",
    "\n",
    "gt_root_dir = \"/group/jug/ashesh/kth_data\"\n",
    "pred_rootdir = '/group/jug/ashesh/training/disentangle'\n",
    "OUTPUT_DIR = '/group/jug/ashesh/naturemethods/two_splitting/'\n",
    "KTH_SAMPLE = 0\n",
    "\n",
    "def sample_subdir(k):\n",
    "    return 'kth{}'.format(k)\n",
    "\n",
    "def get_gt_dir(dtype):\n",
    "    gt_dir = os.path.join(gt_root_dir, dtype)\n",
    "    gt_dir = os.path.join(gt_dir, sample_subdir(KTH_SAMPLE))\n",
    "    return gt_dir\n",
    "\n",
    "\n",
    "def get_kth_gt(val_data):\n",
    "    if hasattr(val_data, '_data'):\n",
    "        gt_data = val_data._data[KTH_SAMPLE][0]\n",
    "    else:\n",
    "        gt_data = val_data[KTH_SAMPLE]\n",
    "    return gt_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_frame_pred_dirs = {\n",
    "# pavia\n",
    "# '2408/D24-M3-S0-L8/6': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/kth_{KTH_SAMPLE}/pred_training_disentangle_2408_D24-M3-S0-L8_6_1.tif'\n",
    "\n",
    "# '2404/D21-M3-S0-L8/6': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D21-M3-S0-L8_6_1.tif',\n",
    "# '2408/D29-M3-S0-L8/22': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/kth_{KTH_SAMPLE}/pred_training_disentangle_2408_D29-M3-S0-L8_22_1.tif'\n",
    "# '2408/D19-M3-S0-L8/11':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/pred_training_disentangle_2408_D19-M3-S0-L8_11_1.tif'\n",
    "# '2408/D12-M3-S0-L8/3': '/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/pred_training_disentangle_2408_D12-M3-S0-L8_3_1.tif',\n",
    "\n",
    "# '2404/D25-M3-S0-L8/97': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_97_1.tif',\n",
    "# '2404/D25-M3-S0-L8/111': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_111_1.tif',\n",
    "'2405/D18-M3-S0-L8/13': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_13_1.tif',\n",
    "# '2405/D18-M3-S0-L8/14': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_14_1.tif',\n",
    "# '2404/D19-M3-S0-L8/5' : f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk16_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D19-M3-S0-L8_5_1.tif',\n",
    "\n",
    "# '2404/D25-M3-S0-L8/120': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_120_1.tif',\n",
    "# '2404/D25-M3-S0-L8/125': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_125_1.tif',\n",
    "# '2404/D25-M3-S0-L8/139': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_139_1.tif',\n",
    "# '2404/D25-M3-S0-L8/143': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D25-M3-S0-L8_143_1.tif',\n",
    "# '2405/D18-M3-S0-L8/15': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_15_1.tif',\n",
    "# '2405/D18-M3-S0-L8/10': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_10_1.tif',\n",
    "# '2405/D18-M3-S0-L8/11': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_11_1.tif',\n",
    "# '2405/D18-M3-S0-L8/12': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2405_D18-M3-S0-L8_12_1.tif',\n",
    "\n",
    "# '2404/D17-M3-S0-L8/4': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D17-M3-S0-L8_4_1.tif',\n",
    "# '2404/D21-M3-S0-L8/1': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_disentangle_2404_D21-M3-S0-L8_1_1.tif',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "crops_pred_dirs = {\n",
    "        # '2404/D21-M3-S0-L8/6':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D21-M3-S0-L8_6.pkl',\n",
    "        # '2404/D25-M3-S0-L8/97':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_97.pkl',\n",
    "        # '2404/D25-M3-S0-L8/120':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_120.pkl',\n",
    "        # '2404/D25-M3-S0-L8/111':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_111.pkl',\n",
    "        # '2404/D25-M3-S0-L8/125':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_125.pkl',\n",
    "        # '2404/D25-M3-S0-L8/139':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_139.pkl',\n",
    "        # '2404/D25-M3-S0-L8/143':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_143.pkl',\n",
    "        # '2405/D18-M3-S0-L8/13':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_13.pkl',\n",
    "        # '2405/D18-M3-S0-L8/14':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_14.pkl',\n",
    "        # '2405/D18-M3-S0-L8/15':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_15.pkl',\n",
    "        # '2405/D18-M3-S0-L8/10':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_10.pkl',\n",
    "        # '2405/D18-M3-S0-L8/11':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_11.pkl',\n",
    "        # '2405/D18-M3-S0-L8/12':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_12.pkl',\n",
    "        # '2404/D17-M3-S0-L8/4':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D17-M3-S0-L8_4.pkl',\n",
    "        # '2404/D21-M3-S0-L8/1':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D21-M3-S0-L8_1.pkl',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the kth frame data and store it for fast access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_dir, pred_fpath in full_frame_pred_dirs.items():\n",
    "    dtype = model_dir.split('/')[1].split('-')[0]\n",
    "    gt_dir = get_gt_dir(dtype)\n",
    "\n",
    "    if not os.path.exists(gt_dir):\n",
    "        print('No such dir {}. Creating it'.format(gt_dir))\n",
    "        os.makedirs(gt_dir, exist_ok=True)\n",
    "    \n",
    "    gt_fpath = os.path.join(gt_dir, 'gt_for_'+os.path.basename(pred_fpath))\n",
    "    if not os.path.exists(gt_fpath):\n",
    "        print('GT data is not present at {}. Creating it'.format(gt_fpath))\n",
    "        # loading directory.\n",
    "        config = load_config(os.path.join(pred_rootdir, model_dir, 'config.pkl'))\n",
    "        val_data = get_train_val_data(config.data, get_data_dir(int(dtype[1:])), DataSplitType.Test, \n",
    "        val_fraction=config.training.val_fraction,\n",
    "        test_fraction=config.training.test_fraction)\n",
    "        kth_gt = get_kth_gt(val_data)\n",
    "        save_tiff(gt_fpath, kth_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = key.split('/')[1].split('-')[0]\n",
    "# config = load_config(os.path.join(pred_rootdir, key, 'config.pkl'))\n",
    "# val_data = get_train_val_data(config.data, get_data_dir(int(dtype[1:])), DataSplitType.Test, \n",
    "#         val_fraction=config.training.val_fraction,\n",
    "#         test_fraction=config.training.test_fraction)\n",
    "# kth_gt = get_kth_gt(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from tqdm import tqdm\n",
    "z_idx = 5\n",
    "gt_pred_dict = {}\n",
    "for model_dir, pred_fpath in tqdm(full_frame_pred_dirs.items()):\n",
    "    dtype = model_dir.split('/')[1].split('-')[0]\n",
    "    gt_dir = get_gt_dir(dtype)\n",
    "    gt_fpath = os.path.join(gt_dir, 'gt_for_'+os.path.basename(pred_fpath))\n",
    "    kth_gt = load_tiff(gt_fpath)\n",
    "    kth_pred = load_tiff(pred_fpath)\n",
    "    if len(kth_gt.squeeze().shape) == 4:\n",
    "        # this is 3D data. \n",
    "        kth_gt = kth_gt.squeeze()[z_idx]\n",
    "        kth_pred = kth_pred.squeeze()[z_idx]\n",
    "\n",
    "    gt_pred_dict[model_dir] = (kth_gt, kth_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.notion.so/Evaluating-2-channel-results-281cea8bb51c47ccadd50a389614100f?pvs=4\n",
    "\n",
    "keys = [\n",
    "#  '2408/D12-M3-S0-L8/3'   \n",
    "# '2404/D21-M3-S0-L8/6',\n",
    "# '2408/D24-M3-S0-L8/6'\n",
    "# '2408/D19-M3-S0-L8/11'\n",
    "# '2408/D29-M3-S0-L8/22', #=> kth = 0\n",
    "# '2404/D25-M3-S0-L8/97', # => kth = 0\n",
    "# '2404/D25-M3-S0-L8/111', # => kth = 0\n",
    "'2405/D18-M3-S0-L8/13', # => kth = 0\n",
    "# '2405/D18-M3-S0-L8/14', # => kth = 0\n",
    "# '2405/D19-M3-S0-L8/5',\n",
    "# '2405/D18-M3-S0-L8/15',\n",
    "# '2405/D18-M3-S0-L8/10',\n",
    "# '2405/D18-M3-S0-L8/11',\n",
    "# '2405/D18-M3-S0-L8/12',\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def get_input(gt):\n",
    "    synthetic_input = None\n",
    "    if gt.shape[-1] == 2:\n",
    "        inp = (gt[...,0] + gt[...,1])/2\n",
    "        synthetic_input = True\n",
    "    else:\n",
    "        assert gt.shape[-1] == 3\n",
    "        inp = gt[...,-1]\n",
    "        synthetic_input = False\n",
    "    return inp, synthetic_input\n",
    "\n",
    "\n",
    "key = keys[-1]\n",
    "print(key)\n",
    "gt, pred = gt_pred_dict[key]\n",
    "gt = gt.squeeze()\n",
    "pred = pred.squeeze()\n",
    "_,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "inp, is_syhthetic = get_input(gt)\n",
    "if is_syhthetic:\n",
    "    ax[0].set_title('Synthetic Input')\n",
    "else:\n",
    "    ax[0].set_title('Real Input')\n",
    "\n",
    "ax[0].imshow(inp)\n",
    "ax[1].imshow(gt[...,0])\n",
    "ax[2].imshow(pred[...,0])\n",
    "\n",
    "ax[3].imshow(gt[...,1])\n",
    "ax[4].imshow(pred[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "hs = 500\n",
    "ws = 500\n",
    "sz = 300\n",
    "ax[0].imshow(inp[hs:hs+sz, ws:ws+sz])\n",
    "ax[1].imshow(gt[hs:hs+sz, ws:ws+sz,0])\n",
    "ax[2].imshow(pred[hs:hs+sz, ws:ws+sz,0])\n",
    "\n",
    "ax[3].imshow(gt[hs:hs+sz, ws:ws+sz,1])\n",
    "ax[4].imshow(pred[hs:hs+sz, ws:ws+sz,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 5x10 grid for the input. 2x10 grid for the two targets and predictions.\n",
    "\n",
    "\n",
    "def get_cropped_img(inp, hfac, hs=None, ws= None, wN=None):\n",
    "    if wN is None:\n",
    "        wN = inp.shape[1]\n",
    "    \n",
    "    if ws is None:\n",
    "        ws = (inp.shape[1] - wN)//2\n",
    "    else:\n",
    "        assert ws + wN < inp.shape[1], f'Invalid ws for the input. ws = {ws}, wN = {wN}, inp.shape = {inp.shape}'\n",
    "    \n",
    "    hN = int(wN*hfac)\n",
    "    if hs is None:\n",
    "        hs = (inp.shape[0] - hN)//2\n",
    "    else:\n",
    "        assert hs + hN < inp.shape[0], f'Invalid hs for the input. hs = {hs}, hN = {hN}, inp.shape = {inp.shape}'\n",
    "    return inp[hs:hs+hN, ws:ws+wN], (hs, ws, hN, wN)\n",
    "\n",
    "# key = keys[-1]\n",
    "# input_h_factor = 0.5 # we want to make rectangula\n",
    "# channel_h_factor = 0.48\n",
    "# unit_size = 6\n",
    "# ncols = 3\n",
    "# nrows = 1\n",
    "# grid_factor = 50\n",
    "# wN = 1500\n",
    "# ws = 1500\n",
    "\n",
    "# fig = plt.figure(figsize=(ncols*unit_size,int(nrows*unit_size*input_h_factor)))\n",
    "\n",
    "# gs = gridspec.GridSpec(int(nrows*grid_factor), ncols*grid_factor, figure=fig, wspace=0.0, hspace=0.0)\n",
    "\n",
    "# gt, pred = gt_pred_dict[key]\n",
    "# gt = gt.squeeze()\n",
    "# pred = pred.squeeze()\n",
    "# inp = get_input(gt)[0]\n",
    "\n",
    "# channel_g_rows = int(grid_factor*channel_h_factor)\n",
    "# channel_g_cols = grid_factor\n",
    "\n",
    "# # input \n",
    "# col_s = 0\n",
    "# col_e = grid_factor\n",
    "# row_s = 0\n",
    "# row_e = int(grid_factor)\n",
    "\n",
    "# ax_inp = fig.add_subplot(gs[row_s:row_e, col_s:col_e])\n",
    "# inp_crop, input_coordinates = get_cropped_img(inp, input_h_factor, wN=wN, ws=ws)\n",
    "# ax_inp.imshow(inp_crop, cmap='magma')\n",
    "# ax_inp.axis('off')\n",
    "\n",
    "# # two targets\n",
    "# col_s = col_e\n",
    "# col_e = col_s + channel_g_cols\n",
    "# row1_s = 0\n",
    "# row1_e = channel_g_rows\n",
    "# ax_tar1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "# tar1_crop, ch_cordinates = get_cropped_img(gt[...,0], channel_h_factor*input_h_factor,  wN=wN, ws=ws)\n",
    "# relative_coordinates = (ch_cordinates[0] - input_coordinates[0],\n",
    "#                         ch_cordinates[1] - input_coordinates[1],\n",
    "#                         ch_cordinates[2],\n",
    "#                         ch_cordinates[3])\n",
    "# rect = patches.Rectangle((relative_coordinates[1], relative_coordinates[0]), relative_coordinates[3],relative_coordinates[2], \n",
    "#                          linewidth=1, edgecolor='w', facecolor='none', linestyle='--')\n",
    "# ax_inp.add_patch(rect)\n",
    "\n",
    "# ax_tar1.imshow(tar1_crop, cmap='magma')\n",
    "# ax_tar1.axis('off')\n",
    "\n",
    "# row2_e = grid_factor\n",
    "# row2_s = row2_e - channel_g_rows\n",
    "# ax_tar2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "# ax_tar2.imshow(get_cropped_img(gt[...,1], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_tar2.axis('off')\n",
    "\n",
    "\n",
    "# # two predictions\n",
    "# col_s = col_e\n",
    "# col_e = col_s + channel_g_cols\n",
    "# ax_pred1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "# ax_pred1.imshow(get_cropped_img(pred[...,0], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_pred1.axis('off')\n",
    "\n",
    "# ax_pred2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "# ax_pred2.imshow(get_cropped_img(pred[...,1], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_pred2.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "# 5x10 grid for the input. 2x10 grid for the two targets and predictions.\n",
    "\n",
    "key = keys[-1]\n",
    "channel_h_factor = 0.48\n",
    "unit_size = 2\n",
    "ncols = 3\n",
    "nrows = 1\n",
    "grid_factor = 200\n",
    "\n",
    "# this describes the left most input patch.\n",
    "wN = 1000\n",
    "input_h_factor = 3 # we want to make rectangula\n",
    "# ws = np.random.randint(0, inp.shape[1] - wN)\n",
    "# hs = np.random.randint(0, inp.shape[0] - wN*input_h_factor)\n",
    "\n",
    "# within the input patch, this describes the region of interest.\n",
    "zoom_in = 1.0\n",
    "# ws_inset = ws + np.random.randint(0, wN - int(wN/zoom_in)) if zoom_in > 1 else ws\n",
    "# hs_inset = hs + np.random.randint(0, wN*input_h_factor - int(wN*channel_h_factor/zoom_in))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*unit_size,int(nrows*unit_size*input_h_factor)))\n",
    "\n",
    "gs = gridspec.GridSpec(int(nrows*grid_factor), ncols*grid_factor, figure=fig, wspace=0.0, hspace=0.1)\n",
    "\n",
    "gt, pred = gt_pred_dict[key]\n",
    "gt = gt.squeeze()\n",
    "pred = pred.squeeze()\n",
    "inp = get_input(gt)[0]\n",
    "\n",
    "channel_g_rows = int(grid_factor*channel_h_factor)\n",
    "channel_g_cols = grid_factor\n",
    "\n",
    "# input \n",
    "col_s = 0\n",
    "col_e = grid_factor\n",
    "row_s = 0\n",
    "row_e = int(grid_factor)\n",
    "\n",
    "ax_inp = fig.add_subplot(gs[row_s:row_e, col_s:col_e])\n",
    "inp_crop, input_coordinates = get_cropped_img(inp, input_h_factor, wN=wN, ws=ws,hs=hs)\n",
    "# print('input_coordinates', input_coordinates)\n",
    "ax_inp.imshow(inp_crop, cmap='magma')\n",
    "ax_inp.axis('off')\n",
    "\n",
    "# two targets\n",
    "col_s = col_e\n",
    "col_e = col_s + channel_g_cols\n",
    "row1_s = 0\n",
    "row1_e = channel_g_rows\n",
    "ax_tar1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "tar1_crop, ch_cordinates = get_cropped_img(gt[...,0], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_inset)\n",
    "ax_tar1.imshow(tar1_crop, cmap='magma')\n",
    "ax_tar1.axis('off')\n",
    "relative_coordinates = (ch_cordinates[0] - input_coordinates[0],\n",
    "                        ch_cordinates[1] - input_coordinates[1],\n",
    "                        ch_cordinates[2],\n",
    "                        ch_cordinates[3])\n",
    "rect = patches.Rectangle((relative_coordinates[1]+3, relative_coordinates[0]), relative_coordinates[3]-9,relative_coordinates[2], \n",
    "                         linewidth=2, edgecolor='w', facecolor='none', linestyle='--')\n",
    "ax_inp.add_patch(rect)\n",
    "\n",
    "row2_e = grid_factor\n",
    "row2_s = row2_e - channel_g_rows\n",
    "ax_tar2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "ax_tar2.imshow(get_cropped_img(gt[...,1], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_inset)[0], cmap='magma')\n",
    "ax_tar2.axis('off')\n",
    "\n",
    "\n",
    "# two predictions\n",
    "col_s = col_e\n",
    "col_e = col_s + channel_g_cols\n",
    "ax_pred1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "ax_pred1.imshow(get_cropped_img(pred[...,0], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_inset)[0], cmap='magma')\n",
    "ax_pred1.axis('off')\n",
    "\n",
    "ax_pred2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "ax_pred2.imshow(get_cropped_img(pred[...,1], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_inset)[0], cmap='magma')\n",
    "ax_pred2.axis('off')\n",
    "\n",
    "# filename should contain all cropping information\n",
    "fname = 'cropped_{}_K{}_{}-{}-{}-{}.png'.format(key.replace('/','_'),KTH_SAMPLE, ch_cordinates[0], ch_cordinates[1], ch_cordinates[2], ch_cordinates[3])\n",
    "fpath = os.path.join(OUTPUT_DIR, fname)\n",
    "print(fpath)\n",
    "plt.savefig(fpath, dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# _, ax = plt.subplots(figsize=(9,15), ncols=3, nrows=5)\n",
    "# ex_idx = ex_idx +1 #np.random.choice(range(len(data['inp'])))\n",
    "# print(ex_idx)\n",
    "# ax[0,0].imshow(data['inp'][ex_idx][0,0].cpu().numpy())\n",
    "# ax[0,1].imshow(data['tar'][ex_idx][0,0].cpu().numpy())\n",
    "# ax[0,2].imshow(data['tar'][ex_idx][0,1].cpu().numpy())\n",
    "\n",
    "# ax[1,1].imshow(data['pred'][0][ex_idx].mean(axis=0))\n",
    "# ax[1,2].imshow(data['pred'][1][ex_idx].mean(axis=0))\n",
    "\n",
    "# ax[2,1].imshow(data['pred'][0][ex_idx][0])\n",
    "# ax[2,2].imshow(data['pred'][1][ex_idx][0])\n",
    "# ax[3,1].imshow(data['pred'][0][ex_idx][1])\n",
    "# ax[3,2].imshow(data['pred'][1][ex_idx][1])\n",
    "\n",
    "# ax[4,1].imshow(data['pred'][0][ex_idx][1] - data['pred'][0][ex_idx][0])\n",
    "# ax[4,2].imshow(data['pred'][1][ex_idx][1] - data['pred'][1][ex_idx][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from skimage.io import imread\n",
    "data = imread('/group/jug/ashesh/data/Dao4Channel/SIM_3color_1channel_group1.tif', plugin='tifffile')\n",
    "data =data[::6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = imread('/group/jug/ashesh/training/N2V/2405/65/SIM_3color_1channel_group1.tif', plugin='tifffile')[::6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12,6), ncols=2)\n",
    "h = 1500\n",
    "w = 1500\n",
    "sz = 500\n",
    "ax[0].imshow(data[0,h:h+sz,w:w+sz,0])\n",
    "ax[1].imshow(denoised[0,h:h+sz,w:w+sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(12,3),ncols=4)\n",
    "img_idx = -1\n",
    "ax[0].imshow(data[img_idx,::5,::5,0])\n",
    "ax[1].imshow(data[img_idx,::5,::5,1])\n",
    "ax[2].imshow(data[img_idx,::5,::5,2])\n",
    "ax[3].imshow(data[img_idx,::5,::5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[img_idx,1600:1900, 1000:1300, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[...,0].mean(), data[...,1].mean(), data[...,2].mean(), data[...,3].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
