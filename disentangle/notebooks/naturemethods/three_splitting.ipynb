{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.train_val_data import get_train_val_data\n",
    "from disentangle.config_utils import load_config\n",
    "from disentangle.scripts.evaluate import get_data_dir\n",
    "from disentangle.core.data_split_type import DataSplitType\n",
    "from disentangle.core.tiff_reader import save_tiff, load_tiff\n",
    "import os\n",
    "\n",
    "gt_root_dir = \"/group/jug/ashesh/kth_data\"\n",
    "pred_rootdir = '/group/jug/ashesh/training/disentangle'\n",
    "output_data_dir = '/group/jug/ashesh/naturemethods/three_splitting/'\n",
    "KTH_SAMPLE = 1\n",
    "\n",
    "def sample_subdir(k):\n",
    "    return 'kth{}'.format(k)\n",
    "\n",
    "def get_gt_dir(dtype):\n",
    "    gt_dir = os.path.join(gt_root_dir, dtype)\n",
    "    gt_dir = os.path.join(gt_dir, sample_subdir(KTH_SAMPLE))\n",
    "    return gt_dir\n",
    "\n",
    "\n",
    "def get_kth_gt(val_data):\n",
    "    if hasattr(val_data, '_data'):\n",
    "        gt_data = val_data._data[KTH_SAMPLE][0]\n",
    "    else:\n",
    "        gt_data = val_data[KTH_SAMPLE]\n",
    "    return gt_data\n",
    "\n",
    "\n",
    "\n",
    "full_frame_pred_dirs = {\n",
    "# \"2406/D25-M3-S0-L8/4\": f\"/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2406_D25-M3-S0-L8_4_1.tif\",\n",
    "# \"2406/D25-M3-S0-L8/5\": f\"/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2406_D25-M3-S0-L8_5_1.tif\",\n",
    "# \"2406/D25-M3-S0-L8/6\": f\"/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2406_D25-M3-S0-L8_6_1.tif\",\n",
    "# \"2406/D25-M3-S0-L8/14\" : f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2406_D25-M3-S0-L8_14_1.tif',\n",
    "\"2406/D25-M3-S0-L8/17\": f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2406_D25-M3-S0-L8_17_1.tif',\n",
    "# '2405/D25-M3-S0-L8/2': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2405_D25-M3-S0-L8_2_1.tif',\n",
    "# '2405/D25-M3-S0-L8/3': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2405_D25-M3-S0-L8_3_1.tif',\n",
    "# '2405/D18-M3-S0-L8/16': f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{KTH_SAMPLE}/pred_training_disentangle_2405_D18-M3-S0-L8_16_1.tif',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "crops_pred_dirs = {\n",
    "        # '2404/D21-M3-S0-L8/6':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D21-M3-S0-L8_6.pkl',\n",
    "        # '2404/D25-M3-S0-L8/97':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_97.pkl',\n",
    "        # '2404/D25-M3-S0-L8/120':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_120.pkl',\n",
    "        # '2404/D25-M3-S0-L8/111':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_111.pkl',\n",
    "        # '2404/D25-M3-S0-L8/125':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_125.pkl',\n",
    "        # '2404/D25-M3-S0-L8/139':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_139.pkl',\n",
    "        # '2404/D25-M3-S0-L8/143':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D25-M3-S0-L8_143.pkl',\n",
    "        # '2405/D18-M3-S0-L8/13':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_13.pkl',\n",
    "        # '2405/D18-M3-S0-L8/14':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_14.pkl',\n",
    "        # '2405/D18-M3-S0-L8/15':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_15.pkl',\n",
    "        # '2405/D18-M3-S0-L8/10':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_10.pkl',\n",
    "        # '2405/D18-M3-S0-L8/11':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_11.pkl',\n",
    "        # '2405/D18-M3-S0-L8/12':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2405_D18-M3-S0-L8_12.pkl',\n",
    "        # '2404/D17-M3-S0-L8/4':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D17-M3-S0-L8_4.pkl',\n",
    "        # '2404/D21-M3-S0-L8/1':'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/stats_disentangle_2404_D21-M3-S0-L8_1.pkl',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the kth frame data and store it for fast access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_dir, pred_fpath in full_frame_pred_dirs.items():\n",
    "    dtype = model_dir.split('/')[1].split('-')[0]\n",
    "    gt_dir = get_gt_dir(dtype)\n",
    "\n",
    "    if not os.path.exists(gt_dir):\n",
    "        print('No such dir {}. Creating it'.format(gt_dir))\n",
    "        os.makedirs(gt_dir, exist_ok=True)\n",
    "    \n",
    "    gt_fpath = os.path.join(gt_dir, 'gt_for_'+os.path.basename(pred_fpath))\n",
    "    if not os.path.exists(gt_fpath):\n",
    "        print('GT data is not present at {}. Creating it'.format(gt_fpath))\n",
    "        # loading directory.\n",
    "        config = load_config(os.path.join(pred_rootdir, model_dir, 'config.pkl'))\n",
    "        val_data = get_train_val_data(config.data, get_data_dir(int(dtype[1:])), DataSplitType.Test, \n",
    "        val_fraction=config.training.val_fraction,\n",
    "        test_fraction=config.training.test_fraction)\n",
    "        kth_gt = get_kth_gt(val_data)\n",
    "        save_tiff(gt_fpath, kth_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = key.split('/')[1].split('-')[0]\n",
    "# config = load_config(os.path.join(pred_rootdir, key, 'config.pkl'))\n",
    "# val_data = get_train_val_data(config.data, get_data_dir(int(dtype[1:])), DataSplitType.Test, \n",
    "#         val_fraction=config.training.val_fraction,\n",
    "#         test_fraction=config.training.test_fraction)\n",
    "# kth_gt = get_kth_gt(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from tqdm import tqdm\n",
    "\n",
    "gt_pred_dict = {}\n",
    "for model_dir, pred_fpath in tqdm(full_frame_pred_dirs.items()):\n",
    "    dtype = model_dir.split('/')[1].split('-')[0]\n",
    "    gt_dir = get_gt_dir(dtype)\n",
    "    gt_fpath = os.path.join(gt_dir, 'gt_for_'+os.path.basename(pred_fpath))\n",
    "    kth_gt = load_tiff(gt_fpath)\n",
    "    kth_pred = load_tiff(pred_fpath)\n",
    "    print(pred_fpath)\n",
    "    gt_pred_dict[model_dir] = (kth_gt, kth_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.notion.so/Evaluating-2-channel-results-281cea8bb51c47ccadd50a389614100f?pvs=4\n",
    "\n",
    "keys = [\n",
    "# '2405/D25-M3-S0-L8/2',\n",
    "# '2405/D25-M3-S0-L8/3',\n",
    "# '2405/D18-M3-S0-L8/16',\n",
    "# \"2406/D25-M3-S0-L8/4\",\n",
    "# \"2406/D25-M3-S0-L8/5\",\n",
    "# \"2406/D25-M3-S0-L8/6\",\n",
    "# \"2406/D25-M3-S0-L8/14\",\n",
    "\"2406/D25-M3-S0-L8/17\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def get_input(gt):\n",
    "    synthetic_input = None\n",
    "    if gt.shape[-1] == 3:\n",
    "        inp = gt.mean(axis=-1)\n",
    "        synthetic_input = True\n",
    "    else:\n",
    "        assert gt.shape[-1] == 4, f'Expected 4 or 3 channels. Got {gt.shape[-1]} channels.'\n",
    "        inp = gt[...,-1]\n",
    "        synthetic_input = False\n",
    "    return inp, synthetic_input\n",
    "\n",
    "\n",
    "key = keys[-1]\n",
    "print(key)\n",
    "gt, pred = gt_pred_dict[key]\n",
    "gt = gt.squeeze()\n",
    "pred = pred.squeeze()\n",
    "_,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "inp, is_syhthetic = get_input(gt)\n",
    "if is_syhthetic:\n",
    "    ax[0].set_title('Synthetic Input')\n",
    "else:\n",
    "    ax[0].set_title('Real Input')\n",
    "\n",
    "ax[0].imshow(inp)   \n",
    "ax[1].imshow(gt[...,0])\n",
    "ax[2].imshow(pred[...,0])\n",
    "\n",
    "ax[3].imshow(gt[...,1])\n",
    "ax[4].imshow(pred[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "hs = 500\n",
    "ws = 500\n",
    "sz = 300\n",
    "ax[0].imshow(inp[hs:hs+sz, ws:ws+sz])\n",
    "ax[1].imshow(gt[hs:hs+sz, ws:ws+sz,0])\n",
    "ax[2].imshow(pred[hs:hs+sz, ws:ws+sz,0])\n",
    "\n",
    "ax[3].imshow(gt[hs:hs+sz, ws:ws+sz,1])\n",
    "ax[4].imshow(pred[hs:hs+sz, ws:ws+sz,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "\n",
    "# 5x10 grid for the input. 2x10 grid for the two targets and predictions.\n",
    "\n",
    "\n",
    "def get_cropped_img(inp, hfac, hs=None, ws= None, wN=None, extra_h=0, extra_w=0):\n",
    "    if wN is None:\n",
    "        wN = inp.shape[1]\n",
    "    \n",
    "    if ws is None:\n",
    "        ws = (inp.shape[1] - wN)//2\n",
    "    else:\n",
    "        assert ws + wN < inp.shape[1], f'Invalid ws for the input. ws = {ws}, wN = {wN}, inp.shape = {inp.shape}'\n",
    "    \n",
    "    hN = int(wN*hfac)\n",
    "    if hs is None:\n",
    "        hs = (inp.shape[0] - hN)//2\n",
    "    else:\n",
    "        assert hs + hN < inp.shape[0], f'Invalid hs for the input. hs = {hs}, hN = {hN}, inp.shape = {inp.shape}'\n",
    "    return inp[hs-extra_h//2:hs+hN+extra_h//2, ws - extra_w//2:ws+wN+extra_w//2], (hs-extra_h//2, ws-extra_w//2, hN+extra_h//2, wN+extra_w//2)\n",
    "\n",
    "\n",
    "def find_most_interesting_box(inp_crop, channel_h_factor):\n",
    "    \"\"\"\n",
    "    Returns hs, the start of the box\n",
    "    \"\"\"\n",
    "    boxH = int(np.ceil(channel_h_factor * inp_crop.shape[0]))\n",
    "    idx = np.argmax(pd.Series(inp_crop.std(axis=1)).rolling(window=boxH).mean().iloc[boxH:].values)\n",
    "    return idx\n",
    "# key = keys[0]\n",
    "# input_h_factor = 0.5 # we want to make rectangula\n",
    "# channel_h_factor = 0.48\n",
    "# unit_size = 6\n",
    "# ncols = 3\n",
    "# nrows = 1\n",
    "# grid_factor = 50\n",
    "# wN = 1500\n",
    "# ws = 1500\n",
    "\n",
    "# fig = plt.figure(figsize=(ncols*unit_size,int(nrows*unit_size*input_h_factor)))\n",
    "\n",
    "# gs = gridspec.GridSpec(int(nrows*grid_factor), ncols*grid_factor, figure=fig, wspace=0.0, hspace=0.0)\n",
    "\n",
    "# gt, pred = gt_pred_dict[key]\n",
    "# gt = gt.squeeze()\n",
    "# pred = pred.squeeze()\n",
    "# inp = get_input(gt)[0]\n",
    "\n",
    "# channel_g_rows = int(grid_factor*channel_h_factor)\n",
    "# channel_g_cols = grid_factor\n",
    "\n",
    "# # input \n",
    "# col_s = 0\n",
    "# col_e = grid_factor\n",
    "# row_s = 0\n",
    "# row_e = int(grid_factor)\n",
    "\n",
    "# ax_inp = fig.add_subplot(gs[row_s:row_e, col_s:col_e])\n",
    "# inp_crop, input_coordinates = get_cropped_img(inp, input_h_factor, wN=wN, ws=ws)\n",
    "# ax_inp.imshow(inp_crop, cmap='magma')\n",
    "# ax_inp.axis('off')\n",
    "\n",
    "# # two targets\n",
    "# col_s = col_e\n",
    "# col_e = col_s + channel_g_cols\n",
    "# row1_s = 0\n",
    "# row1_e = channel_g_rows\n",
    "# ax_tar1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "# tar1_crop, ch_cordinates = get_cropped_img(gt[...,0], channel_h_factor*input_h_factor,  wN=wN, ws=ws)\n",
    "# relative_coordinates = (ch_cordinates[0] - input_coordinates[0],\n",
    "#                         ch_cordinates[1] - input_coordinates[1],\n",
    "#                         ch_cordinates[2],\n",
    "#                         ch_cordinates[3])\n",
    "# rect = patches.Rectangle((relative_coordinates[1], relative_coordinates[0]), relative_coordinates[3],relative_coordinates[2], \n",
    "#                          linewidth=1, edgecolor='w', facecolor='none', linestyle='--')\n",
    "# ax_inp.add_patch(rect)\n",
    "\n",
    "# ax_tar1.imshow(tar1_crop, cmap='magma')\n",
    "# ax_tar1.axis('off')\n",
    "\n",
    "# row2_e = grid_factor\n",
    "# row2_s = row2_e - channel_g_rows\n",
    "# ax_tar2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "# ax_tar2.imshow(get_cropped_img(gt[...,1], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_tar2.axis('off')\n",
    "\n",
    "\n",
    "# # two predictions\n",
    "# col_s = col_e\n",
    "# col_e = col_s + channel_g_cols\n",
    "# ax_pred1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "# ax_pred1.imshow(get_cropped_img(pred[...,0], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_pred1.axis('off')\n",
    "\n",
    "# ax_pred2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "# ax_pred2.imshow(get_cropped_img(pred[...,1], channel_h_factor*input_h_factor,  wN=wN, ws=ws)[0], cmap='magma')\n",
    "# ax_pred2.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "# 5x10 grid for the input. 2x10 grid for the two targets and predictions.\n",
    "\n",
    "key = keys[0]\n",
    "input_h_factor = 1.5 # we want to make rectangula\n",
    "channel_h_factor = 0.324\n",
    "unit_size = 2\n",
    "ncols = 4\n",
    "nrows = 1\n",
    "grid_factor = 450\n",
    "wN = 400\n",
    "savefig = True\n",
    "zoom_in = 1.5\n",
    "\n",
    "if savefig is False:\n",
    "    ws = np.random.randint(0, inp.shape[1] - wN)\n",
    "    hs = np.random.randint(0, inp.shape[0] - wN*input_h_factor)\n",
    "\n",
    "    # within the input patch, this describes the region of interest.\n",
    "    ws_inset = ws + np.random.randint(0, wN - int(wN/zoom_in)) if zoom_in > 1 else ws\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{ws}, {hs}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*unit_size,int(nrows*unit_size*input_h_factor)))\n",
    "gs = gridspec.GridSpec(int(nrows*grid_factor), ncols*grid_factor, figure=fig, wspace=0.0, hspace=0.1)\n",
    "\n",
    "gt, pred = gt_pred_dict[key]\n",
    "gt = gt.squeeze()\n",
    "pred = pred.squeeze()\n",
    "inp = get_input(gt)[0]\n",
    "\n",
    "channel_g_rows = int(grid_factor*channel_h_factor)\n",
    "channel_g_cols = grid_factor\n",
    "\n",
    "# input \n",
    "col_s = 0\n",
    "col_e = grid_factor\n",
    "row_s = 0\n",
    "row_e = int(grid_factor)\n",
    "\n",
    "ax_inp = fig.add_subplot(gs[row_s:row_e, col_s:col_e])\n",
    "inp_crop, input_coordinates = get_cropped_img(inp, input_h_factor, wN=wN, ws=ws, hs=hs)\n",
    "ax_inp.imshow(inp_crop, cmap='magma')\n",
    "ax_inp.axis('off')\n",
    "\n",
    "# three targets\n",
    "# tar 1\n",
    "col_s = col_e\n",
    "col_e = col_s + channel_g_cols\n",
    "row1_s = 0\n",
    "row1_e = channel_g_rows\n",
    "ax_tar1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "# find the most interesting box in the inp_crop\n",
    "hs_tar = hs + find_most_interesting_box(inp_crop, channel_h_factor)\n",
    "\n",
    "tar1_crop, ch_cordinates = get_cropped_img(gt[...,0], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar)\n",
    "ax_tar1.imshow(tar1_crop, cmap='magma')\n",
    "ax_tar1.axis('off')\n",
    "relative_coordinates = (ch_cordinates[0] - input_coordinates[0],\n",
    "                        ch_cordinates[1] - input_coordinates[1],\n",
    "                        ch_cordinates[2],\n",
    "                        ch_cordinates[3])\n",
    "rect = patches.Rectangle((relative_coordinates[1]+3, relative_coordinates[0]), relative_coordinates[3]-9,relative_coordinates[2], \n",
    "                         linewidth=2, edgecolor='w', facecolor='none', linestyle='--')\n",
    "ax_inp.add_patch(rect)\n",
    "\n",
    "# tar 2\n",
    "row_offset= 3\n",
    "row2_s = channel_g_rows + row_offset\n",
    "row2_e = 2*channel_g_rows + row_offset\n",
    "ax_tar2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "ax_tar2.imshow(get_cropped_img(gt[...,1], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar)[0], cmap='magma')\n",
    "ax_tar2.axis('off')\n",
    "\n",
    "# tar 3\n",
    "extra_h = 0\n",
    "extra_w = -20\n",
    "row3_s = 2*channel_g_rows + 2*row_offset\n",
    "row3_e = grid_factor\n",
    "ax_tar3 = fig.add_subplot(gs[row3_s:row3_e, col_s:col_e])\n",
    "ax_tar3.imshow(get_cropped_img(gt[...,2], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar, extra_h=extra_h, extra_w=extra_w+5)[0], cmap='magma')\n",
    "ax_tar3.axis('off')\n",
    "\n",
    "\n",
    "# three predictions\n",
    "col_s = col_e\n",
    "col_e = col_s + channel_g_cols\n",
    "ax_pred1 = fig.add_subplot(gs[row1_s:row1_e, col_s:col_e])\n",
    "ax_pred1.imshow(get_cropped_img(pred[...,0], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar)[0], cmap='magma')\n",
    "ax_pred1.axis('off')\n",
    "\n",
    "ax_pred2 = fig.add_subplot(gs[row2_s:row2_e, col_s:col_e])\n",
    "ax_pred2.imshow(get_cropped_img(pred[...,1], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar)[0], cmap='magma')\n",
    "ax_pred2.axis('off')\n",
    "\n",
    "ax_pred3 = fig.add_subplot(gs[row3_s:row3_e, col_s:col_e])\n",
    "ax_pred3.imshow(get_cropped_img(pred[...,2], channel_h_factor*input_h_factor,  wN=int(wN/zoom_in), ws=ws_inset,hs=hs_tar, extra_h=extra_h,extra_w=extra_w+5)[0], cmap='magma')\n",
    "ax_pred3.axis('off')\n",
    "\n",
    "if savefig:\n",
    "    \n",
    "    # filename should contain all cropping information\n",
    "    fname = 'cropped_{}_K{}_{}-{}-{}-{}.png'.format(key.replace('/','_'),KTH_SAMPLE, ch_cordinates[0], ch_cordinates[1], ch_cordinates[2], ch_cordinates[3])\n",
    "    fpath = os.path.join(output_data_dir, fname)\n",
    "    print(fpath)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inp_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# _, ax = plt.subplots(figsize=(9,15), ncols=3, nrows=5)\n",
    "# ex_idx = ex_idx +1 #np.random.choice(range(len(data['inp'])))\n",
    "# print(ex_idx)\n",
    "# ax[0,0].imshow(data['inp'][ex_idx][0,0].cpu().numpy())\n",
    "# ax[0,1].imshow(data['tar'][ex_idx][0,0].cpu().numpy())\n",
    "# ax[0,2].imshow(data['tar'][ex_idx][0,1].cpu().numpy())\n",
    "\n",
    "# ax[1,1].imshow(data['pred'][0][ex_idx].mean(axis=0))\n",
    "# ax[1,2].imshow(data['pred'][1][ex_idx].mean(axis=0))\n",
    "\n",
    "# ax[2,1].imshow(data['pred'][0][ex_idx][0])\n",
    "# ax[2,2].imshow(data['pred'][1][ex_idx][0])\n",
    "# ax[3,1].imshow(data['pred'][0][ex_idx][1])\n",
    "# ax[3,2].imshow(data['pred'][1][ex_idx][1])\n",
    "\n",
    "# ax[4,1].imshow(data['pred'][0][ex_idx][1] - data['pred'][0][ex_idx][0])\n",
    "# ax[4,2].imshow(data['pred'][1][ex_idx][1] - data['pred'][1][ex_idx][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "kth = 1\n",
    "incorrect_data = load_tiff(f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_1/pred_training_disentangle_2405_D25-M3-S0-L8_3_1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_data =load_tiff('/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/pred_training_disentangle_2405_D25-M3-S0-L8_3_1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# _,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "# ch_idx = 1\n",
    "# ax[0].imshow(incorrect_data[0,...,ch_idx])\n",
    "# ax[1].imshow(correct_data[:2,...,ch_idx].sum(axis=0))\n",
    "# ax[2].imshow(correct_data[0,...,ch_idx])\n",
    "# ax[3].imshow(correct_data[1,...,ch_idx])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "ch_idx = 1\n",
    "ax[0].imshow(incorrect_data[0,...,ch_idx])\n",
    "ax[1].imshow(correct_data[[0,kth],...,ch_idx].sum(axis=0))\n",
    "ax[2].imshow(correct_data[0,...,ch_idx])\n",
    "ax[3].imshow(correct_data[kth,...,ch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(incorrect_data[0,...,ch_idx].mean(), correct_data[:2,...,ch_idx].sum(axis=0).mean(), correct_data[0,...,ch_idx].mean(), correct_data[1,...,ch_idx].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "from disentangle.core.tiff_reader import save_tiff\n",
    "import os\n",
    "\n",
    "# fpath = '/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0/pred_training_disentangle_2406_D25-M3-S0-L8_14_1.tif'\n",
    "# data = load_tiff(fpath)\n",
    "\n",
    "# for i in range(data.shape[0]):\n",
    "#     fname = os.path.basename(fpath)\n",
    "#     new_dir = f'/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk0_F/kth_{i}/'\n",
    "#     new_fpath = os.path.join(new_dir, fname)\n",
    "#     save_tiff(new_fpath, data[i:i+1])\n",
    "#     print(new_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0,...,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
