{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ashesh.ashesh/code/Disentangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run ./nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.patch_index_manager import TilingMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ckpt_dir = \"/group/jug/ashesh/training/disentangle/2406/D25-M3-S0-L8/17\"\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2406/D25-M3-S0-L8/4'\n",
    "outputdir = '/group/jug/ashesh/EnsDeLyon/coverage_dicts/'\n",
    "\n",
    "image_size_for_grid_centers = 32\n",
    "mmse_count = 10\n",
    "elem_size = 5\n",
    "custom_image_size = None\n",
    "data_t_list = [0] #[0,1,2,3]\n",
    "skip_percentile = 50\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "\n",
    "save_comparative_plots =False\n",
    "enable_calibration = False\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "        \n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    if 'validtarget_random_fraction' in config.data:\n",
    "        config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    if 'dump_kth_frame_prediction' in config.training:\n",
    "        config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    if 'input_is_sum' not in config.data:\n",
    "        config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_patches(model, dset,num_workers=4, batch_size = 32):\n",
    "#     dloader = DataLoader(dset, pin_memory=False, num_workers=num_workers, shuffle=False, batch_size=batch_size)\n",
    "#     tar_patches = []\n",
    "#     for batch in tqdm(dloader):\n",
    "#         inp, tar = batch[:2]\n",
    "#         inp = inp.cuda()\n",
    "#         tar = tar.cuda()\n",
    "#         tar_normalized = model.normalize_target(tar)\n",
    "#         tar_patches.append(tar_normalized.cpu().numpy())\n",
    "#     tar_patches = np.concatenate(tar_patches, axis=0)\n",
    "#     return tar_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c54b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.background_threshold_estimation import get_background_thresholds\n",
    "target_normalizer_func = lambda x: model.normalize_target(x.cuda())\n",
    "background_thresholds = get_background_thresholds(val_dset,target_normalizer_func, num_workers=4, batch_size=32, skip_percentile=skip_percentile)\n",
    "print(background_thresholds)\n",
    "\n",
    "# import numpy as np\n",
    "# tar_patches = get_patches(model, val_dset, num_workers=num_workers, batch_size=batch_size)\n",
    "# background_thresholds = [np.percentile(tar_patches[:,i], skip_percentile) for i in range(tar_patches.shape[1])]\n",
    "\n",
    "def background_patch_detection_func(data, ch_idx):\n",
    "    threshold = background_thresholds[ch_idx]\n",
    "    return data.reshape(data.shape[0],-1).mean(axis=-1) < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.calibration_coverage import  get_calibration_coverage_data\n",
    "import numpy as np\n",
    "# mmse_count = 10\n",
    "scalar_values = [1]\n",
    "coverage_dict = {}\n",
    "num_workers = 4\n",
    "for scalar in scalar_values:\n",
    "    var, err =get_calibration_coverage_data(model, val_dset, num_workers=num_workers,\n",
    "                                       calib_stats_dict={0:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      1:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      2:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      },\n",
    "                                        mmse_count=mmse_count,\n",
    "                                        elem_size=elem_size,\n",
    "                                        background_patch_detection_func=background_patch_detection_func)\n",
    "    nan_mask = np.isnan(var).any(axis=-1).any(axis=-1)\n",
    "    var = var[~nan_mask]\n",
    "    err = err[~nan_mask]\n",
    "    coverage_dict[scalar] = (var, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.shape, err.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65e762",
   "metadata": {},
   "source": [
    "### Grid search for optimal scaling parameter.\n",
    "binary search inspired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.calibration_coverage_grid_search import grid_search\n",
    "from disentangle.analysis.calibration_coverage_grid_search import plot_coverage_plot\n",
    "from disentangle.analysis.calibration_coverage_grid_search import get_percentage_occurance\n",
    "\n",
    "factors = []\n",
    "offsets = []\n",
    "achieved_percentiles = []\n",
    "for ch_idx in range(var.shape[1]):\n",
    "    print('Starting the grid search')\n",
    "    factor_ch, offset_ch, achieved_percentile_ch = grid_search(err[:,ch_idx], var[:,ch_idx], init_delta=10, init_factor=10,around_center=False)\n",
    "    factors.append(factor_ch)\n",
    "    offsets.append(offset_ch)\n",
    "    achieved_percentiles.append(achieved_percentile_ch)\n",
    "    \n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6beac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd44295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "_,ax = plt.subplots(figsize=(7,5))\n",
    "log_scale = True\n",
    "ch_idx = 2\n",
    "sns.histplot(var[:,ch_idx,:4].reshape(-1,), bins=1000,log_scale=log_scale, ax=ax, label='Unscaled_var', stat='probability')\n",
    "sns.histplot(factors[ch_idx]*var[:,ch_idx,:4].reshape(-1,) + offsets[ch_idx], bins=1000,log_scale=log_scale, ax=ax, label='Scaled_var', stat='probability')\n",
    "sns.histplot(err[:,ch_idx], bins=1000,log_scale=log_scale, ax=ax, label='err', stat='probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left_oriented = plot_coverage_plot(var, err, factors, offsets, around_center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ca197",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_centered = plot_coverage_plot(var, err, factors, offsets, around_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = np.linspace(0,100,100)\n",
    "for col_idx in range(var.shape[1]):\n",
    "    act = data_centered[col_idx]['scaled'][1]\n",
    "    mean_err = np.abs(perfect - act).mean() \n",
    "    max_err = np.abs(perfect - act).max()\n",
    "    print(f'Centered: Channel {col_idx} MAE {mean_err:.2f}, MAX Err {max_err:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = np.linspace(0,100,100)\n",
    "for col_idx in range(var.shape[1]):\n",
    "    act = data_left_oriented[col_idx]['scaled'][1]\n",
    "    mean_err = np.abs(perfect - act).mean() \n",
    "    max_err = np.abs(perfect - act).max()\n",
    "    print(f'LeftOriented: Channel {col_idx} MAE {mean_err:.2f}, MAX Err {max_err:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_centered[2]['scaled'][2], label='Larger')\n",
    "plt.plot(data_centered[2]['scaled'][0], label='Smaller')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
