{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ashesh.ashesh/code/Disentangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/root_dirs.ipynb\n",
    "setup_syspath_disentangle(False)\n",
    "%run ./nb_core/disentangle_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.data_loader.patch_index_manager import TilingMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9748a9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ckpt_dir = \"/group/jug/ashesh/training/disentangle/2406/D25-M3-S0-L8/17\"\n",
    "# ckpt_dir = '/group/jug/ashesh/training/disentangle/2406/D25-M3-S0-L8/4'\n",
    "outputdir = '/group/jug/ashesh/EnsDeLyon/coverage_dicts/'\n",
    "\n",
    "image_size_for_grid_centers = 32\n",
    "mmse_count = 50\n",
    "elem_size = 5\n",
    "custom_image_size = None\n",
    "data_t_list = [0] #[0,1,2,3]\n",
    "skip_percentile = 50\n",
    "tiling_mode = TilingMode.ShiftBoundary\n",
    "\n",
    "save_comparative_plots =False\n",
    "enable_calibration = False\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None\n",
    "threshold = None # 0.02\n",
    "compute_kl_loss = False\n",
    "evaluate_train = False# inspect training performance\n",
    "eval_datasplit_type = DataSplitType.Test \n",
    "val_repeat_factor = None\n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(ckpt_fpath):\n",
    "    if os.path.isdir(ckpt_fpath):\n",
    "        ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "    elif os.path.isfile(ckpt_fpath):\n",
    "        ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "    assert ckpt_fpath[-1] != '/'\n",
    "    return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = get_dtype(ckpt_dir)\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/config_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ckpt_dir.split('/')\n",
    "idx = tokens.index('disentangle')\n",
    "if config.model.model_type == 25 and tokens[idx+1] == '2312':\n",
    "    config.model.model_type = ModelType.LadderVAERestrictedReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.sampler_type import SamplerType\n",
    "from disentangle.core.loss_type import LossType\n",
    "from disentangle.data_loader.ht_iba1_ki67_rawdata_loader import SubDsetType\n",
    "# from disentangle.core.lowres_merge_type import LowresMergeType\n",
    "\n",
    "\n",
    "with config.unlocked():\n",
    "    if 'depth3D' in config.data and config.data.depth3D > 1:\n",
    "        config.data.mode_3D = True\n",
    "        config.model.mode_3D = True\n",
    "        \n",
    "    config.model.skip_nboundary_pixels_from_loss = None\n",
    "    if config.model.model_type == ModelType.UNet and 'n_levels' not in config.model:\n",
    "        config.model.n_levels = 4\n",
    "    if config.data.sampler_type == SamplerType.NeighborSampler:\n",
    "        config.data.sampler_type = SamplerType.DefaultSampler\n",
    "        config.loss.loss_type = LossType.Elbo\n",
    "        config.data.grid_size = config.data.image_size\n",
    "    if 'ch1_fpath_list' in config.data:\n",
    "        config.data.ch1_fpath_list = config.data.ch1_fpath_list[:1]\n",
    "        config.data.mix_fpath_list = config.data.mix_fpath_list[:1]\n",
    "    if config.data.data_type == DataType.Pavia2VanillaSplitting:\n",
    "        if 'channel_2_downscale_factor' not in config.data:\n",
    "            config.data.channel_2_downscale_factor = 1\n",
    "    if config.model.model_type == ModelType.UNet and 'init_channel_count' not in config.model:\n",
    "        config.model.init_channel_count = 64\n",
    "    \n",
    "    if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "        config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "    if dtype == DataType.HTIba1Ki67:\n",
    "        config.data.subdset_type = SubDsetType.OnlyIba1P30\n",
    "        config.data.empty_patch_replacement_enabled = False\n",
    "    \n",
    "    if 'lowres_merge_type' not in config.model.encoder:\n",
    "        config.model.encoder.lowres_merge_type = 0\n",
    "    if 'validtarget_random_fraction' in config.data:\n",
    "        config.data.validtarget_random_fraction = None\n",
    "    \n",
    "    if config.data.data_type == DataType.TwoDset:\n",
    "        config.model.model_type = ModelType.LadderVae\n",
    "        for key in config.data.dset1:\n",
    "            config.data[key] = config.data.dset1[key]\n",
    "    \n",
    "    if 'dump_kth_frame_prediction' in config.training:\n",
    "        config.training.dump_kth_frame_prediction = None\n",
    "\n",
    "    if 'input_is_sum' not in config.data:\n",
    "        config.data.input_is_sum = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "    data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "elif dtype == DataType.OptiMEM100_014:\n",
    "    data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "elif dtype == DataType.Prevedel_EMBL:\n",
    "    data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "elif dtype == DataType.AllenCellMito:\n",
    "    data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "elif dtype == DataType.SeparateTiffData:\n",
    "    data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "    data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "    data_dir = f'{DATA_ROOT}/pavia2'\n",
    "# elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "    # data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "elif dtype == DataType.ShroffMitoEr:\n",
    "    data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "elif dtype == DataType.HTIba1Ki67:\n",
    "    data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "elif dtype == DataType.BioSR_MRC:\n",
    "    data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "elif dtype == DataType.ExpMicroscopyV2:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/datafiles/'\n",
    "elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "    data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "elif dtype == DataType.Pavia3SeqData:\n",
    "    data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "elif dtype == DataType.NicolaData:\n",
    "    data_dir = f'{DATA_ROOT}/nikola_data/20240531/'\n",
    "elif dtype == DataType.Dao3ChannelWithInput:\n",
    "    data_dir = f'{DATA_ROOT}/Dao4Channel/'\n",
    "elif dtype == DataType.Dao3Channel:\n",
    "    data_dir = f'{DATA_ROOT}/Dao3Channel/'\n",
    "elif dtype == DataType.SilvioLabCSHLData:\n",
    "    data_dir = f'{DATA_ROOT}/svilen_cshl2024/'\n",
    "elif dtype == DataType.ExpMicroscopyV3:\n",
    "    data_dir = f'{DATA_ROOT}/expansion_microscopy_v4/405_NHS_488BODIPY/'\n",
    "elif dtype == DataType.Elisa3DData:\n",
    "    data_dir = f'{DATA_ROOT}/Elisa3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.noise_model_ch1_fpath = config.model.noise_model_ch1_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')\n",
    "# config.model.noise_model_ch2_fpath = config.model.noise_model_ch2_fpath.replace('/home/ashesh.ashesh/training/', '/group/jug/ashesh/training_pre_eccv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./nb_core/disentangle_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and custom_image_size is not None:\n",
    "    model.reset_for_different_output_size(custom_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_,ax = plt.subplots(figsize=(4*ncols,4*nrows),ncols=ncols,nrows=nrows)\n",
    "for i in range(min(ncols,len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.calibration_coverage_v2 import patches_for_optimal_transform\n",
    "# val_dset.set_img_sz(64, 32)\n",
    "# model.reset_for_different_output_size(64)\n",
    "# tar_patches, recons_patches = patches_for_optimal_transform(model, val_dset, num_workers=num_workers, batch_size=batch_size, mmse_count=mmse_count, elem_size=elem_size, skip_pixels=32)\n",
    "def get_patches(model, dset,num_workers=4, batch_size = 32):\n",
    "    dloader = DataLoader(dset, pin_memory=False, num_workers=num_workers, shuffle=False, batch_size=batch_size)\n",
    "    tar_patches = []\n",
    "    for batch in tqdm(dloader):\n",
    "        inp, tar = batch[:2]\n",
    "        inp = inp.cuda()\n",
    "        tar = tar.cuda()\n",
    "        tar_normalized = model.normalize_target(tar)\n",
    "        tar_patches.append(tar_normalized.cpu().numpy())\n",
    "    tar_patches = np.concatenate(tar_patches, axis=0)\n",
    "    return tar_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c54b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tar_patches = get_patches(model, val_dset, num_workers=num_workers, batch_size=batch_size)\n",
    "background_thresholds = [np.percentile(tar_patches[:,i], skip_percentile) for i in range(tar_patches.shape[1])]\n",
    "print(background_thresholds)\n",
    "\n",
    "def background_patch_detection_func(data, ch_idx):\n",
    "    threshold = background_thresholds[ch_idx]\n",
    "    return data.reshape(data.shape[0],-1).mean(axis=-1) < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa350ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# from disentangle.analysis.calibration_coverage_v2 import find_optimal_scalar_offset\n",
    "# import numpy as np\n",
    "\n",
    "# def fit_optimal_transform(recons_patches, tar_patches, skip_percentile=50):\n",
    "#     mmse_recons = recons_patches.mean(axis=1)\n",
    "#     # N x C x H x W for both tar_patches and mmse_recons\n",
    "#     assert tar_patches.shape == mmse_recons.shape, f'{tar_patches.shape} != {mmse_recons.shape}'\n",
    "#     assert tar_patches.ndim == 4, f'{tar_patches.ndim} != 4'\n",
    "#     N = tar_patches.shape[0]\n",
    "#     output = {}\n",
    "#     for ch_idx in range(tar_patches.shape[1]):\n",
    "#         recons_data = mmse_recons[:, ch_idx]\n",
    "#         tar_data = tar_patches[:, ch_idx]\n",
    "#         backgrnd = np.percentile(tar_data, skip_percentile)\n",
    "#         fg_mask = tar_data.mean(axis=(1,2)) > backgrnd\n",
    "#         print('fg_mask', fg_mask.mean())\n",
    "#         scalar, offset = find_optimal_scalar_offset(recons_data[fg_mask], tar_patches[fg_mask, ch_idx])\n",
    "#         output[ch_idx] = {'scalar':scalar, 'offset':offset}\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ce60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_transform_dict = fit_optimal_transform(recons_patches, tar_patches, skip_percentile=50)\n",
    "# print(optimal_transform_dict)\n",
    "\n",
    "\n",
    "# def get_background_thresholds():\n",
    "#     return [optimal_transform_dict[0]['qval'], optimal_transform_dict[1]['qval'], optimal_transform_dict[2]['qval']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "# ax[0].imshow(tar_patches[3,2])\n",
    "# ax[1].imshow(recons_patches[3,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # 2406/D25-M3-S0-L8/17\n",
    "# fpath = '/group/jug/ashesh/data/paper_stats/Val_P64_G32_M50_Sk0/calib_training_disentangle_2406_D25-M3-S0-L8_17.pkl'\n",
    "# with open(fpath, \"rb\") as f:\n",
    "#     eval_calibration_factors = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.stitch_prediction import stitch_predictions\n",
    "# from disentangle.analysis.mmse_prediction import get_dset_predictions\n",
    "# # from disentangle.analysis.stitch_prediction import get_predictions as get_dset_predictions\n",
    "# def get_mean_std(nTar):\n",
    "#     mean, std = val_dset.get_mean_std()\n",
    "#     mean = mean['target'].squeeze()\n",
    "#     std = std['target'].squeeze()\n",
    "#     print(mean.shape, std.shape)\n",
    "#     return mean[:nTar].reshape(1,1,1,nTar), std[:nTar].reshape(1,1,1,nTar)\n",
    "\n",
    "\n",
    "\n",
    "# pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(model, val_dset,batch_size,\n",
    "#                                                num_workers=num_workers,\n",
    "#                                                mmse_count=mmse_count,\n",
    "#                                                 model_type = config.model.model_type,\n",
    "#                                               )\n",
    "# tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "# print('Patch wise PSNR, as computed during training', tmp, np.mean(tmp))\n",
    "# pred = stitch_predictions(pred_tiled, val_dset, )\n",
    "\n",
    "# # target \n",
    "# is_list_prediction = isinstance(pred, list)\n",
    "# tar_unnorm = (val_dset._data if not is_list_prediction else [val_dset.dsets[i]._data for i in range(len(val_dset.dsets))])\n",
    "\n",
    "# if \"target_idx_list\" in config.data and config.data.target_idx_list is not None:\n",
    "#     nTar =len(config.data.target_idx_list)\n",
    "#     pred = pred[..., :len(config.data.target_idx_list)] if not is_list_prediction else [pred[i][..., :len(config.data.target_idx_list)] for i in range(len(pred))]\n",
    "#     tar_unnorm = [x[...,config.data.target_idx_list] for x in tar_unnorm] if is_list_prediction else tar_unnorm[...,config.data.target_idx_list]\n",
    "\n",
    "# nTar = pred[0].shape[-1]\n",
    "# mean, std = get_mean_std(nTar)\n",
    "# # normalize the target\n",
    "# tar = [(x-mean)/std for x in tar_unnorm] if is_list_prediction else (tar_unnorm-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab893b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.calibration_coverage_v2 import find_optimal_scalar_offset\n",
    "# scalar, offset = find_optimal_scalar_offset(pred, tar)\n",
    "# print(scalar, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.calibration_coverage import  get_calibration_coverage_data\n",
    "import numpy as np\n",
    "# mmse_count = 10\n",
    "scalar_values = [1]\n",
    "coverage_dict = {}\n",
    "num_workers = 4\n",
    "for scalar in scalar_values:\n",
    "    var, err =get_calibration_coverage_data(model, val_dset, num_workers=num_workers,\n",
    "                                       calib_stats_dict={0:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      1:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      2:{'scalar':scalar,'offset':0.0}, \n",
    "                                                                      },\n",
    "                                        mmse_count=mmse_count,\n",
    "                                        elem_size=elem_size,\n",
    "                                        background_patch_detection_func=background_patch_detection_func)\n",
    "    nan_mask = np.isnan(var).any(axis=-1).any(axis=-1)\n",
    "    var = var[~nan_mask]\n",
    "    err = err[~nan_mask]\n",
    "    coverage_dict[scalar] = (var, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.shape, err.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_optimal_scaling(x,y):\n",
    "#     \"\"\"\n",
    "#     minimize ||y - ax -b||^2\n",
    "#     \"\"\"\n",
    "#     x = x.reshape(-1)\n",
    "#     y = y.reshape(-1)\n",
    "#     ux = np.mean(x)\n",
    "#     uy = np.mean(y)\n",
    "#     uxy = np.mean(x*y)\n",
    "#     ux2 = np.mean(x*x)\n",
    "#     a = (uxy - ux*uy)/(ux2 - ux*ux)\n",
    "#     b = uy - a*ux\n",
    "#     return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998493f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_var= np.mean(var, axis=-1)\n",
    "median_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c250c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.shape, err.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65e762",
   "metadata": {},
   "source": [
    "### Grid search for optimal scaling parameter.\n",
    "binary search inspired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.calibration_coverage_grid_search import grid_search\n",
    "factors = []\n",
    "achieved_percentiles = []\n",
    "for ch_idx in range(var.shape[1]):\n",
    "    print('Starting the grid search')\n",
    "    factor_ch1, achieved_percentile_ch1 = grid_search(err[:,ch_idx], var[:,ch_idx], init_delta=1)\n",
    "    factors.append(factor_ch1)\n",
    "    achieved_percentiles.append(achieved_percentile_ch1)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28adcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,100,100)\n",
    "y = get_percentage_occurance(x, err[:,ch_idx], var[:,ch_idx], factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518cc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ncols = var.shape[1]\n",
    "_,ax = plt.subplots(figsize=(5*ncols,5),ncols=ncols)\n",
    "for col_idx in range(ncols):    \n",
    "    # percentiles = x\n",
    "    linestyles = [\n",
    "        'solid',\n",
    "        'dotted',\n",
    "        'dashed',\n",
    "        'dashdot',]\n",
    "    \n",
    "    x = np.linspace(0,100,100)\n",
    "    # scaled. \n",
    "    y = get_percentage_occurance(x, err[:,col_idx], var[:,col_idx], factors[col_idx])\n",
    "\n",
    "    ax[col_idx].plot(x, y, label=f'Scaled', linestyle= linestyles[i%len(linestyles)])\n",
    "    y = get_percentage_occurance(x, err[:,col_idx], var[:,col_idx], 1)\n",
    "\n",
    "    ax[col_idx].plot(x, y, label=f'Unscaled', linestyle= linestyles[i%len(linestyles)])\n",
    "\n",
    "    ax[col_idx].grid()\n",
    "    # facecolor to gray\n",
    "    ax[col_idx].set_facecolor('lightgray')\n",
    "    ax[col_idx].set_xlabel('Percentile (Confidence level)')\n",
    "    ax[col_idx].set_ylabel('Percentage of data (Empirical coverage)')\n",
    "# plot y=x line\n",
    "    ax[col_idx].plot([0,100],[0,100], 'k--')\n",
    "\n",
    "ax[-1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29891da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales = []\n",
    "# offsets = []\n",
    "# for ch_idx in range(err.shape[1]):\n",
    "#     scale,offset = get_optimal_scaling(median_var[:,ch_idx], err[:,ch_idx])\n",
    "#     scales.append(scale)\n",
    "#     offsets.append(offset)\n",
    "\n",
    "# scales = np.array(scales).reshape(1,-1)\n",
    "# offsets = np.array(offsets).reshape(1,-1)\n",
    "# scales, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean((median_var*scales + offsets - err)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean((median_var - err)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_var = var*scales[...,None] + offsets[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# from tqdm import tqdm\n",
    "# scaled_percentile_data = np.zeros(err.shape)\n",
    "# unscaled_percentile_data = np.zeros(err.shape)\n",
    "# for elem_idx in tqdm(range(len(scaled_var))):\n",
    "#     for col_idx in range(scaled_var.shape[1]):\n",
    "#         scaled_percentile_data[elem_idx,col_idx] = scipy.stats.percentileofscore(scaled_var[elem_idx,col_idx],err[elem_idx, col_idx])\n",
    "#         unscaled_percentile_data[elem_idx,col_idx] = scipy.stats.percentileofscore(var[elem_idx,col_idx],err[elem_idx, col_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def how_many_lie_in_k_quantiles(calibration_coverage_data, k):\n",
    "#     assert k >= 0 and k <= 100\n",
    "#     return np.mean(calibration_coverage_data <= k) * 100\n",
    "\n",
    "\n",
    "# ncols = scaled_percentile_data.shape[1]\n",
    "# _,ax = plt.subplots(figsize=(5*ncols,5),ncols=ncols)\n",
    "# for col_idx in range(ncols):    \n",
    "#     # percentiles = x\n",
    "#     linestyles = [\n",
    "#         'solid',\n",
    "#         'dotted',\n",
    "#         'dashed',\n",
    "#         'dashdot',]\n",
    "    \n",
    "#     x = np.linspace(0,100,100)\n",
    "#     # scaled. \n",
    "#     cov = scaled_percentile_data[:,col_idx]\n",
    "#     y = [how_many_lie_in_k_quantiles(cov, k) for k in x]\n",
    "#     ax[col_idx].plot(x, y, label=f'Scaled', linestyle= linestyles[i%len(linestyles)])\n",
    "#     # unscaled\n",
    "#     cov = unscaled_percentile_data[:,col_idx]\n",
    "#     y = [how_many_lie_in_k_quantiles(cov, k) for k in x]\n",
    "#     ax[col_idx].plot(x, y, label=f'Unscaled', linestyle= linestyles[i%len(linestyles)])\n",
    "\n",
    "#     ax[col_idx].grid()\n",
    "#     # facecolor to gray\n",
    "#     ax[col_idx].set_facecolor('lightgray')\n",
    "#     ax[col_idx].set_xlabel('Percentile (Confidence level)')\n",
    "#     ax[col_idx].set_ylabel('Percentage of data (Empirical coverage)')\n",
    "# # plot y=x line\n",
    "#     ax[col_idx].plot([0,100],[0,100], 'k--')\n",
    "\n",
    "# ax[-1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c43a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.Series(percentile_data.reshape(-1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578aacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.calibration_coverage import  get_calibration_coverage_data\n",
    "# import numpy as np\n",
    "# # mmse_count = 10\n",
    "# def background_patch_detection_func(data, ch_idx):\n",
    "#     threshold = get_background_thresholds()[ch_idx]\n",
    "#     return data.reshape(data.shape[0],-1).mean(axis=-1) > threshold\n",
    "\n",
    "# coverage_dict = {}\n",
    "# cov_unscaled =get_calibration_coverage_data(model, val_dset, \n",
    "#                                        calib_stats_dict={   0:{'scalar':1.0,'offset':0.0}, \n",
    "#                                                             1:{'scalar':1.0,'offset':0.0}, \n",
    "#                                                             2:{'scalar':1.0,'offset':0.0}, \n",
    "#                                                                       },\n",
    "#                                         mmse_count=mmse_count,\n",
    "#                                         elem_size=elem_size,\n",
    "#                                         )\n",
    "\n",
    "# cov_scaled =get_calibration_coverage_data(model, val_dset, \n",
    "#                                        calib_stats_dict=optimal_transform_dict,\n",
    "#                                         mmse_count=mmse_count,\n",
    "#                                         elem_size=elem_size,\n",
    "#                                         )\n",
    "\n",
    "# coverage_dict['unscaled'] = cov_unscaled\n",
    "# coverage_dict['scaled'] = cov_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the coverage_dict\n",
    "import pickle\n",
    "model_str = '-'.join(ckpt_dir.split('/')[-3:])\n",
    "fpath = os.path.join(outputdir,f'coverage_dict_{model_str}_MMSE-{mmse_count}_E-{elem_size}_Skip-{skip_percentile}.pkl')\n",
    "with open(fpath, 'wb') as f:\n",
    "    pickle.dump(coverage_dict, f)\n",
    "print(f'Coverage dict saved at {fpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def how_many_lie_in_k_quantiles(calibration_coverage_data, k):\n",
    "    assert k >= 0 and k <= 100\n",
    "    return np.mean(calibration_coverage_data <= k) * 100\n",
    "\n",
    "\n",
    "ncols = coverage_dict[list(coverage_dict.keys())[0]].shape[1]\n",
    "_,ax = plt.subplots(figsize=(5*ncols,5),ncols=ncols)\n",
    "for col_idx in range(ncols):    \n",
    "    # percentiles = x\n",
    "    linestyles = [\n",
    "        'solid',\n",
    "        'dotted',\n",
    "        'dashed',\n",
    "        'dashdot',]\n",
    "    \n",
    "    x = np.linspace(0,100,100)\n",
    "    for i,key in enumerate(coverage_dict.keys()):\n",
    "            cov = coverage_dict[key][:,col_idx]\n",
    "            # skip the background patches. they correspond to nan values\n",
    "            print('NaN entries fraction', np.isnan(cov).mean())\n",
    "            cov = cov[~np.isnan(cov)]\n",
    "            y = [how_many_lie_in_k_quantiles(cov, k) for k in x]\n",
    "            ax[col_idx].plot(x, y, label=f'Scaled by:{key}', linestyle= linestyles[i%len(linestyles)])\n",
    "\n",
    "\n",
    "    ax[col_idx].grid()\n",
    "    # facecolor to gray\n",
    "    ax[col_idx].set_facecolor('lightgray')\n",
    "    ax[col_idx].set_xlabel('Percentile (Confidence level)')\n",
    "    ax[col_idx].set_ylabel('Percentage of data (Empirical coverage)')\n",
    "# plot y=x line\n",
    "    ax[col_idx].plot([0,100],[0,100], 'k--')\n",
    "\n",
    "ax[-1].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
