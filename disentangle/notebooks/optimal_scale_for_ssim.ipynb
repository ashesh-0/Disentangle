{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import * \n",
    "ux, uy, sx, sy, sxy, c1, c2, alpha = symbols('u_x u_y s_x s_y s_{xy} c1 c2 alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = (2*ux*uy*alpha + c1) * (2*sxy*alpha + c2) / (ux**2 + alpha**2 * uy**2 + c1) / (sx**2 + alpha**2 * sy**2 + c2)\n",
    "ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative = diff(ssim, alpha)\n",
    "derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import * \n",
    "# ux, uy, sx, sy, sxy, alpha = symbols('u_x u_y s_x s_y s_{xy} alpha', real=True, positive=True)\n",
    "ux, uy, sx, sy, sxy = symbols('u_x u_y s_x s_y s_{xy}', real=True, positive=True)\n",
    "alpha= symbols(' alpha', real=True)\n",
    "ssim = (2*ux*uy*alpha ) * (2*sxy*alpha ) / (ux**2 + alpha**2 * uy**2 ) / (sx**2 + alpha**2 * sy**2 )\n",
    "ssim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative = diff(ssim, alpha)\n",
    "derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = solve(derivative, alpha)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative.subs(alpha, out[0]).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_derivative = diff(derivative, alpha)\n",
    "double_derivative.subs(alpha, out[2]).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_derivative.subs(alpha, out[1]).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex(double_derivative.subs(alpha, out[0]).simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve(derivative, 0, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving it with numerical optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff\n",
    "pred_fpath = '/group/jug/ashesh/data/paper_stats/Test_P64_G32_M50_Sk8_F/kth_0/pred_training_disentangle_2406_D25-M3-S0-L8_12_1.tif'\n",
    "pred = load_tiff(pred_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pred_fname =os.path.basename(pred_fpath)\n",
    "assert pred_fname.endswith('_1.tif')\n",
    "model_subdir = pred_fname.replace('pred_training_disentangle_', '').replace('_1.tif', '').replace('_','/')\n",
    "model_fpath = os.path.join('/group/jug/ashesh/training/disentangle/', model_subdir)\n",
    "model_fpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.config_utils import load_config\n",
    "from disentangle.core.data_split_type import DataSplitType\n",
    "from disentangle.data_loader.nikola_7D_rawdata_loader import get_train_val_data\n",
    "from ml_collections import ConfigDict\n",
    "config = ConfigDict(load_config(model_fpath))\n",
    "with config.unlocked():\n",
    "    config.data.dset_type = '500ms'\n",
    "datadir = '/group/jug/ashesh/data/nikola_data/20240531/'\n",
    "gt_data = get_train_val_data(datadir, config.data, DataSplitType.Test,\n",
    "                            config.training.val_fraction, config.training.test_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kth_idx = int(pred_fpath.split('/')[-2].split('_')[-1])\n",
    "tar = gt_data[kth_idx:kth_idx+1]\n",
    "tar = tar[:,:pred.shape[1], :pred.shape[2], :pred.shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(tar[0,...,0])\n",
    "ax[1].imshow(pred[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.ssim import compute_multiscale_ssim\n",
    "import numpy as np\n",
    "compute_multiscale_ssim(tar.astype(np.float32), pred.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_multiscale_ssim(tar.astype(np.float32), pred.astype(np.float32), range_invariant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "from skimage._shared import utils\n",
    "from skimage._shared.filters import gaussian\n",
    "from skimage._shared.utils import _supported_float_type, check_shape_equality, warn\n",
    "from skimage.util.arraycrop import crop\n",
    "from skimage.util.dtype import dtype_range\n",
    "\n",
    "__all__ = ['structural_similarity']\n",
    "\n",
    "\n",
    "def structural_similarity_dict(\n",
    "    im1,\n",
    "    im2,\n",
    "    *,\n",
    "    win_size=None,\n",
    "    gradient=False,\n",
    "    data_range=None,\n",
    "    channel_axis=None,\n",
    "    gaussian_weights=False,\n",
    "    full=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the mean structural similarity index between two images.\n",
    "    Please pay attention to the `data_range` parameter with floating-point images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1, im2 : ndarray\n",
    "        Images. Any dimensionality with same shape.\n",
    "    win_size : int or None, optional\n",
    "        The side-length of the sliding window used in comparison. Must be an\n",
    "        odd value. If `gaussian_weights` is True, this is ignored and the\n",
    "        window size will depend on `sigma`.\n",
    "    gradient : bool, optional\n",
    "        If True, also return the gradient with respect to im2.\n",
    "    data_range : float, optional\n",
    "        The data range of the input image (difference between maximum and\n",
    "        minimum possible values). By default, this is estimated from the image\n",
    "        data type. This estimate may be wrong for floating-point image data.\n",
    "        Therefore it is recommended to always pass this scalar value explicitly\n",
    "        (see note below).\n",
    "    channel_axis : int or None, optional\n",
    "        If None, the image is assumed to be a grayscale (single channel) image.\n",
    "        Otherwise, this parameter indicates which axis of the array corresponds\n",
    "        to channels.\n",
    "\n",
    "        .. versionadded:: 0.19\n",
    "           ``channel_axis`` was added in 0.19.\n",
    "    gaussian_weights : bool, optional\n",
    "        If True, each patch has its mean and variance spatially weighted by a\n",
    "        normalized Gaussian kernel of width sigma=1.5.\n",
    "    full : bool, optional\n",
    "        If True, also return the full structural similarity image.\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    use_sample_covariance : bool\n",
    "        If True, normalize covariances by N-1 rather than, N where N is the\n",
    "        number of pixels within the sliding window.\n",
    "    K1 : float\n",
    "        Algorithm parameter, K1 (small constant, see [1]_).\n",
    "    K2 : float\n",
    "        Algorithm parameter, K2 (small constant, see [1]_).\n",
    "    sigma : float\n",
    "        Standard deviation for the Gaussian when `gaussian_weights` is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mssim : float\n",
    "        The mean structural similarity index over the image.\n",
    "    grad : ndarray\n",
    "        The gradient of the structural similarity between im1 and im2 [2]_.\n",
    "        This is only returned if `gradient` is set to True.\n",
    "    S : ndarray\n",
    "        The full SSIM image.  This is only returned if `full` is set to True.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If `data_range` is not specified, the range is automatically guessed\n",
    "    based on the image data type. However for floating-point image data, this\n",
    "    estimate yields a result double the value of the desired range, as the\n",
    "    `dtype_range` in `skimage.util.dtype.py` has defined intervals from -1 to\n",
    "    +1. This yields an estimate of 2, instead of 1, which is most often\n",
    "    required when working with image data (as negative light intensities are\n",
    "    nonsensical). In case of working with YCbCr-like color data, note that\n",
    "    these ranges are different per channel (Cb and Cr have double the range\n",
    "    of Y), so one cannot calculate a channel-averaged SSIM with a single call\n",
    "    to this function, as identical ranges are assumed for each channel.\n",
    "\n",
    "    To match the implementation of Wang et al. [1]_, set `gaussian_weights`\n",
    "    to True, `sigma` to 1.5, `use_sample_covariance` to False, and\n",
    "    specify the `data_range` argument.\n",
    "\n",
    "    .. versionchanged:: 0.16\n",
    "        This function was renamed from ``skimage.measure.compare_ssim`` to\n",
    "        ``skimage.metrics.structural_similarity``.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P.\n",
    "       (2004). Image quality assessment: From error visibility to\n",
    "       structural similarity. IEEE Transactions on Image Processing,\n",
    "       13, 600-612.\n",
    "       https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf,\n",
    "       :DOI:`10.1109/TIP.2003.819861`\n",
    "\n",
    "    .. [2] Avanaki, A. N. (2009). Exact global histogram specification\n",
    "       optimized for structural similarity. Optical Review, 16, 613-621.\n",
    "       :arxiv:`0901.0065`\n",
    "       :DOI:`10.1007/s10043-009-0119-z`\n",
    "\n",
    "    \"\"\"\n",
    "    check_shape_equality(im1, im2)\n",
    "    float_type = _supported_float_type(im1.dtype)\n",
    "\n",
    "    if channel_axis is not None:\n",
    "        # loop over channels\n",
    "        args = dict(\n",
    "            win_size=win_size,\n",
    "            gradient=gradient,\n",
    "            data_range=data_range,\n",
    "            channel_axis=None,\n",
    "            gaussian_weights=gaussian_weights,\n",
    "            full=full,\n",
    "        )\n",
    "        args.update(kwargs)\n",
    "        nch = im1.shape[channel_axis]\n",
    "        mssim = np.empty(nch, dtype=float_type)\n",
    "\n",
    "        if gradient:\n",
    "            G = np.empty(im1.shape, dtype=float_type)\n",
    "        if full:\n",
    "            S = np.empty(im1.shape, dtype=float_type)\n",
    "        channel_axis = channel_axis % im1.ndim\n",
    "        _at = functools.partial(utils.slice_at_axis, axis=channel_axis)\n",
    "        for ch in range(nch):\n",
    "            ch_result = structural_similarity(im1[_at(ch)], im2[_at(ch)], **args)\n",
    "            if gradient and full:\n",
    "                mssim[ch], G[_at(ch)], S[_at(ch)] = ch_result\n",
    "            elif gradient:\n",
    "                mssim[ch], G[_at(ch)] = ch_result\n",
    "            elif full:\n",
    "                mssim[ch], S[_at(ch)] = ch_result\n",
    "            else:\n",
    "                mssim[ch] = ch_result\n",
    "        mssim = mssim.mean()\n",
    "        if gradient and full:\n",
    "            return mssim, G, S\n",
    "        elif gradient:\n",
    "            return mssim, G\n",
    "        elif full:\n",
    "            return mssim, S\n",
    "        else:\n",
    "            return mssim\n",
    "\n",
    "    K1 = kwargs.pop('K1', 0.01)\n",
    "    K2 = kwargs.pop('K2', 0.03)\n",
    "    sigma = kwargs.pop('sigma', 1.5)\n",
    "    if K1 < 0:\n",
    "        raise ValueError(\"K1 must be positive\")\n",
    "    if K2 < 0:\n",
    "        raise ValueError(\"K2 must be positive\")\n",
    "    if sigma < 0:\n",
    "        raise ValueError(\"sigma must be positive\")\n",
    "    use_sample_covariance = kwargs.pop('use_sample_covariance', True)\n",
    "\n",
    "    if gaussian_weights:\n",
    "        # Set to give an 11-tap filter with the default sigma of 1.5 to match\n",
    "        # Wang et. al. 2004.\n",
    "        truncate = 3.5\n",
    "\n",
    "    if win_size is None:\n",
    "        if gaussian_weights:\n",
    "            # set win_size used by crop to match the filter size\n",
    "            r = int(truncate * sigma + 0.5)  # radius as in ndimage\n",
    "            win_size = 2 * r + 1\n",
    "        else:\n",
    "            win_size = 7  # backwards compatibility\n",
    "\n",
    "    if np.any((np.asarray(im1.shape) - win_size) < 0):\n",
    "        raise ValueError(\n",
    "            'win_size exceeds image extent. '\n",
    "            'Either ensure that your images are '\n",
    "            'at least 7x7; or pass win_size explicitly '\n",
    "            'in the function call, with an odd value '\n",
    "            'less than or equal to the smaller side of your '\n",
    "            'images. If your images are multichannel '\n",
    "            '(with color channels), set channel_axis to '\n",
    "            'the axis number corresponding to the channels.'\n",
    "        )\n",
    "\n",
    "    if not (win_size % 2 == 1):\n",
    "        raise ValueError('Window size must be odd.')\n",
    "\n",
    "    if data_range is None:\n",
    "        if np.issubdtype(im1.dtype, np.floating) or np.issubdtype(\n",
    "            im2.dtype, np.floating\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                'Since image dtype is floating point, you must specify '\n",
    "                'the data_range parameter. Please read the documentation '\n",
    "                'carefully (including the note). It is recommended that '\n",
    "                'you always specify the data_range anyway.'\n",
    "            )\n",
    "        if im1.dtype != im2.dtype:\n",
    "            warn(\n",
    "                \"Inputs have mismatched dtypes. Setting data_range based on im1.dtype.\",\n",
    "                stacklevel=2,\n",
    "            )\n",
    "        dmin, dmax = dtype_range[im1.dtype.type]\n",
    "        data_range = dmax - dmin\n",
    "        if np.issubdtype(im1.dtype, np.integer) and (im1.dtype != np.uint8):\n",
    "            warn(\n",
    "                \"Setting data_range based on im1.dtype. \"\n",
    "                + f\"data_range = {data_range:.0f}. \"\n",
    "                + \"Please specify data_range explicitly to avoid mistakes.\",\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "    ndim = im1.ndim\n",
    "\n",
    "    if gaussian_weights:\n",
    "        filter_func = gaussian\n",
    "        filter_args = {'sigma': sigma, 'truncate': truncate, 'mode': 'reflect'}\n",
    "    else:\n",
    "        filter_func = uniform_filter\n",
    "        filter_args = {'size': win_size}\n",
    "\n",
    "    # ndimage filters need floating point data\n",
    "    im1 = im1.astype(float_type, copy=False)\n",
    "    im2 = im2.astype(float_type, copy=False)\n",
    "\n",
    "    NP = win_size**ndim\n",
    "\n",
    "    # filter has already normalized by NP\n",
    "    if use_sample_covariance:\n",
    "        cov_norm = NP / (NP - 1)  # sample covariance\n",
    "    else:\n",
    "        cov_norm = 1.0  # population covariance to match Wang et. al. 2004\n",
    "\n",
    "    # compute (weighted) means\n",
    "    ux = filter_func(im1, **filter_args)\n",
    "    uy = filter_func(im2, **filter_args)\n",
    "\n",
    "    # compute (weighted) variances and covariances\n",
    "    uxx = filter_func(im1 * im1, **filter_args)\n",
    "    uyy = filter_func(im2 * im2, **filter_args)\n",
    "    uxy = filter_func(im1 * im2, **filter_args)\n",
    "    vx = cov_norm * (uxx - ux * ux)\n",
    "    vy = cov_norm * (uyy - uy * uy)\n",
    "    vxy = cov_norm * (uxy - ux * uy)\n",
    "\n",
    "    R = data_range\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "\n",
    "    return {\n",
    "        'ux': ux,\n",
    "        'uy': uy,\n",
    "        'vxy': vxy,\n",
    "        'vx': vx,\n",
    "        'vy': vy,\n",
    "        'C1': C1,\n",
    "        'C2': C2,\n",
    "    }\n",
    "\n",
    "    # A1, A2, B1, B2 = (\n",
    "    #     2 * ux * uy + C1,\n",
    "    #     2 * vxy + C2,\n",
    "    #     ux**2 + uy**2 + C1,\n",
    "    #     vx + vy + C2,\n",
    "    # )\n",
    "    \n",
    "    # D = B1 * B2\n",
    "    # S = (A1 * A2) / D\n",
    "\n",
    "    # # to avoid edge effects will ignore filter radius strip around edges\n",
    "    # pad = (win_size - 1) // 2\n",
    "\n",
    "    # # compute (weighted) mean of ssim. Use float64 for accuracy.\n",
    "    # mssim = crop(S, pad).mean(dtype=np.float64)\n",
    "\n",
    "    # if gradient:\n",
    "    #     # The following is Eqs. 7-8 of Avanaki 2009.\n",
    "    #     grad = filter_func(A1 / D, **filter_args) * im1\n",
    "    #     grad += filter_func(-S / B2, **filter_args) * im2\n",
    "    #     grad += filter_func((ux * (A2 - A1) - uy * (B2 - B1) * S) / D, **filter_args)\n",
    "    #     grad *= 2 / im1.size\n",
    "\n",
    "    #     if full:\n",
    "    #         return mssim, grad, S\n",
    "    #     else:\n",
    "    #         return mssim, grad\n",
    "    # else:\n",
    "    #     if full:\n",
    "    #         return mssim, S\n",
    "    #     else:\n",
    "    #         return mssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_ssim_from_params(alpha, ux, uy, vx, vy, vxy, C1, C2):\n",
    "    A1, A2, B1, B2 = (\n",
    "        2 * alpha* ux * uy + C1,\n",
    "        2 * alpha * vxy + C2,\n",
    "        ux**2 + (alpha**2) * uy**2 + C1,\n",
    "        vx + (alpha**2)*vy + C2,\n",
    "    )\n",
    "    \n",
    "    D = B1 * B2\n",
    "    S = (A1 * A2) / D\n",
    "    return np.mean(-1 * S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_dict = structural_similarity_dict(tar[0,...,0].astype(np.float32), pred[0,...,0].astype(np.float32), data_range = tar[:,...,0].max() - tar[:,...,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_from_params(0.1, ssim_dict['ux'], ssim_dict['uy'],ssim_dict['vx'],ssim_dict['vy'], ssim_dict['vxy'], ssim_dict['C1'], ssim_dict['C2']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxy = ssim_dict['vxy']\n",
    "vx = ssim_dict['vx']\n",
    "vy = ssim_dict['vy']\n",
    "\n",
    "ux = ssim_dict['ux']\n",
    "uy = ssim_dict['uy']\n",
    "\n",
    "C1 = ssim_dict['C1']\n",
    "C2 = ssim_dict['C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# initial (bad) guess at (x,y) values\n",
    "initial_guess = np.array([1])\n",
    "res = minimize(neg_ssim_from_params, initial_guess, args=(ux, uy, vx, vy, vxy, C1, C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.psnr import fix, zero_mean\n",
    "from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure\n",
    "from disentangle.core.numpy_decorator import allow_numpy\n",
    "import torch\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def range_invariant_ssim(gt_, pred_):\n",
    "    \"\"\"\n",
    "    Computes range invariant multiscale ssim for one channel.\n",
    "    This has the benefit that it is invariant to scalar multiplications in the prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    shape = gt_.shape\n",
    "    gt_ = torch.Tensor(gt_.reshape((shape[0],-1)))\n",
    "    pred_ = torch.Tensor(pred_.reshape((shape[0],-1)))\n",
    "    gt_ = zero_mean(gt_)\n",
    "    pred_ = zero_mean(pred_)\n",
    "    pred_ = fix(gt_, pred_)\n",
    "    pred_ = pred_.reshape(shape).numpy()\n",
    "    gt_ = gt_.reshape(shape).numpy()\n",
    "    return ssim(gt_, pred_, data_range=gt_.max() - gt_.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "range_invariant_multiscale_ssim(tar[0,...,0].astype(np.float32), pred[0,...,0].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sympy import * \n",
    "\n",
    "# alpha = symbols('alpha')\n",
    "\n",
    "# vxy = Matrix(ssim_dict['vxy'])\n",
    "# vx = Matrix(ssim_dict['vx'])\n",
    "# vy = Matrix(ssim_dict['vy'])\n",
    "\n",
    "# ux = Matrix(ssim_dict['ux'])\n",
    "# uy = Matrix(ssim_dict['uy'])\n",
    "\n",
    "# C1 = ssim_dict['C1']\n",
    "# C2 = ssim_dict['C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 = ssim_dict['C1']\n",
    "# C2 = ssim_dict['C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num =  (2*alpha*vxy + C2) * (2*alpha*ux * uy + C1)\n",
    "# den = (alpha**2 * vy + vx + C2) * (ux**2 + uy**2 + C1)\n",
    "# ssim = num/den"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
