{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Here, the objective is to find the rank of the individual structures and also those structures with/without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "from disentangle.data_loader.multifile_raw_dloader import SubDsetType\n",
    "from disentangle.data_loader.sox2golgi_v2_rawdata_loader import Sox2GolgiV2ChannelList, get_train_val_data\n",
    "from disentangle.core.data_split_type import DataSplitType\n",
    "\n",
    "config = ml_collections.ConfigDict()\n",
    "config.subdset_type = SubDsetType.MultiChannel\n",
    "config.channel_idx_list = [\n",
    "    Sox2GolgiV2ChannelList.GT_Cy5, Sox2GolgiV2ChannelList.GT_TRITC, Sox2GolgiV2ChannelList.GT_555_647\n",
    "]\n",
    "config.num_channels = len(config.channel_idx_list)\n",
    "config.input_idx = 2\n",
    "config.target_idx_list = [0, 1]\n",
    "config.use_selected_fpaths = ['Test1_Slice1/1.nd2', 'Test1_Slice1/2.nd2', 'Test1_Slice1/3.nd2',\n",
    "                              'Test1_Slice2_a/4.nd2', 'Test1_Slice2_a/5.nd2', 'Test1_Slice2_a/6.nd2',\n",
    "                              'Test1_Slice2_b/7.nd2', 'Test1_Slice2_b/8.nd2', 'Test1_Slice2_b/9.nd2']\n",
    "\n",
    "data = get_train_val_data('/group/jug/ashesh/data/TavernaSox2Golgi/acquisition2/',\n",
    "                            config,\n",
    "                            DataSplitType.Test,\n",
    "                            val_fraction=0.1,\n",
    "                            test_fraction=0.1)\n",
    "print(len(data))\n",
    "import matplotlib.pyplot as plt\n",
    "_, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "ax[0].imshow(data[0][0][..., 0])\n",
    "ax[1].imshow(data[0][0][..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ch1_imgs = np.stack([d[0][..., 0] for d in data])\n",
    "ch2_imgs = np.stack([d[0][..., 1] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ch2_imgs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.calibration_coverage_v2 import divide_into_smaller_patches\n",
    "# def divide_into_smaller_patches(np_array, elem_size=10):\n",
    "patch_size = 128\n",
    "patches_1 = divide_into_smaller_patches(ch1_imgs[:,None], elem_size=patch_size)[:,0]\n",
    "patches_2 = divide_into_smaller_patches(ch2_imgs[:,None], elem_size=patch_size)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(patches_2[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_1 = patches_1.reshape(-1, patch_size*patch_size)\n",
    "vectors_2 = patches_2.reshape(-1, patch_size*patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 600\n",
    "pca1 = PCA(n_components=n_components)\n",
    "pca1.fit(vectors_1)\n",
    "pca2 = PCA(n_components=n_components)\n",
    "pca2.fit(vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pca1.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_vector1 = pca1.inverse_transform(pca1.transform(vectors_1))\n",
    "recons_patches1 = recons_vector1.reshape(-1, patch_size, patch_size)\n",
    "\n",
    "recons_vector2 = pca2.inverse_transform(pca2.transform(vectors_2))\n",
    "recons_patches2 = recons_vector2.reshape(-1, patch_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(6,6), ncols=2,nrows=2)\n",
    "ax[0,0].imshow(patches_1[10])\n",
    "ax[0,1].imshow(recons_patches1[10])\n",
    "\n",
    "ax[1,0].imshow(patches_2[10])\n",
    "ax[1,1].imshow(recons_patches2[10])\n",
    "\n",
    "ax[0,0].set_title('Original')\n",
    "ax[0,1].set_title('Reconstructed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetunesplit.asymmetric_transforms import VFlip, Rotate, HFlip, DeepinvTransform, TransformAllChannels\n",
    "from deepinv.transform.projective import Homography\n",
    "# trans_homo = Homography(n_trans = 1, zoom_factor_min=1.0, theta_max=10, theta_z_max=180, skew_max=0, shift_max=0.5,\n",
    "#                         x_stretch_factor_min = 1,\n",
    "#                         y_stretch_factor_min = 1)\n",
    "# transform_types = {0:[VFlip(), Rotate(),HFlip(), DeepinvTransform(trans_homo)], 1:[ VFlip(), HFlip(), Rotate(), DeepinvTransform(trans_homo)]}\n",
    "transform_types = {0:[VFlip(), Rotate(),HFlip()], 1:[ VFlip(), HFlip(), Rotate()]}\n",
    "transform_all = TransformAllChannels(transform_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_patches = np.concatenate([patches_1[:,None], patches_2[:,None]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "num_transforms = 5\n",
    "augmented_data = []\n",
    "for _ in range(num_transforms):\n",
    "    transformed_patches,_ = transform_all(torch.Tensor(combined_patches*1.0))\n",
    "    augmented_data.append(transformed_patches)\n",
    "\n",
    "augmented_data = np.concatenate(augmented_data, axis=0)\n",
    "augmented_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1_dict = {}\n",
    "pca2_dict = {}\n",
    "\n",
    "for i in range(num_transforms):\n",
    "    enlarged_data= np.concatenate([augmented_data[:(i+1)*len(combined_patches)], combined_patches],axis=0)\n",
    "    print(enlarged_data.shape)\n",
    "    pca1_enlarged = PCA(n_components=n_components+200)\n",
    "    pca1_enlarged.fit(enlarged_data[:,0].reshape(-1,patch_size*patch_size))\n",
    "    pca2_enlarged = PCA(n_components=n_components+200)\n",
    "    pca2_enlarged.fit(enlarged_data[:,1].reshape(-1,patch_size*patch_size))\n",
    "    pca1_dict[i] = pca1_enlarged\n",
    "    pca2_dict[i] = pca2_enlarged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_var_coverage_1 = pca1.explained_variance_ratio_.cumsum()\n",
    "orig_var_coverage_2 = pca2.explained_variance_ratio_.cumsum()\n",
    "\n",
    "var1_coverage_dict = {}\n",
    "var2_coverage_dict = {}\n",
    "for i in range(num_transforms):\n",
    "    aug_var_coverage_1 =pca1_dict[i].explained_variance_ratio_.cumsum()\n",
    "    aug_var_coverage_2 =pca2_dict[i].explained_variance_ratio_.cumsum()\n",
    "    var1_coverage_dict[i] = aug_var_coverage_1\n",
    "    var2_coverage_dict[i] = aug_var_coverage_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "ax[0].plot(orig_var_coverage_1, label='original')\n",
    "ax[1].plot(orig_var_coverage_2, label='original')\n",
    "\n",
    "for i in range(num_transforms):\n",
    "    ax[0].plot(var1_coverage_dict[i], label=f'{i+1} augmented images ')\n",
    "    ax[1].plot(var2_coverage_dict[i], label=f'{i+1} augmented images ')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reach the same level of reconstruction, how many more components do we need?\n",
    "def plot_extra_dims(orig_var_coverage, aug_var_coverage, ax=None, label=None):\n",
    "    if ax is None:\n",
    "        _,ax = plt.subplots()\n",
    "    index =  np.searchsorted(orig_var_coverage, aug_var_coverage)\n",
    "    orig_index = np.arange(0, len(aug_var_coverage),1)\n",
    "    ax.plot(aug_var_coverage, orig_index - index, label=label)\n",
    "    ax.grid()\n",
    "\n",
    "# plot y=x\n",
    "# plt.plot(orig_index, orig_index, 'r--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "for i in range(num_transforms):\n",
    "    plot_extra_dims(orig_var_coverage_1, var1_coverage_dict[i], ax=ax[0], label=f'{i+1} augmented images ')\n",
    "    plot_extra_dims(orig_var_coverage_2, var2_coverage_dict[i], ax=ax[1], label=f'{i+1} augmented images ')\n",
    "ax[0].set_xlabel('% Variance explained')\n",
    "ax[1].set_xlabel('% Variance explained')\n",
    "ax[0].set_ylabel('Extra dimensions needed')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlcusion\n",
    "So, we need 4 augmentations at the same time to have the highest rank.\n",
    "Anything more than 4 augmentations will not have any effect on the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_var_coverage_1[-1], orig_var_coverage_2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
