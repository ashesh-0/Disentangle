{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Vanilla Unfolded algorithm for super-resolution\n",
    "\n",
    "This is a simple example to show how to use vanilla unfolded Plug-and-Play.\n",
    "The DnCNN denoiser and the algorithm parameters (stepsize, regularization parameters) are trained jointly.\n",
    "For simplicity, we show how to train the algorithm on a  small dataset. For optimal results, use a larger dataset.\n",
    "For visualizing the training, you can use Weight&Bias (wandb) by setting ``wandb_vis=True``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from deepinv.optim.data_fidelity import L2\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.unfolded import unfolded_builder\n",
    "from torchvision import transforms\n",
    "from deepinv.utils.demo import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup paths for data loading and results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load base image datasets and degradation operators.\n",
    "In this example, we use the CBSD500 dataset for training and the Set3C dataset for testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64 if torch.cuda.is_available() else 32\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "operation = \"super-resolution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dataset of low resolution images and load it.\n",
    "We use the Downsampling class from the physics module to generate a dataset of low resolution images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we use a small dataset for training.\n",
    "# To be replaced for optimal results. For example, you can use the larger \"drunet\" dataset.\n",
    "train_dataset_name = \"CBSD500\"\n",
    "test_dataset_name = \"set3c\"\n",
    "# Specify the  train and test transforms to be applied to the input images.\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "# Define the base train and test datasets of clean images.\n",
    "train_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\n",
    "test_base_dataset = load_dataset(test_dataset_name, transform=test_transform)\n",
    "\n",
    "# Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous\n",
    "# dataloading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Degradation parameters\n",
    "factor = 2\n",
    "noise_level_img = 0.03\n",
    "\n",
    "# Generate the gaussian blur downsampling operator.\n",
    "physics = dinv.physics.Downsampling(\n",
    "    filter=\"gaussian\",\n",
    "    img_size=(n_channels, img_size, img_size),\n",
    "    factor=factor,\n",
    "    device=device,\n",
    "    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n",
    ")\n",
    "my_dataset_name = \"demo_unfolded_sr\"\n",
    "n_images_max = (\n",
    "    1000 if torch.cuda.is_available() else 10\n",
    ")  # maximal number of images used for training\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "generated_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the unfolded PnP algorithm.\n",
    "We use the helper function :func:`deepinv.unfolded.unfolded_builder` to defined the Unfolded architecture.\n",
    "The chosen algorithm is here DRS (Douglas-Rachford Splitting).\n",
    "Note that if the prior (resp. a parameter) is initialized with a list of lenght max_iter,\n",
    "then a distinct model (resp. parameter) is trained for each iteration.\n",
    "For fixed trained model prior (resp. parameter) across iterations, initialize with a single element.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unrolled optimization algorithm parameters\n",
    "max_iter = 5  # number of unfolded layers\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = L2()\n",
    "\n",
    "# Set up the trainable denoising prior\n",
    "# Here the prior model is common for all iterations\n",
    "prior = PnP(denoiser=dinv.models.DnCNN(depth=7, pretrained=None).to(device))\n",
    "\n",
    "# The parameters are initialized with a list of length max_iter, so that a distinct parameter is trained for each iteration.\n",
    "stepsize = [1] * max_iter  # stepsize of the algorithm\n",
    "sigma_denoiser = [0.01] * max_iter  # noise level parameter of the denoiser\n",
    "beta = 1  # relaxation parameter of the Douglas-Rachford splitting\n",
    "params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n",
    "    \"stepsize\": stepsize,\n",
    "    \"g_param\": sigma_denoiser,\n",
    "    \"beta\": beta,\n",
    "}\n",
    "trainable_params = [\n",
    "    \"g_param\",\n",
    "    \"stepsize\",\n",
    "    \"beta\",\n",
    "]  # define which parameters from 'params_algo' are trainable\n",
    "\n",
    "# Logging parameters\n",
    "verbose = True\n",
    "wandb_vis = False  # plot curves and images in Weight&Bias\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = unfolded_builder(\n",
    "    iteration=\"DRS\",\n",
    "    params_algo=params_algo.copy(),\n",
    "    trainable_params=trainable_params,\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training parameters.\n",
    "We use the Adam optimizer and the StepLR scheduler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 10 if torch.cuda.is_available() else 2\n",
    "learning_rate = 5e-4\n",
    "train_batch_size = 32 if torch.cuda.is_available() else 1\n",
    "test_batch_size = 3\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n",
    "\n",
    "# choose supervised training loss\n",
    "losses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "We train the network using the :class:`deepinv.Trainer` class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = dinv.Trainer(\n",
    "    model,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler,\n",
    "    losses=losses,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    verbose=verbose,\n",
    "    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n",
    "    wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias\n",
    ")\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_dataloader)\n",
    "\n",
    "test_sample, _ = next(iter(test_dataloader))\n",
    "model.eval()\n",
    "test_sample = test_sample.to(device)\n",
    "\n",
    "# Get the measurements and the ground truth\n",
    "y = physics(test_sample)\n",
    "with torch.no_grad():\n",
    "    rec = model(y, physics=physics)\n",
    "\n",
    "backprojected = physics.A_adjoint(y)\n",
    "\n",
    "dinv.utils.plot(\n",
    "    [backprojected, rec, test_sample],\n",
    "    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n",
    "    suptitle=\"Reconstruction results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the weights of the network.\n",
    "\n",
    "We now plot the weights of the network that were learned and check that they are different from their initialization\n",
    "values. Note that ``g_param`` corresponds to $\\lambda$ in the proximal gradient algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinv.utils.plotting.plot_parameters(\n",
    "    model, init_params=params_algo, save_dir=RESULTS_DIR / \"unfolded_pgd\" / operation\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
